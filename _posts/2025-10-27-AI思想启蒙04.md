---
layout: post
title: "ã€AIæ€æƒ³å¯è’™04ã€‘çº¿æ€§å›å½’3çªç ´ç“¶é¢ˆï¼Œæ¨¡å‹æ•ˆæœçš„æå‡ "
subtitle: "å¤šå…ƒçº¿æ€§å›å½’å¤„ç†å¤šç‰¹å¾æ•°æ®ï¼Œé€šè¿‡å¢å¹¿å‘é‡ç»Ÿä¸€è¡¨è¾¾ï¼ŒMSEä¼˜åŒ–æƒé‡ã€‚å¤šé¡¹å¼å›å½’æ‹Ÿåˆéçº¿æ€§ï¼Œéœ€å¹³è¡¡è¿‡æ‹Ÿåˆã€‚éšæœºç‰¹å¾æƒé‡æœŸæœ›ä¸º0ï¼Œå…±çº¿æ€§å¯¼è‡´ç³»æ•°ä¸ç¨³å®šï¼Œéœ€ç‰¹å¾é€‰æ‹©æˆ–æ­£åˆ™åŒ–ã€‚"
date: 2025-10-27
author: "Hilda"
header-img: "img/post-bg-2015.jpg"
tags:
- AIæ€æƒ³å¯è’™
---

<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG">
</script>



ç°å®ä¸­ï¼Œçº¿æ€§å›å½’çš„é—®é¢˜å¾€å¾€æ˜¯å¤šå…ƒçš„ã€‚

# 1.å¤šå…ƒå›å½’æ¨¡å‹åŸºæœ¬æè¿°

å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹æ˜¯å¤„ç†å…·æœ‰å¤šä¸ªç‰¹å¾ï¼ˆ$$X$$ å‘é‡ï¼‰çš„å›å½’é—®é¢˜ã€‚

æ¨¡å‹æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå°†è¾“å…¥ $$X$$ æ˜ å°„åˆ°è¾“å‡º $$Y$$ã€‚

ç›®æ ‡å€¼ $$y$$ æ˜¯ç”±å¤šä¸ªç‰¹å¾ $$x_i$$ åŠå…¶å¯¹åº”çš„æƒé‡ $$w_i$$ çš„çº¿æ€§ç»„åˆæ„æˆã€‚

$$y = w_1 x_1 + w_2 x_2 + \cdots + w_n x_n + w_0$$

ä¸Šé¢çš„æ˜¯æ ‡é‡å½¢å¼ï¼Œä¹Ÿå¯ä»¥å†™æˆå‘é‡å½¢å¼/çŸ©é˜µä¹˜æ³•å½¢å¼ï¼Œè¿™æ˜¯ä¸€ç§æ›´è§„èŒƒã€æ›´ç´§å‡‘çš„è¡¨è¾¾æ–¹å¼ï¼š

$$\hat{y} = \mathbf{W}^{\text{T}} \mathbf{X} + w_0$$

å…¶ä¸­ï¼Œ$$\mathbf{W} = \begin{pmatrix} w_1 \\ \vdots \\ w_n \end{pmatrix}$$ æ˜¯æƒé‡å‘é‡ã€‚$$\mathbf{X} = \begin{pmatrix} x_1 \\ \vdots \\ x_n \end{pmatrix}$$ æ˜¯ç‰¹å¾å‘é‡ã€‚$$w_0$$ï¼ˆæˆ– $$b$$ï¼‰æ˜¯åç½®ï¼ˆæˆªè·ï¼‰é¡¹ã€‚

æ¨¡å‹çš„ç›®æ ‡æ˜¯æ‰¾åˆ°æœ€ä¼˜çš„æƒé‡ $$\mathbf{W}$$ å’Œåç½® $$w_0$$ï¼Œä½¿å¾—é¢„æµ‹å€¼ $$\hat{y}$$ ä¸çœŸå®å€¼ $$y$$ ä¹‹é—´çš„è¯¯å·®æœ€å°ã€‚

å’Œä¸€å…ƒçš„çº¿æ€§å›å½’é—®é¢˜ä¸€æ ·ï¼Œè¡¡é‡æ¨¡å‹æ€§èƒ½æœ€å¸¸ç”¨çš„æŒ‡æ ‡è¿˜æ˜¯MSEï¼ˆå‡æ–¹è¯¯å·®ï¼‰ï¼š

$$\text{MSE} = \frac{1}{n}\sum_{i=1}^n (\hat{y}_i - y_i)^2$$

ä¸ºäº†å°†åç½®é¡¹ $$w_0$$ èå…¥çŸ©é˜µä¹˜æ³•ä¸­ï¼Œä½¿å…¶æˆä¸ºæƒé‡ $$\mathbf{W}$$ çš„ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬éœ€è¦å¯¹ç‰¹å¾å‘é‡ $$\mathbf{X}$$ è¿›è¡Œ**å¢å¹¿ï¼ˆAugmentationï¼‰**ï¼š

å¢å¹¿ç‰¹å¾å‘é‡ $$\mathbf{X}$$ï¼šåœ¨åŸå§‹ç‰¹å¾å‘é‡ $$\mathbf{X}$$ çš„ç¬¬ä¸€ä¸ªä½ç½®ï¼ˆæˆ–æœ€åä¸€ä¸ªä½ç½®ï¼‰æ·»åŠ ä¸€ä¸ªæ’ä¸º1çš„å…ƒç´ ã€‚

$$\mathbf{X} = \begin{pmatrix} 1 \\ x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix}$$

è¿™ä¸ªå¸¸æ•° $1$ ç¡®ä¿äº† $w_0$ åœ¨çŸ©é˜µä¹˜æ³•ä¸­è¢«ä¿ç•™ã€‚

**å¢å¹¿æƒé‡å‘é‡ $$\mathbf{W}$$ï¼š** å°†åç½®é¡¹ $$w_0$$ ä½œä¸ºæƒé‡å‘é‡ $$\mathbf{W}$$ çš„ç¬¬ä¸€ä¸ªå…ƒç´ ï¼ˆå¯¹åº”äºå¢å¹¿ç‰¹å¾1ï¼‰ã€‚

$$\mathbf{W} = \begin{pmatrix} w_0 \\ w_1 \\ w_2 \\ \vdots \\ w_n \end{pmatrix}$$

é€šè¿‡è¿™ç§å¢å¹¿ï¼Œå¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹å¯ä»¥ç»Ÿä¸€è¡¨è¾¾ä¸ºä¸€ä¸ªç®€å•çš„å‘é‡å†…ç§¯ï¼ˆçŸ©é˜µä¹˜æ³•ï¼‰ï¼š

$$\hat{y} = \mathbf{W}^{\text{T}} \mathbf{X}$$

æˆ–

$$\hat{y} = \mathbf{X}^{\text{T}} \mathbf{W}$$

è¿™ç§ç®€åŒ–è¡¨è¾¾æ˜¯æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ä¸­çš„**æ ‡å‡†åšæ³•**,ç®€åŒ–æ‰€æœ‰æ•°å­¦æ¨å¯¼ï¼ˆå¦‚æ¢¯åº¦ã€æ­£è§„æ–¹ç¨‹ï¼‰ã€‚åŒæ—¶ç®€åŒ–äº†ç¼–ç¨‹å®ç°ï¼Œè€Œä¸”MSE æŸå¤±å‡½æ•°ä»ç„¶é€‚ç”¨äºè¿™ç§ç®€åŒ–å½¢å¼ï¼š

$$\text{MSE} = \frac{1}{m}\sum_{i=1}^m (\mathbf{W}^{\text{T}} \mathbf{X}_i - y_i)^2$$

è¿™ç§ç®€æ´çš„è¡¨è¾¾æ–¹å¼ä½¿å¾—å¤æ‚çš„å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹åœ¨ä»£æ•°å’Œç¼–ç¨‹ä¸Šéƒ½å˜å¾—é«˜æ•ˆå’Œä¼˜é›…ã€‚

# 2.å¤šå…ƒå›å½’-å®æˆ˜

1.è¯»å–æ•°æ®ï¼š

```python
import numpy as np
import ast

def load_data_from_list_format(file_path):
    """
    åŠ è½½å¹¶è§£ææ‚¨çš„ç‰¹å®šæ ¼å¼ï¼ˆ[[...], ...]ï¼‰çš„æ•°æ®æ–‡ä»¶ã€‚
    """
    features = []
    targets = []
    
    with open(file_path, 'r') as f:
        for line in f:
            # 1. ä½¿ç”¨ ast.literal_eval å®‰å…¨åœ°å°†å­—ç¬¦ä¸²è§£æä¸º Python åˆ—è¡¨
            try:
                data_tuple = ast.literal_eval(line.strip())
                
                # 2. è§£åŒ…ï¼šç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯ç‰¹å¾åˆ—è¡¨ï¼Œç¬¬äºŒä¸ªæ˜¯ç›®æ ‡å€¼
                X_row = data_tuple[0]
                y_value = data_tuple[1]
                
                features.append(X_row)
                targets.append(y_value)
                
            except (ValueError, SyntaxError) as e:
                print(f"Skipping line due to error: {e} in line: {line.strip()}")
                continue
                
    # 3. è½¬æ¢ä¸º NumPy æ•°ç»„
    X = np.array(features)
    y = np.array(targets)
    
    return X, y

# ç¤ºä¾‹è°ƒç”¨
file_path = "../boston/train_data"
X_train, y_train = load_data_from_list_format(file_path)

print(f"Features (X_train) shape: {X_train.shape}")
print(f"Targets (y_train) shape: {y_train.shape}")
print("\nFirst row of features:")
print(X_train[0])
print("\nFirst target value:")
print(y_train[0])
```

<img src="https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027180907089.png" alt="image-20251027180907089" style="zoom:50%;" />

2.ä½¿ç”¨å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹å¯¹åŠ è½½çš„å…¨éƒ¨æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå¹¶æ‰“å°å‡ºæ¨¡å‹çš„å‚æ•°ï¼ˆå³æˆªè·å’Œç³»æ•°ï¼‰ã€‚

```python
# ----------------- æ¨¡å‹è®­ç»ƒ -----------------
print("ğŸš€ æ­£åœ¨ä½¿ç”¨å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹è¿›è¡Œè®­ç»ƒ...")

# 1. åˆå§‹åŒ–æ¨¡å‹
model = LinearRegression()

# 2. è®­ç»ƒæ¨¡å‹
# æ³¨æ„ï¼šåœ¨å®é™…åº”ç”¨ä¸­ï¼Œæ‚¨é€šå¸¸ä¼šåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œä½†æ ¹æ®æ‚¨çš„è¯·æ±‚ï¼Œæˆ‘ä»¬ä½¿ç”¨å…¨éƒ¨æ•°æ®è¿›è¡Œè®­ç»ƒã€‚
model.fit(X_train, y_train)

print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆã€‚")
print("\n--- æ¨¡å‹å‚æ•° ---")

# 3. æ‰“å°æ¨¡å‹å‚æ•°
# æˆªè· (Intercept)
print(f"**æˆªè· (Intercept, $\\beta_0$):** {model.intercept_:.4f}")

# ç³»æ•° (Coefficients)
print("\n**ç‰¹å¾ç³»æ•° (Coefficients, $\\beta_{1}$ åˆ° $\\beta_{13}$):**")
# å°†ç³»æ•°æ‰“å°æˆæ˜“äºé˜…è¯»çš„æ ¼å¼
coefficients = model.coef_
for i, coef in enumerate(coefficients):
    # å‡è®¾ç‰¹å¾ç´¢å¼•å¯¹åº”äºç¬¬ 1 åˆ° ç¬¬ 13 ä¸ªç‰¹å¾
    print(f"  - Feature {i+1} (X{i+1}): {coef:.4f}")

# å¦‚æœæ‚¨æƒ³ä»¥ NumPy æ•°ç»„å½¢å¼æŸ¥çœ‹æ‰€æœ‰ç³»æ•°
# print(f"\næ‰€æœ‰ç³»æ•°æ•°ç»„: \n{coefficients}")
```

<img src="https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027181202802.png" alt="image-20251027181202802" style="zoom:50%;" />

æ³¨æ„ï¼Œä¸Šé¢çš„13ä¸ªå˜é‡æ²¡æœ‰è¿›è¡Œæ ‡å‡†åŒ–ï¼Œåªæœ‰åœ¨æ‰€æœ‰ç‰¹å¾ï¼ˆè‡ªå˜é‡ $$X_i$$ï¼‰éƒ½ç»è¿‡**æ ‡å‡†åŒ–ï¼ˆStandardizationï¼‰**å¤„ç†ï¼Œå³å®ƒä»¬å…·æœ‰ç›¸åŒçš„å°ºåº¦ï¼ˆä¾‹å¦‚ï¼Œå‡å€¼ä¸º 0ï¼Œæ ‡å‡†å·®ä¸º 1ï¼‰æ—¶ï¼Œå‚æ•°ï¼ˆç³»æ•°ï¼‰çš„ç»å¯¹å€¼è¶Šå¤§ï¼Œæ‰è¯´æ˜è¯¥å˜é‡å¯¹ $$Y$$ çš„å½±å“è¶Šå¤§ã€‚

> åœ¨è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œå¯¹æ‰€æœ‰ç‰¹å¾ $$X$$ è¿›è¡Œæ ‡å‡†åŒ–ï¼ˆStandardScalerï¼‰ï¼Œç„¶åå†æ¬¡è®­ç»ƒæ¨¡å‹ã€‚
>
> $$\text{æ ‡å‡†åŒ–} (X') = \frac{X - \mu}{\sigma}$$

# 3.å¤šé¡¹å¼å›å½’

ä½¿ç”¨çº¿æ€§å›å½’çš„å‰ææ¡ä»¶ï¼šæ•°æ®å°½é‡åœ¨ä¸€æ¡ç›´çº¿ä¸Š

ä½†æ˜¯å¦‚æœæœ‰ä¸‹é¢è¿™æ ·çš„æ•°æ®ï¼Œå¦‚ä½•æ‹Ÿåˆï¼Ÿ

```python
import numpy as np

def load_and_clean_data(file_path):
    """
    ä»æŒ‡å®šæ–‡ä»¶ä¸­è¯»å–æ•°æ®ï¼Œæ¸…ç†å­—ç¬¦ä¸²æ ¼å¼ï¼Œå¹¶è¿”å› NumPy æ•°ç»„ã€‚
    æ•°æ®æ ¼å¼é¢„æœŸä¸ºï¼š[[x], [y]]
    """
    cleaned_data_list = []
    line_number = 0 # ç”¨äºè·Ÿè¸ªè¡Œå·

    try:
        with open(file_path, 'r') as f:
            for line in f:
                line_number += 1
                
                # 1. æ¸…ç†è¡Œé¦–å’Œè¡Œå°¾çš„ç©ºç™½å­—ç¬¦
                line_stripped = line.strip()
                
                # ä¸¥æ ¼è·³è¿‡ç©ºè¡Œæˆ–ä»…åŒ…å«ç©ºç™½å­—ç¬¦çš„è¡Œ
                if not line_stripped:
                    # å¦‚æœéœ€è¦è°ƒè¯•ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Šä¸‹é¢è¿™è¡Œ
                    # print(f"è·³è¿‡æ–‡ä»¶ä¸­çš„ç©ºè¡Œæˆ–ç©ºç™½è¡Œ (è¡Œå·: {line_number})")
                    continue
                    
                # 2. ç§»é™¤æ‰€æœ‰æ–¹æ‹¬å· '[]' å’Œç©ºæ ¼ï¼Œåªç•™ä¸‹æ•°å­—å’Œé€—å·
                # ç¤ºä¾‹: "[[5.34...], [30.91...]]" -> "5.34...,30.91..."
                clean_value_str = line_stripped.replace('[', '').replace(']', '').replace(' ', '')
                
                # 3. æŒ‰é€—å·åˆ†éš”ï¼Œå¾—åˆ° X å’Œ y çš„å­—ç¬¦ä¸²
                x_str, y_str = clean_value_str.split(',')
                
                # 4. è½¬æ¢ä¸ºæµ®ç‚¹æ•°å¹¶å­˜å‚¨
                x_val = float(x_str)
                y_val = float(y_str)
                cleaned_data_list.append([x_val, y_val])
                
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ {file_path}ã€‚è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„ã€‚")
        return None, None
    except ValueError as e:
        print(f"âŒ é”™è¯¯ï¼šæ•°æ®æ ¼å¼ä¸æ­£ç¡®ï¼Œæ— æ³•è½¬æ¢ä¸ºæµ®ç‚¹æ•°ã€‚è¯·æ£€æŸ¥æ•°æ®è¡Œ (è¡Œå·: {line_number}): {line_stripped}")
        print(f"å…·ä½“é”™è¯¯ä¿¡æ¯: {e}")
        return None, None
    except Exception as e:
        print(f"âŒ å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return None, None

    # 5. è½¬æ¢ä¸ºæœ€ç»ˆçš„ NumPy æ•°ç»„
    cleaned_data_np = np.array(cleaned_data_list, dtype=np.float64)
    
    # 6. åˆ†ç¦»ç‰¹å¾ (X) å’Œç›®æ ‡å€¼ (y)
    # X å¿…é¡»æ˜¯äºŒç»´æ•°ç»„ (n, 1)
    X = cleaned_data_np[:, 0].reshape(-1, 1)
    y = cleaned_data_np[:, 1] # y æ˜¯ä¸€ç»´æ•°ç»„ (n,)
    
    return X, y

# ----------------- ä¿®æ”¹åçš„ä½¿ç”¨ç¤ºä¾‹ -----------------
file_name = 'train_paracurve_data' # å»ºè®®ä½¿ç”¨ .txt æ‰©å±•åï¼Œä»¥æ˜ç¡®æ–‡ä»¶ç±»å‹

# **æ³¨æ„:** è¯·ç¡®ä¿æ‚¨çš„æ•°æ®å·²ä¿å­˜åˆ°æŒ‡å®šçš„æ–‡ä»¶ä¸­
X, y = load_and_clean_data(file_name)

if X is not None and y is not None:
    print("--- âœ… æ•°æ®è¯»å–æˆåŠŸ ---")
    print(f"ç‰¹å¾ X çš„å½¢çŠ¶: {X.shape}")
    print(f"ç›®æ ‡ y çš„å½¢çŠ¶: {y.shape}")
    print("X çš„å‰ 5 ä¸ªæ ·æœ¬:\n", X[:5])
    print("y çš„å‰ 5 ä¸ªæ ·æœ¬:\n", y[:5])
    print("\næ•°æ®å·²æ¸…ç†å¹¶å‡†å¤‡å¥½è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼ˆæœªåˆ†å‰²æ•°æ®é›†ï¼‰ã€‚")
    
    # **********************************************
    # ç§»é™¤çš„åˆ†å‰²ä»£ç åŸæœ¬åœ¨æ­¤å¤„ï¼Œç°åœ¨ç›´æ¥å¯¹ X å’Œ y è¿›è¡Œæ“ä½œ
    # **********************************************
    
    # ç°åœ¨æ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨æ•´ä¸ª X å’Œ y è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼ˆä¾‹å¦‚ï¼Œè®­ç»ƒé›†å°±æ˜¯æ•´ä¸ªæ•°æ®é›†ï¼‰
    # from sklearn.linear_model import LinearRegression
    # model = LinearRegression()
    # model.fit(X, y) # ç›´æ¥ä½¿ç”¨æ‰€æœ‰æ•°æ®è¿›è¡Œè®­ç»ƒ
    
if X is not None and y is not None:
    print("ğŸ¨ æ­£åœ¨ç”Ÿæˆæ•£ç‚¹å›¾...")
    
    # ç»˜åˆ¶æ•£ç‚¹å›¾
    plt.figure(figsize=(10, 6))
    
    # ç»˜åˆ¶åŸå§‹æ•°æ®ç‚¹ (æ•£ç‚¹å›¾)
    # X å¿…é¡»è¢«å±•å¹³ä¸ºä¸€ç»´æ•°ç»„æ‰èƒ½ä½œä¸º x è½´è¾“å…¥
    plt.scatter(X.flatten(), y, color='blue', alpha=0.7)
    
    # æ·»åŠ æ ‡é¢˜å’Œæ ‡ç­¾
    plt.title('ç‰¹å¾ X ä¸ç›®æ ‡ Y çš„æ•°æ®æ•£ç‚¹å›¾', fontsize=16)
    plt.xlabel('ç‰¹å¾ X å€¼', fontsize=14)
    plt.ylabel('ç›®æ ‡å€¼ Y å€¼', fontsize=14)
    
    # æ˜¾ç¤ºç½‘æ ¼
    plt.grid(True, linestyle='--', alpha=0.6)
    
    # æ˜¾ç¤ºå›¾å½¢
    plt.show()

    print("âœ… æ•£ç‚¹å›¾ç»˜åˆ¶å®Œæˆã€‚")
```

![image-20251027182028140](https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027182028140.png)

å¯ä»¥ç”¨ä¸‹é¢çš„æ¨¡å‹æ‹Ÿåˆï¼šï¼ˆå› ä¸ºé€šè¿‡è§‚å¯ŸçŒœæµ‹å¯ä»¥ç”¨æŠ›ç‰©çº¿æ‹Ÿåˆï¼‰

$$y = a x_1^2 + b x_1 + c$$

è¿™è¢«ç§°ä¸º **äºŒæ¬¡å¤šé¡¹å¼å›å½’ (Quadratic Polynomial Regression)**ã€‚

ä½¿ç”¨ `sklearn` çš„ `PolynomialFeatures` æ¥ç”Ÿæˆ $$x^2$$ å’Œ $$x$$ è¿™ä¸¤ä¸ªç‰¹å¾ï¼Œç„¶åä½¿ç”¨ `LinearRegression` è¿›è¡Œæ‹Ÿåˆã€‚

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score

# ä¸ºä¿è¯ç»˜å›¾å¹³æ»‘ï¼Œæˆ‘ä»¬å¯¹ X è¿›è¡Œæ’åº
sort_index = np.argsort(X.flatten())
X_sorted = X[sort_index]
y_sorted = y[sort_index]

# -------------------------- 1. ç‰¹å¾å·¥ç¨‹ï¼šç”Ÿæˆå¤šé¡¹å¼ç‰¹å¾ --------------------------
# æˆ‘ä»¬éœ€è¦åˆ›å»º X^2 å’Œ X è¿™ä¸¤ä¸ªç‰¹å¾
# å…¬å¼: y = a*x^2 + b*x + c
# è¿™ç›¸å½“äºä¸€ä¸ªçº¿æ€§æ¨¡å‹: y = a*Z1 + b*Z2 + cï¼Œå…¶ä¸­ Z1=x^2, Z2=x

# degree=2 ä¼šç”Ÿæˆ [1, x, x^2] (å¦‚æœ include_bias=True)
# æˆ‘ä»¬è®¾ç½®ä¸º include_bias=Falseï¼Œå› ä¸º LinearRegression é»˜è®¤ä¼šæ·»åŠ æˆªè· (c)
poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly.fit_transform(X_sorted)

# X_poly ç°åœ¨æœ‰ä¸¤åˆ—: [x, x^2] (æ³¨æ„ï¼šPolynomialFeatures é»˜è®¤æŒ‰å¹‚æ¬¡å‡åº [x^1, x^2])

# ä¸ºäº†å¯¹åº”æ‚¨å…¬å¼ä¸­çš„é¡ºåº (x^2, x)ï¼Œæˆ‘ä»¬æ‰‹åŠ¨è°ƒæ•´åˆ—çš„é¡ºåºï¼ˆå¯é€‰ï¼Œä½†æœ‰åŠ©äºå‚æ•°å¯¹åº”ï¼‰
# ç¡®ä¿ X_poly çš„åˆ—é¡ºåºæ˜¯ [x^2, x]
# å®é™…ä¸Šï¼Œç”±äºç³»æ•°æ˜¯è‡ªåŠ¨æ‹Ÿåˆçš„ï¼Œä¿æŒé»˜è®¤é¡ºåº [x, x^2] æ›´ç®€å•ã€‚
# æˆ‘ä»¬ä¿æŒé»˜è®¤é¡ºåºï¼Œå¹¶åœ¨è§£é‡Šç³»æ•°æ—¶è¯´æ˜ã€‚
# é»˜è®¤åˆ—é¡ºåº: X_poly = [x^1, x^2]

# -------------------------- 2. æ¨¡å‹è®­ç»ƒ --------------------------
model = LinearRegression()
model.fit(X_poly, y_sorted)

# 3. é¢„æµ‹æ‹Ÿåˆæ›²çº¿
# ç”¨äºç»˜å›¾çš„é¢„æµ‹å€¼
y_pred = model.predict(X_poly)

# -------------------------- 4. æ‰“å°å‚æ•° --------------------------
# ç³»æ•°é¡ºåº: model.coef_[0] å¯¹åº” xï¼Œ model.coef_[1] å¯¹åº” x^2
# æˆªè·: model.intercept_ å¯¹åº” c
coef_x = model.coef_[0]
coef_x2 = model.coef_[1]
intercept_c = model.intercept_

print("--- âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ ---")
print(f"æ‹Ÿåˆå…¬å¼: y = {coef_x2:.4f} * x^2 + {coef_x:.4f} * x + {intercept_c:.4f}")
print("--- æ¨¡å‹å‚æ•° ---")
print(f"a (x^2 çš„ç³»æ•°): {coef_x2:.4f}")
print(f"b (x çš„ç³»æ•°): {coef_x:.4f}")
print(f"c (æˆªè·): {intercept_c:.4f}")
print(f"æ‹Ÿåˆä¼˜åº¦ RÂ²: {r2_score(y_sorted, y_pred):.4f}")


# -------------------------- 5. ç»˜å›¾ --------------------------
# Matplotlib ç»˜å›¾è®¾ç½®
plt.rcParams["font.sans-serif"] = ["SimHei"]
plt.rcParams["axes.unicode_minus"] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºçš„é—®é¢˜

plt.figure(figsize=(10, 6))

# ç»˜åˆ¶åŸå§‹æ•°æ®ç‚¹ (æ•£ç‚¹å›¾)
plt.scatter(X_sorted.flatten(), y_sorted, color='blue', alpha=0.7, label='åŸå§‹æ•°æ®ç‚¹')

# ç»˜åˆ¶æ‹Ÿåˆæ›²çº¿
plt.plot(X_sorted.flatten(), y_pred, color='red', linewidth=3, label=f'æ‹Ÿåˆæ›²çº¿: y = a*xÂ² + b*x + c')

# æ·»åŠ æ ‡é¢˜å’Œæ ‡ç­¾
plt.title('äºŒæ¬¡å¤šé¡¹å¼å›å½’æ‹Ÿåˆ', fontsize=16)
plt.xlabel('ç‰¹å¾ X', fontsize=14)
plt.ylabel('ç›®æ ‡å€¼ Y', fontsize=14)

# æ·»åŠ å›¾ä¾‹
plt.legend()

# æ˜¾ç¤ºç½‘æ ¼
plt.grid(True, linestyle='--', alpha=0.6)

# æ˜¾ç¤ºå›¾å½¢
plt.show()
```

![image-20251027182554921](https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027182554921.png)

**$$R^2$$â€‹ (R-squared) ï¼Œä¹Ÿç§°ä¸ºå†³å®šç³»æ•° (Coefficient of Determination)**,æ˜¯ç”¨æ¥è¡¡é‡å»ºç«‹çš„å›å½’æ¨¡å‹å¯¹åŸå§‹æ•°æ®çš„æ‹Ÿåˆç¨‹åº¦çš„ä¸€ä¸ªæŒ‡æ ‡ã€‚è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼ˆéå¿…è¦äº†è§£ï¼Œä½†å¯å¸®åŠ©ç†è§£ï¼‰ï¼š

$$R^2 = 1 - \frac{SS_{res}}{SS_{tot}}$$

- $$SS_{res}$$ï¼ˆResidual Sum of Squaresï¼‰ï¼šæ®‹å·®å¹³æ–¹å’Œï¼Œå³é¢„æµ‹å€¼ä¸å®é™…å€¼ä¹‹é—´å·®å¼‚çš„å¹³æ–¹å’Œã€‚
- $$SS_{tot}$$ï¼ˆTotal Sum of Squaresï¼‰ï¼šæ€»å¹³æ–¹å’Œï¼Œå³å®é™…å€¼ä¸å®é™…å€¼å¹³å‡å€¼ä¹‹é—´å·®å¼‚çš„å¹³æ–¹å’Œï¼ˆä»£è¡¨äº† $Y$ çš„æ€»å˜å¼‚ï¼‰ã€‚

$$R^2$$ çš„å–å€¼èŒƒå›´é€šå¸¸åœ¨ 0 åˆ° 1 ä¹‹é—´ã€‚

| **R^2 å€¼**            | **å«ä¹‰**                                                     |
| --------------------- | ------------------------------------------------------------ |
| **$$R^2 \approx 1$$** | æ¨¡å‹èƒ½å¾ˆå¥½åœ°è§£é‡Šæ•°æ®çš„å˜å¼‚ã€‚è¿™æ„å‘³ç€æ¨¡å‹å¯¹æ•°æ®çš„æ‹Ÿåˆéå¸¸å¥½ï¼Œé¢„æµ‹å€¼ä¸å®é™…å€¼éå¸¸æ¥è¿‘ã€‚ |
| **$$R^2 \approx 0$$** | æ¨¡å‹å‡ ä¹ä¸èƒ½è§£é‡Šæ•°æ®çš„å˜å¼‚ã€‚è¿™æ„å‘³ç€æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›å¾ˆå¼±ï¼Œå¯èƒ½è¿˜ä¸å¦‚ç›´æ¥ä½¿ç”¨ $$Y$$ çš„å¹³å‡å€¼æ¥é¢„æµ‹ã€‚ |
| **$$R^2 < 0$$**       | è¿™ç§æƒ…å†µå¾ˆå°‘è§ï¼Œä½†å¯èƒ½å‘ç”Ÿåœ¨æ‹Ÿåˆä¸€ä¸ª**éçº¿æ€§æ¨¡å‹**ï¼ˆå¦‚æ‚¨åˆšæ‰åšçš„å¤šé¡¹å¼å›å½’ï¼‰æˆ–ä½¿ç”¨**ä¸åˆé€‚çš„æ¨¡å‹**æ—¶ã€‚å®ƒæ„å‘³ç€æ‚¨çš„æ¨¡å‹æ‹Ÿåˆæ•ˆæœæ¯”ç®€å•åœ°ä½¿ç”¨ $$Y$$ çš„å¹³å‡å€¼è¿›è¡Œé¢„æµ‹è¿˜è¦å·®ã€‚ |

----

ä¸Šé¢æ¼”ç¤ºçš„æ˜¯äºŒæ¬¡ï¼Œä¸‰æ¬¡ç”šè‡³é«˜æ¬¡éƒ½æ˜¯åŒç†ã€‚

æ ¹æ®æ³°å‹’å…¬å¼ï¼Œä»»æ„å‡½æ•°éƒ½å¯ä»¥è¡¨ç¤ºæˆ$$y = \beta_n x^n + \beta_{n-1} x^{n-1} + \dots + \beta_1 x + \beta_0$$

> æ ¹æ® **æ³°å‹’å…¬å¼ (Taylor's Formula)**ï¼Œ**åœ¨ä¸€å®šæ¡ä»¶ä¸‹**ï¼Œä¸€ä¸ªå¹³æ»‘ï¼ˆå¯å¯¼ï¼‰çš„å‡½æ•° $$f(x)$$ å¯ä»¥åœ¨æŸä¸€ç‚¹ $$x_0$$ é™„è¿‘ç”¨ä¸€ä¸ª**å¤šé¡¹å¼**æ¥è¿‘ä¼¼è¡¨ç¤ºï¼š
>
> $$f(x) \approx f(x_0) + f'(x_0)(x-x_0) + \frac{f''(x_0)}{2!}(x-x_0)^2 + \dots + \frac{f^{(n)}(x_0)}{n!}(x-x_0)^n$$
>
> **è¿™æ­£æ˜¯å¤šé¡¹å¼å›å½’çš„ç†è®ºåŸºç¡€ï¼**
>
> å¤šé¡¹å¼å›å½’çš„æœ¬è´¨å°±æ˜¯åˆ©ç”¨çº¿æ€§æ¨¡å‹æ¥æ‹Ÿåˆç‰¹å¾çš„**å¤šé¡¹å¼ç»„åˆ**ï¼Œä»è€Œ**åˆ©ç”¨æ³°å‹’å¤šé¡¹å¼çš„èƒ½åŠ›å»é€¼è¿‘æ•°æ®é›†ä¸­å­˜åœ¨çš„ä»»ä½•æ½œåœ¨çš„éçº¿æ€§å…³ç³»**ã€‚

åªéœ€é€šè¿‡ `PolynomialFeatures(degree=n)` æ¥ç”Ÿæˆ $$x$$ çš„ $$n$$ æ¬¡æ–¹ç›´åˆ° 1 æ¬¡æ–¹çš„ç‰¹å¾ï¼Œç„¶åå°†å…¶è¾“å…¥åˆ°çº¿æ€§å›å½’æ¨¡å‹ä¸­è¿›è¡Œæ‹Ÿåˆå³å¯ã€‚

æ¬¡æ•°è¶Šé«˜ï¼Œè®¡ç®—é‡**ä¸ä¸€å®š**æ˜¯è¶Šæ¥è¶Šå¤§çš„ï¼ˆå› ä¸ºçº¿æ€§å›å½’çš„è®¡ç®—å¤æ‚åº¦ä¸»è¦å–å†³äºæ ·æœ¬é‡ $$N$$ å’Œç‰¹å¾æ•° $$P$$ï¼‰ï¼Œ**ä½†æ¨¡å‹å¼•å…¥çš„é£é™©æ˜¯è¶Šæ¥è¶Šé«˜çš„ã€‚**ç†ç”±å¦‚ä¸‹ï¼š

1.è¿‡æ‹Ÿåˆæ˜¯æœ€ä¸»è¦çš„é—®é¢˜ã€‚é«˜æ¬¡å¤šé¡¹å¼èƒ½å¤Ÿ**å®Œç¾**ç©¿è¿‡æ‰€æœ‰è®­ç»ƒæ•°æ®ç‚¹ï¼Œä½†å®ƒå­¦åˆ°çš„æ˜¯æ•°æ®ä¸­çš„**å™ªå£°**å’Œéšæœºè¯¯å·®ï¼Œè€Œä¸æ˜¯æ•°æ®èƒŒåçš„çœŸå®è§„å¾‹ã€‚è¿™ä¼šå¯¼è‡´æ¨¡å‹åœ¨**æ–°çš„ã€æœªè§è¿‡çš„æ•°æ®**ä¸Šçš„æ³›åŒ–èƒ½åŠ›æå·®ã€‚

2.å…±çº¿æ€§ï¼šå½“ $$x$$ çš„æ•°å€¼èŒƒå›´è¾ƒå¤§æ—¶ï¼Œ$$x^2, x^3, \dots, x^n$$ è¿™äº›é«˜æ¬¡é¡¹ä¹‹é—´çš„ç›¸å…³æ€§ä¼šéå¸¸é«˜ï¼Œå¯¼è‡´**ç‰¹å¾å…±çº¿æ€§**ã€‚è¿™ä¼šä½¿å›å½’ç³»æ•° $$\beta_i$$ çš„ä¼°è®¡å˜å¾—éå¸¸ä¸ç¨³å®šï¼Œå¾®å°çš„æ•°æ®å˜åŠ¨éƒ½å¯èƒ½å¯¼è‡´ç³»æ•°çš„å·¨å¤§å˜åŒ–ã€‚

3.è®¡ç®—é‡ã€‚è™½ç„¶å¯¹å•å˜é‡è€Œè¨€è®¡ç®—é‡å¢åŠ ä¸æ˜¾è‘—ï¼Œä½†å¯¹äº**å¤šå˜é‡**ï¼ˆå¦‚ $$x_1, x_2$$ï¼‰çš„é«˜æ¬¡æ¨¡å‹ï¼Œç‰¹å¾æ•°é‡ä¼šå‘ˆæŒ‡æ•°çº§å¢é•¿ï¼Œæ­¤æ—¶è®¡ç®—æ—¶é—´å’Œå†…å­˜æ¶ˆè€—ä¼šæ€¥å‰§å¢åŠ ã€‚

4.éšç€å¤šé¡¹å¼æ¬¡æ•°çš„å¢åŠ ï¼Œæ¨¡å‹çš„ç³»æ•°å˜å¾—éš¾ä»¥è§£é‡Šï¼Œé™ä½äº†æ¨¡å‹çš„å¯è¯»æ€§å’Œå®ç”¨æ€§ã€‚

å› æ­¤ï¼Œåœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬é€šå¸¸é€‰æ‹©ä¸€ä¸ª**è¾ƒä½çš„æ¬¡æ•°ï¼ˆå¦‚ 2 æ¬¡æˆ– 3 æ¬¡ï¼‰**ï¼Œå¹¶åœ¨æ‹Ÿåˆåº¦ï¼ˆ$$R^2$$ï¼‰å’Œæ¨¡å‹å¤æ‚åº¦ä¹‹é—´æ‰¾åˆ°æœ€ä½³çš„å¹³è¡¡ç‚¹ã€‚

å¦å¤–ï¼Œå¦‚æœæ¨¡å‹è¿‡æ‹Ÿåˆï¼ˆåœ¨è®­ç»ƒé›†ä¸Šå­¦ä¹ è¿‡å¤šå™ªå£°ï¼‰ï¼Œä¸ä¸€å®šåœ¨æµ‹è¯•é›†ä¸Šå°±ä¸€å®šå¥½ï¼Œæ‰€ä»¥æ¬¡æ•°ä¸€å®šä¸æ˜¯è¶Šé«˜è¶Šå¥½ã€‚ï¼ˆè™½ç„¶æ¬¡æ•°è¶Šé«˜ï¼Œæ¨¡å‹å¯¹äºè®­ç»ƒé›†çš„æ‹Ÿåˆå°±è¶Šå¥½ï¼‰ã€‚è¿™ä¹Ÿæ˜¯ä¸€ç§trade off

# 4.èŠ±å¼ç©æ³•-æŠ—å™ªå£°

è€ƒè™‘è¿™æ ·çš„é—®é¢˜ï¼ŒåŸæ¥æœ‰æ•°æ®$$[X, y]$$ï¼Œç°åœ¨å¼•å…¥éšæœºäº§ç”Ÿçš„æ•°æ®$$X_2$$ï¼Œå°±æœ‰äº†$$[X_1, X_2, y]$$ï¼Œè¯·é—®æœ€åå¤šå…ƒçº¿æ€§å›å½’æ‹Ÿåˆçš„$$\hat{y}=w_1X_1+w_2X_2+b$$ä¸­ï¼Œ$$w_2$$çš„å–å€¼æ˜¯ä¸æ˜¯0ï¼Ÿ

ç»“è®ºï¼š$$w_2$$ çš„**æœŸæœ›**å€¼æ˜¯0ï¼Œä½†**å®é™…**å€¼å¯èƒ½ä¸ä¸º0

$$X_2$$ æ˜¯å®Œå…¨éšæœºç”Ÿæˆçš„ï¼ˆä¾‹å¦‚ï¼Œæ¥è‡ª $$\mathcal{N}(0, 1)$$ æˆ– $$\mathcal{U}(a, b)$$ åˆ†å¸ƒï¼‰ã€‚$$X_2$$ ä¸åŸå§‹ç‰¹å¾ $$X_1$$ **å®Œå…¨ç‹¬ç«‹**ï¼Œå¹¶ä¸”ä¸ç›®æ ‡å˜é‡ $$y$$ **å®Œå…¨ç‹¬ç«‹**ï¼ˆå³å®ƒä»¬ä¹‹é—´æ²¡æœ‰çœŸå®çš„çº¿æ€§å…³ç³»ï¼‰ã€‚

åœ¨çº¿æ€§å›å½’ä¸­ï¼Œæ¨¡å‹çš„ç³»æ•° $$w_i$$ æ—¨åœ¨æœ€å°åŒ–æ®‹å·®å¹³æ–¹å’Œï¼ˆæœ€å°äºŒä¹˜æ³•ï¼‰ã€‚å¦‚æœ $$X_2$$ ä¸ $$y$$ ä¹‹é—´æ²¡æœ‰çœŸå®å…³ç³»ï¼Œé‚£ä¹ˆåœ¨**æ— é™å¤§çš„æ ·æœ¬é›†**ä¸Šï¼Œæœ€å°åŒ–æ®‹å·®å¹³æ–¹å’Œçš„æœ€ä½³è§£æ˜¯è®¾ç½® $$w_2$$ ä¸º $0$ï¼Œå› ä¸ºä»»ä½•éé›¶çš„ $$w_2$$ åªä¼šå¼•å…¥é¢å¤–çš„ã€ä¸å¯è§£é‡Šçš„è¯¯å·®ã€‚

$$E[w_2] = 0$$

**å®é™…åŸå›  (æœ‰é™æ ·æœ¬é›†å’Œéšæœºè¯¯å·®)ï¼š**

åœ¨ä»»ä½•**æœ‰é™çš„å®é™…æ•°æ®é›†**ä¸Šï¼Œå³ä½¿ $$X_2$$ æ˜¯çº¯éšæœºçš„ï¼Œå®ƒä¹Ÿä¼šç”±äº**æŠ½æ ·è¯¯å·®ï¼ˆSampling Errorï¼‰å’Œéšæœºå™ªå£°**è€Œå‡ºç°ä»¥ä¸‹æƒ…å†µï¼š

- **å¶ç„¶ç›¸å…³æ€§ (Spurious Correlation)ï¼š** éšæœºç”Ÿæˆçš„ $$X_2$$ ä¸ç›®æ ‡å˜é‡ $$y$$ ä¹‹é—´ä¼šå­˜åœ¨å¾®å¼±ã€å¶ç„¶çš„éé›¶ç›¸å…³æ€§ã€‚æœ€å°äºŒä¹˜æ³•ä¼šè¯•å›¾åˆ©ç”¨è¿™ç§å¾®å¼±çš„ã€éšæœºçš„ç›¸å…³æ€§æ¥è¿›ä¸€æ­¥ç¨å¾®é™ä½æ®‹å·®å¹³æ–¹å’Œã€‚
- **å™ªå£°å¸æ”¶ï¼š** $$X_2$$ å¯èƒ½ä¼šâ€œå¸æ”¶â€æ¨¡å‹ä¸­æœªè¢« $$X_1$$ è§£é‡Šçš„**éšæœºå™ªå£°**éƒ¨åˆ†ã€‚æ¨¡å‹å¯èƒ½ä¼šå°† $$w_2$$ è®¾ç½®ä¸ºä¸€ä¸ªå¾®å°çš„éé›¶å€¼ï¼Œä»¥åˆ©ç”¨ $$X_2$$ çš„éšæœºæ³¢åŠ¨æ¥å¾®è°ƒæ‹Ÿåˆï¼Œä½¿ $$\sum (y - \hat{y})^2$$ ç•¥å¾®å‡å°ã€‚

åœ¨å®é™…è¿è¡Œä»£ç æ—¶ï¼Œæ‚¨ä¼šå‘ç°æ‹Ÿåˆå¾—åˆ°çš„ $$w_2$$ æ˜¯ä¸€ä¸ª**æ¥è¿‘äº 0 çš„éé›¶å°æ•°**

---

ä¸‹é¢æ˜¯æ¨¡æ‹Ÿçš„ä»£ç ï¼š

```python
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

# --- 1. åˆ›å»ºæ¨¡æ‹Ÿæ•°æ® ---
np.random.seed(42)  # è®¾ç½®éšæœºç§å­ä»¥ä¿è¯ç»“æœå¯é‡ç°
N_SAMPLES = 1000    # æ ·æœ¬æ•°é‡
TRUE_W1 = 5.0       # X1 çš„çœŸå®ç³»æ•°
TRUE_B = 10.0       # çœŸå®æˆªè·

# åŸå§‹ç‰¹å¾ X1 (ä¸ y æœ‰å…³)
X1 = np.random.rand(N_SAMPLES, 1) * 10 

# ç›®æ ‡å˜é‡ y (åŒ…å«éšæœºå™ªå£°)
# y = 5*X1 + 10 + å™ªå£°
y = TRUE_W1 * X1.flatten() + TRUE_B + np.random.normal(0, 2, N_SAMPLES)

# --- 2. å¼•å…¥éšæœºç‰¹å¾ X2 ---
# X2 æ˜¯ä¸€ä¸ªå®Œå…¨éšæœºçš„ç‰¹å¾ï¼Œä¸ X1 å’Œ y å‡ç‹¬ç«‹
X2 = np.random.normal(0, 5, (N_SAMPLES, 1))

# --- 3. ç»„åˆç‰¹å¾çŸ©é˜µ ---
# ç°åœ¨çš„ç‰¹å¾çŸ©é˜µ X åŒ…å« X1 å’Œ X2
# X.shape -> (1000, 2)
X_combined = np.hstack((X1, X2))

print(f"åŸå§‹ç‰¹å¾ X1 å½¢çŠ¶: {X1.shape}")
print(f"éšæœºç‰¹å¾ X2 å½¢çŠ¶: {X2.shape}")
print(f"ç»„åˆç‰¹å¾ X å½¢çŠ¶: {X_combined.shape}")

# --- 4. è®­ç»ƒå¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹ ---
model = LinearRegression()
model.fit(X_combined, y)

# --- 5. æ‰“å°ç»“æœ ---
w1_fit = model.coef_[0]
w2_fit = model.coef_[1]
b_fit = model.intercept_

print("\n--- æ¨¡å‹æ‹Ÿåˆç»“æœ ---")
print(f"ç‰¹å¾ X1 çš„çœŸå®ç³»æ•° (w1): {TRUE_W1:.4f}")
print(f"æ‹Ÿåˆå¾—åˆ°çš„ X1 ç³»æ•° (w1): {w1_fit:.4f}")
print("-" * 30)
print(f"éšæœºç‰¹å¾ X2 çš„çœŸå®ç³»æ•° (w2): 0.0000")
print(f"æ‹Ÿåˆå¾—åˆ°çš„ X2 ç³»æ•° (w2): {w2_fit:.8f}")
print("-" * 30)
print(f"æˆªè·çš„çœŸå®å€¼ (b): {TRUE_B:.4f}")
print(f"æ‹Ÿåˆå¾—åˆ°çš„æˆªè· (b): {b_fit:.4f}")
```

<img src="https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027204319656.png" alt="image-20251027204319656" style="zoom:50%;" />

ä¸Šé¢çš„ä¾‹å­å¯ä»¥è¯´æ˜**çº¿æ€§å›å½’å…·æœ‰æŠ—å™ªå£°çš„èƒ½åŠ›ã€‚**

# 5.èŠ±å¼ç©æ³•-å…±çº¿æ€§

å‡è®¾æˆ‘ä»¬ä»åŸå§‹ç‰¹å¾ $$x_1$$ æ„é€ äº†ä¸¤ä¸ªå®Œå…¨ç›¸åŒçš„ç‰¹å¾ $$X_{1a} = x_1$$å’Œ $$X_{1b} = x_1$$ï¼Œå¹¶å°†å®ƒä»¬ä»£å…¥æ¨¡å‹ï¼š

$$y = w_{1a} X_{1a} + w_{1b} X_{1b} + w_0$$

è¿™ç§å¤åˆ¶ç‰¹å¾çš„æ“ä½œåˆ›å»ºäº†**å®Œç¾çš„å…±çº¿æ€§ï¼ˆPerfect Collinearityï¼‰**ï¼Œå³ç‰¹å¾ $$X_{1a}$$ å’Œ $$X_{1b}$$ ä¹‹é—´çš„ç›¸å…³ç³»æ•°ä¸º1ã€‚

çº¿æ€§å›å½’æ¨¡å‹ï¼ˆæœ€å°äºŒä¹˜æ³•ï¼‰çš„ä¼˜åŒ–ç›®æ ‡æ˜¯æ‰¾åˆ°æœ€ä¼˜çš„æƒé‡ç»„åˆ $$(w_{1a}, w_{1b})$$ï¼Œä½¿å¾—æ®‹å·®å¹³æ–¹å’Œæœ€å°ã€‚

å‡è®¾åŸå§‹çš„çœŸå®å…³ç³»æ˜¯ $$y = W_{\text{true}} x_1 + w_0$$ã€‚

å½“å¼•å…¥ $$X_{1a}$$ å’Œ $$X_{1b}$$ æ—¶ï¼Œæ¨¡å‹è¦æ‹Ÿåˆçš„æ˜¯ï¼š

$$y = w_{1a} x_1 + w_{1b} x_1 + w_0 = (w_{1a} + w_{1b}) x_1 + w_0$$

**é—®é¢˜åœ¨äºï¼š** åªè¦ä¿æŒç³»æ•°ä¹‹å’Œ $$(w_{1a} + w_{1b})$$ ç­‰äºåŸå§‹çš„çœŸå®ç³»æ•° $$W_{\text{true}}$$ï¼Œæ¨¡å‹çš„é¢„æµ‹ç»“æœ $$\hat{y}$$ å°±ä¸ä¼šæ”¹å˜ï¼Œæ®‹å·®å¹³æ–¹å’Œï¼ˆRSSï¼‰ä¹Ÿä¿æŒä¸å˜ã€‚

å› æ­¤ï¼Œæ¨¡å‹æ— æ³•ç¡®å®š $$w_{1a}$$ å’Œ $$w_{1b}$$ çš„å…·ä½“å–å€¼ï¼Œåªè¦æ»¡è¶³ï¼š

$$w_{1a} + w_{1b} = W_{\text{true}}$$

å³ï¼Œå­˜åœ¨**æ— ç©·å¤šç»„**è§£ï¼Œå®ƒä»¬éƒ½èƒ½æœ€å°åŒ– RSSã€‚è¿™ä½¿å¾—ç³»æ•°çŸ©é˜µåœ¨æ•°å­¦ä¸Šæ˜¯**å¥‡å¼‚**çš„ï¼ˆä¸å¯é€†ï¼‰ï¼Œå¯¼è‡´æœ€å°äºŒä¹˜è§£å˜å¾—ä¸ç¡®å®šæˆ–ä¸ç¨³å®šã€‚

è¿™ç§ç°è±¡è¯´æ˜äº†çº¿æ€§å›å½’çš„ä¸€ä¸ªé‡è¦ç‰¹æ€§ï¼š

**çº¿æ€§å›å½’å¯¹ç‰¹å¾é—´çš„å…±çº¿æ€§é«˜åº¦æ•æ„Ÿã€‚å½“ç‰¹å¾ä¹‹é—´å­˜åœ¨é«˜åº¦ç›¸å…³æ€§æ—¶ï¼Œæ¨¡å‹çš„ç³»æ•°ä¼šè¢«â€œæ‘Šæ´¾â€ï¼Œå˜å¾—ä¸ç¨³å®šã€éš¾ä»¥è§£é‡Šï¼Œå¹¶ä¸”åœ¨ä¸åŒæ•°æ®é›†ä¸Šè¿è¡Œæ—¶ï¼Œç³»æ•°çš„å–å€¼å¯èƒ½ä¼šå‘ç”Ÿå‰§çƒˆå˜åŒ–ã€‚**

å› æ­¤ï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¤„ç†å…±çº¿æ€§æ˜¯ç‰¹å¾å·¥ç¨‹çš„ä¸€ä¸ªé‡è¦ç¯èŠ‚ï¼Œå¸¸ç”¨çš„è§£å†³æ–¹æ³•åŒ…æ‹¬ï¼š

1. **ç‰¹å¾é€‰æ‹©ï¼š** åˆ é™¤é‡å¤æˆ–é«˜åº¦ç›¸å…³çš„ç‰¹å¾ï¼ˆä¾‹å¦‚ï¼Œåœ¨è¿™ä¸ªä¾‹å­ä¸­åˆ é™¤ $$X_{1b}$$ï¼‰ã€‚
2. **æ­£åˆ™åŒ–ï¼š** ä½¿ç”¨ **å²­å›å½’ (Ridge Regression)** æˆ– **Lasso å›å½’**ï¼Œå®ƒä»¬é€šè¿‡å¼•å…¥æƒ©ç½šé¡¹æ¥ç¨³å®šå’Œçº¦æŸç³»æ•°ï¼Œå‡è½»å…±çº¿æ€§çš„å½±å“ã€‚

---

**åŠ å™ªå£°å¯¹äºçº¿æ€§å›å½’æ²¡æœ‰ä¼¤å®³ï¼ŒåŠ ç›¸å…³æ€§å¼ºçš„å˜é‡ä¹Ÿä¸ä¼šå¸¦æ¥å¸®åŠ©ã€‚**è¿™æ˜¯çº¿æ€§å›å½’å¾ˆé‡è¦çš„ç‰¹ç‚¹ã€‚

