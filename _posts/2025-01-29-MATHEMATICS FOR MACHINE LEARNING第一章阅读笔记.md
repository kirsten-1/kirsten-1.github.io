---
layout: post
title: "MATHEMATICS FOR MACHINE LEARNING第一章阅读笔记"
subtitle: "chap1 Introduction and Motivation"
date: 2025-01-29
author: "Hilda"
header-img: "img/post-bg-2015.jpg"
tags:
- 书籍阅读
---

<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG">
</script>

## MATHEMATICS FOR MACHINE LEARNING第一章阅读笔记

<img src="https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20250128185858695.png" alt="image-20250128185858695" style="zoom:50%;" />

## chap1 Introduction and Motivation

机器学习是关于设计能够自动从数据中提取有价值信息的算法。这里的重点在于“自动(`automatic`)”，也就是说，机器学习关注的是可以应用于许多数据集的通用方法(`general-purpose methodologies`)，同时产生有意义的结果。机器学习的核心有三个概念：数据(`data`)、模型(`model`)和学习(`learning`)。

由于机器学习本质上是数据驱动(`data driven`)的，数据处于机器学习的核心位置。机器学习的目标是设计通用的方法，从数据中提取有价值的模式(`patterns`)，理想情况下不需要太多领域特定的专业知识。例如，给定大量文档（例如，许多图书馆中的书籍），机器学习方法可以自动找到在这些文档中共有的相关主题（Hoffman等人，2010）。为了实现这一目标，我们设计的**模型**通常与生成数据的过程相关，类似于我们所给定的数据集。例如，在回归设置(`regression setting`)中，模型会描述一个将输入映射到实值输出的函数。引用Mitchell（1997）的话来说：如果模型在考虑数据后在给定任务(`task`)上的表现(`performance`)有所提高，则认为该模型是从数据中学习的。目标是找到能够很好地推广到尚未见过的数据的好模型，这些数据可能是我们在未来关心的。学习可以被理解为通过优化模型参数来自动发现数据中的模式和结构的一种方式。

> 上面这一段，分别阐释了3个重要概念：data,model,learning

为什么要学习机器学习中的数学？虽然机器学习已经取得了很多成功案例，并且有现成的软件可以设计和训练复杂灵活的机器学习系统，但我们认为机器学习的数学基础对于理解更复杂的机器学习系统所基于的基本原理非常重要。理解这些原理有助于创建新的机器学习解决方案，理解和调试现有方法，并了解我们所使用的方法论固有的假设和局限性。

# 1.1 为直觉寻找词汇Finding Words for Intuitions

> 这一节重点解释三个概念：数据(`data`)、模型(`model`)和学习(`learning`)

我们在机器学习中经常面临的一个挑战是概念和术语是模糊的，机器学习系统的特定组件可以抽象为不同的数学概念。例如，“算法(`algorithm`)”这个词在机器学习的背景下至少有两种不同的含义。在第一种意义上，我们使用“机器学习算法(`machine learning algorithm`)”这个短语来指一个基于输入数据进行**预测(`makes predictions`)**的系统。我们把这些算法称为**预测器(`predictor`)**。在第二种意义上，我们使用相同的短语“机器学习算法”来指一个**调整(`adapts`)**预测器内部某些参数的系统，使其在未来未见过的输入数据上表现良好。这里我们将这种适应过程称为**训练(`training`)系统**。

本书不会解决模糊性问题，但我们希望在一开始就强调，根据上下文的不同，相同的表达可能有不同的含义。然而，我们努力使上下文足够清晰，以减少模糊性的程度。

本书的第一部分介绍了讨论机器学习系统的三个主要组成部分所需的基本数学概念和基础：数据(`data`)、模型(`model`)和学习(`learning`)。我们将在本节简要概述这些组成部分，并在第8章再次回顾它们，在此之前我们将讨论必要的数学概念。

> 本书分为2个部分：
>
> Part I：Mathematical Foundations
>
> Part II：Central Machine Learning Problems

并非所有数据都是数值型的，但通常将数据视为数字格式是有用的。在本书中，我们假设数据已经适当地转换为适合输入计算机程序的数值表示形式。因此，我们将**数据视为向量(`data as vectors`)**。作为词语微妙性的另一个例证，至少有三种不同的方式来思考向量：**向量可以被视为一组数字（计算机科学的观点，也可以简单理解为数组），向量可以被视为带有方向和大小的箭头（物理学的观点），以及向量可以被视为遵循加法和缩放规则的对象（数学的观点）。**

一个**模型(`model`)**通常用于描述生成数据的过程，类似于手头的数据集。因此，好的模型也可以被视为真实（未知）数据生成过程的简化版本，捕捉对建模数据和提取隐藏模式相关的方面。一个好的模型可以用来预测现实世界中会发生什么，而无需进行实际的实验。

我们现在来到问题的核心，机器学习中的**学习(`learning`)**组件。假设我们有一个数据集和一个合适的模型。训练模型意味着使用可用的数据来优化模型的一些参数，以使模型在预测训练数据方面的表现达到最优，这是通过一个评估函数来衡量的。大多数训练方法可以被看作是类似于爬山以到达山顶的方法。在这个比喻中，山顶对应于某个可以达到期望的性能指标效用函数的最大值。然而，在实际应用中，我们更关注模型在未见过的数据上的表现。在已经见过的数据（训练数据）上表现良好可能只意味着我们找到了一种很好的方法来记忆这些数据。然而，这可能无法很好地推广到未见过的数据，并且在实际应用中，我们经常需要让机器学习系统面对它之前未曾遇到过的情况。让我们总结一下本书中涵盖的机器学习的主要概念：

- 我们将**数据表示为向量(`data as vectors`)**。
- 我们选择一个合适的**模型(`model`)**，要么使用**概率(`probabilistic`)**视角，要么使用**优化(`optimization`)**视角。
- 我们通过使用数值优化方法从可用数据中学习，目标是使模型在未用于训练的数据上表现良好。

---

# 1.2 阅读本书的两种方式

- 自下而上(`Bottom-up`)：从基础概念逐步构建到更高级的概念。这种方法在数学等技术领域中通常是首选。这种策略的优点是读者在任何时候都可以依赖他们之前学到的概念。不幸的是，对于实践者来说，许多基础概念本身并不特别有趣，缺乏动力意味着大多数基础定义很快就会被遗忘。
- 自上而下(`Top-down`)：从实际需求出发，逐步深入到更基本的要求。这种目标驱动的方法的优点是读者在任何时候都知道为什么需要研究某个特定的概念，并且有一条明确的知识路径。这种方法的缺点是知识可能建立在不稳固的基础上，读者必须记住一组他们无法理解的术语。

---

我们决定以模块化的方式编写这本书，将基础的（数学）概念与应用分开，以便读者可以选择不同的阅读方式。本书分为两部分，第一部分奠定数学基础，第二部分则将第一部分的概念应用于一组基本的机器学习问题，这些问题构成了机器学习的四大支柱，如图1.1所示：回归(`regression`)、降维(`dimensionality reduction`)、密度估计(`density estimation`)和分类(`classification`)。第一部分的章节大多基于前一章的内容，但如有必要，可以跳过某一章并回溯阅读。第二部分的章节关联较为松散，可以按任意顺序阅读。书中有很多前后呼应的在书的两部分之间的提示，将数学概念与机器学习算法联系起来。

<img src="https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20250128195046632.png" alt="机器学习的基础和四大支柱"  style="zoom:50%;" />

当然，阅读这本书的方法不止两种。大多数读者采用自上而下和自下而上相结合的方法进行学习，有时会在尝试更复杂的概念之前先打好基本的数学基础，但也根据机器学习的应用来选择主题。

------

**第一部分是关于数学的。**

本书中讨论的机器学习四大支柱（见图1.1）需要坚实的数学基础，这部分内容在第一部分中进行了详细阐述。

**线性代数(`linear algebra`)**:我们将数值数据表示为**向量(`vectors`)**，将这样的数据表表示为**矩阵(`matrix`)**。向量和矩阵的研究被称为线性代数(`linear algebra`)，我们在第2章介绍线性代数。向量集合作为矩阵的表示也在该章节中描述。

**解析几何(`analytic geometry`)**:给定两个向量，表示现实世界中的两个**对象(`objects`)**，我们希望对其**相似性(`similarity`)**做出判断。我们的想法是，相似的向量应该被机器学习算法（预测器`predictor`）预测为具有相似的输出。为了形式化向量之间的相似性概念，我们需要引入操作，这些操作以两个向量作为输入，并返回一个表示它们相似性的数值。相似性和**距离(`distances`)**的构建是解析几何的核心内容，并在第三章中进行了讨论。

**矩阵分解(`matrix decomposition`)**:在第4章中，我们介绍了一些关于矩阵和矩阵分解的基本概念。矩阵上的某些操作在机器学习中极为有用，它们使得数据的解释更加直观，并且能够实现更高效的学习。

**概率论(`probability theory`)**:我们通常认为数据是一些真实底层信号的嘈杂观测。我们希望借助机器学习能够从噪声中识别出信号。这要求我们有一种量化“噪声”含义的语言。我们通常也希望拥有能够预测的模型，这些模型可以允许我们表达某种不确定性，例如，量化我们在某个特定测试数据点上对预测值的信心。**不确定性量化(`Quantification of uncertainty`)**属于概率论的范畴，而概率论在第六章中有所介绍。

**矢量微积分(`vector calculus`)和优化(`optimization`)**:为了训练机器学习模型，我们通常寻找能使某些性能指标最大化的参数。许多优化技术需要**梯度(`gradient`)**的概念，它告诉我们搜索解决方案的方向。第5章讨论了向量微积分，并详细介绍了梯度的概念，随后在第7章中，我们将使用这些概念讨论如何通过优化找到函数的**极大值/极小值(`maxima/minima`)**。

----

**第二部分是关于机器学习的内容。**

本书的第二部分介绍了机器学习的四大支柱，如图1.1所示。我们阐述了书中第一部分引入的数学概念如何成为每个支柱的基础。大致来说，章节按照难度递增的顺序排列。

在第八章，我们以数学方式重新阐述了机器学习的三个组成部分（数据、模型和参数估计）。此外，我们还提供了一些构建实验设置的指导原则，以防止对机器学习系统的评估过于乐观。回顾一下，目标是建立一个在未见过的数据上表现良好的预测器。

**线性回归(`linear regression`)**:在第九章，我们将详细探讨线性回归，其中我们的线性回归目标是找到将输入 ( \$\$x \in \mathbb{R}^D $$) 映射到相应观测函数值 ( \$$y \in \mathbb{R} $$) 的函数，我们可以将其解释为各自输入的**标签(`label`)**。我们将讨论通过**最大似然估计(`maximum likelihood estimation`)**和**最大后验估计(`maximum a posteriori estimation`)**进行的经典模型拟合`fitting`（参数估计`parameter estimation`），以及**贝叶斯线性回归(`Bayesian linear regression`)**，在贝叶斯线性回归中，我们**对参数进行积分(`integrate the parameters out`)**而不是优化它们。

**降维(`dimensionality reduction`)**:第十章专注于降维，这是图1.1中的第二个支柱，采用**主成分分析方法(`principal component analysis,PCA`)**。降维的主要目标是找到高维数据\$$x \in \mathbb{R}^D $$的紧凑、低维表示形式，这通常比原始数据更容易分析。与回归不同，降维只关注建模数据——数据点 x 没有任何标签。

**密度估计(`density estimation`)**:在第11章，我们将进入第三个支柱：密度估计。密度估计的目标是找到一个能够描述给定数据集的**概率分布(`probability distribution`)**。我们将专注于**高斯混合模型(`Gaussian mixture models`)**，并讨论一种**迭代方案(` iterative scheme`)**来确定该模型的参数。与降维类似，数据点\$$x \in \mathbb{R}^D $$没有对应的标签。然而，我们并不寻求数据的低维表示。相反，我们关注的是能够描述数据的**密度模型(`density model `)**。

**分类(`classification`)**:第12章以对第四根支柱——“分类”的深入讨论结束本书。我们将讨论在**支持向量机(`support vector machines`)**的背景下分类问题。类似于回归（第9章），我们有输入x和相应的标签y。然而，不同于回归中标签是实数值的情况，分类中的标签是整数，这需要特别注意。

# 1.3 练习与反馈

我们在第一部分提供了一些练习，这些练习主要可以通过纸笔完成。对于第二部分，我们提供了编程教程（jupyter notebooks），以探索我们在本书中讨论的机器学习算法的一些特性。

我们非常感谢剑桥大学出版社对我们目标的大力支持，即通过免费提供这本书的下载来普及教育和学习。读者可以在 https://mml-book.com 获取教程、勘误表和额外资料。错误报告和反馈也可以通过上述网址提交。





