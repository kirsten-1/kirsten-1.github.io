---
layout: post
title: "ollama工具-下载安装快速上手"
subtitle: "介绍本地大模型运行器Ollama，说明了如何安装、通过命令行下载并运行Gemma等模型进行交互，以及如何列出、删除模型。还演示了直接提问、查看效率和使用llava分析图片功能"
date: 2025-04-07
author: "Hilda"
header-img: "img/post-bg-2015.jpg"
tags:
- ollama工具
---


<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG">
</script>



简单来说Ollama就是一个大模型的管理平台，**"LLM 运行器"** 或 **"本地 LLM 管理器"**

> `Ollama` 是一个基于 Go 语言开发的简单易用的本地大语言模型运行框架。可以将其类比为 docker，事实上它也的确制定了类 docker 的一种模型应用标准
>
> 在管理模型的同时，它还基于 Go 语言中的 Web 框架 [gin](https://github.com/gin-gonic/gin)提供了一些 Api 接口，让你能够像跟 OpenAI 提供的接口那样进行交互。

几个关键点：

- 允许用户下载并在自己的 Mac、Windows (通过 WSL) 或 Linux 电脑上运行各种强大的开源 LLMs，例如DeepSeek，llama等。
- Ollama 是一个开源项目，代码托管在 GitHub 上，社区活跃，发展迅速
- 提供了一个简单易用的**命令行工具**（也有webUI）来管理（下载、删除、列出）模型和运行模型进行交互式聊天
- 当你运行一个模型时，Ollama 会在本地启动一个 API 服务器（默认在 11434 端口）。这使得其他应用程序（如自定义脚本、Web 界面、开发工具等）可以通过标准的 REST API 与本地运行的 LLM 进行交互，通常兼容 OpenAI 的 API 格式，方便集成。
- Ollama 维护了一个包含许多流行开源模型的库，用户可以方便地从中选择和下载。用户也可以导入自定义模型
- 支持利用 GPU（如果你的系统有兼容的 NVIDIA GPU 或 Apple Silicon）进行加速，以提高模型推理的速度。当然，它也可以仅在 CPU 上运行（速度会慢很多）。------**灵活：没有GPU就用CPU**

[官网链接](https://ollama.com/)

<img src="https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20250404204402314.png" alt="image-20250404204402314" style="zoom:50%;" />

直接在官网根据不同的操作系统下载与安装即可。

# Ollama支持的模型

https://ollama.com/search列出了支持的模型。

例如有[gemma3](https://ollama.com/library/gemma3)，[qwq](https://ollama.com/library/qwq)，[deepseek-r1](https://ollama.com/library/deepseek-r1)，[llama3.3](https://ollama.com/library/llama3.3)，[phi4](https://ollama.com/library/phi4)

<img src="https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20250404210435534.png" alt="image-20250404210435534" style="zoom:50%;" />

7B表示70亿的参数，以此类推。

选择相应的模型参数数量级之后通过右侧的命令进行下载：

<img src="https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20250404221750593.png" alt="image-20250404221750593" style="zoom:50%;" />

注：ollama官方给出的参考如下：

如果下载7b，建议本机拥有8G内存；如果下载13b，建议本机拥有16G内存；如果下载33b，建议本机拥有32G内存；如果下载70b，建议本机拥有128G内存

下载建议：

如果是语言类模型，建议Gemma，DeepSeek，Qwen

如果是视觉类(图片)，建议llava，Phi，minicpm-v

# Ollama 快速上手

可以通过“ollama run +模型”来运行模型，这里以运行“gemma”模型为例演示如何使用Ollama。

打开终端窗口，输入“ollama run gemma:2b”运行Gemma模型（或者官网看到的其他模型的运行命令），如果Ollama没有该模型，会自动下载模型后再运行，后续运行不会重复下载模型。(下面这个命令是7b的)

```
ollama run gemma
```

<img src="https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20250407142832882.png" alt="image-20250407142832882" style="zoom:50%;" />

Ollama支持命令行方式使用模型，也支持API方式使用模型，这里先演示命令行方式使用模型，API方式使用模型参考后文。

<img src="https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20250407153958877.png" alt="image-20250407153958877" style="zoom:50%;" />

可以在与模型多次对话后输入“/clear”来清除上下文信息。最后使用ctrl+d 或者 输入` /bye `退出Ollama。

注：

通过`ollama list`查看ollama已经下载过的模型有哪些：

<img src="https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20250407155429937.png" alt="image-20250407155429937" style="zoom:50%;" />

删除某个模型：

```
ollama rm gemma:latest
```

<img src="https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20250407155522970.png" alt="image-20250407155522970" style="zoom:50%;" />

补充其他命令：

模型会话中支持多行输入，可以使用`“"""”`将文本括起来，进行对话。

```java
>>>"""
... 请给我讲一个故事
... 不超过100字
... """
<think>
</think>
当然可以，请听一下这个有趣的故事：
... ...
>>>/bye
```

在运行模型时，可以将prompt（提示词）作为参数传入给模型，无需进入与模型对话的交互式窗口即可获取模型返回内容。如下：

```
ollama run deepseek-r1:1.5b "你是谁"
<think>
</think>
您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。
```

执行模型时，可以加入“--verbose”来查看每次对话后模型执行的效率细节。

```
ollama run deepseek-r1:1.5b --verbose
>>> 你是谁
<think>

</think>

您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。

total duration:       578.5214ms 
load duration:        28.5914ms
prompt eval count:    5 token(s)
prompt eval duration: 37.5937ms
prompt eval rate:     133.00 tokens/s
eval count:           40 token(s)
eval duration:        511.8619ms
eval rate:            78.15 tokens/s

```

total duration：表示整个运行过程所花费的总时间。

load duration：表示加载模型所花费的时间，单位为毫秒。

prompt eval count：表示在处理提示（prompt）时评估的标记（token）数量。

prompt eval duration：表示评估提示所花费的时间，单位为毫秒。

prompt eval rate：表示评估提示时的速度，以每秒处理的标记数量表示。

eval count：表示在生成响应时评估的标记数量。

eval duration：表示生成响应所花费的时间，单位为毫秒。

eval rate：表示生成响应时的速度，以每秒处理的标记数量表示。

---

不仅仅可以与模型进行对话，也可以让模型分析文本文件及图片内容。这里下载llava模型并进行图片内容分析。

```java
#拉取模型
ollama pull llava:7b

#在C盘下准备pic.png图片，并通过该模型分析图片内容
C:\Users\wubai>ollama run llava:7b "请中文回复图片中是什么内容？ C:\pic1.png"
Added image 'C:\pic1.png'
 这张照片显示了一名人，戴着头部上的葫叶服饰，手中也戴着一些装饰。他们身穿的衣服有多彩的元素，以及一些华佩样式的鞋和裙。照片背景是一个山谷场景，可以看到远处的山岭、天空和白云。整体感觉像是一位在中国农村地区的人，戴着传统服饰，与自然环境相轨。

```

