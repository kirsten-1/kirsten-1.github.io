<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hilda</title>
    <description>这里是 Hilda 的个人博客，与你一起发现更大的世界 | 要做一个有 swag 的程序员</description>
    <link>https://kirsten-1.github.io/</link>
    <atom:link href="https://kirsten-1.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sat, 22 Nov 2025 07:04:01 +0000</pubDate>
    <lastBuildDate>Sat, 22 Nov 2025 07:04:01 +0000</lastBuildDate>
    <generator>Jekyll v4.4.1</generator>
    
      <item>
        <title>【AI思想启蒙10】朴素贝叶斯模型：简单背后蕴含的有效 </title>
        <description>&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG&quot;&gt;
&lt;/script&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251121165449435.png&quot; alt=&quot;image-20251121165449435&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1先验概率和后验概率&quot;&gt;1.先验概率和后验概率&lt;/h1&gt;

&lt;p&gt;先验概率是根据经验得到的，比如看摊位买的西瓜，大致认为60%的概率西瓜是好的。先验概率不需要样本数据，不受任何条件的影响。不根据其他，就根据常识大致判断。&lt;/p&gt;

&lt;p&gt;而后验概率就类似于看瓜蒂脱落与否判断西瓜是否是好的。&lt;/p&gt;

&lt;p&gt;计算后验概率就是朴素贝叶斯最核心的一步。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;联合概率&lt;/strong&gt;是几个事件同时发生的概率。例如P(瓜熟， 瓜蒂脱落)就是一个联合概率&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P (瓜熟，瓜蒂脱落) =P (瓜熟|瓜蒂脱落) *P (瓜蒂脱落)&lt;/code&gt;&lt;/p&gt;

  &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P(瓜熟，瓜蒂脱落) =P(瓜蒂脱落|瓜熟) *P(瓜熟)&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;但是要求的是$$P(\text{瓜熟&lt;/td&gt;
      &lt;td&gt;瓜蒂脱落})$$：&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$$P(\text{瓜熟&lt;/td&gt;
      &lt;td&gt;瓜蒂脱落}) \times P(\text{瓜蒂脱落}) = P(\text{瓜蒂脱落&lt;/td&gt;
      &lt;td&gt;瓜熟}) \times P(\text{瓜熟})$$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$$P(\text{瓜熟&lt;/td&gt;
      &lt;td&gt;瓜蒂脱落}) = \frac{P(\text{瓜蒂脱落&lt;/td&gt;
      &lt;td&gt;瓜熟}) \times P(\text{瓜熟})}{P(\text{瓜蒂脱落})}$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;因为$$P(\text{瓜蒂脱落&lt;/td&gt;
      &lt;td&gt;瓜熟})\(和\)P(\text{瓜熟})\(是已知的，所以只需要求出\)P(\text{瓜蒂脱落})$$即可。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;而&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P(瓜蒂脱落) = P(瓜蒂脱落|瓜熟) * P(瓜熟) + P(瓜蒂脱落|瓜生) * P(瓜生)&lt;/code&gt;(全概率公式)&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;若已知P(瓜熟)=0.6，P(瓜蒂脱落&lt;/td&gt;
      &lt;td&gt;瓜生)=0.，P(瓜生)=0.4，P(瓜蒂脱落&lt;/td&gt;
      &lt;td&gt;瓜熟)=0.8&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;则&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P(瓜熟/瓜蒂脱落) = (0.8*0.6) / (0.8*0.6+0.4*0.4) =0.75&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;如果特征很多（各个特征之间是独立的），那么可以这么计算：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251121164242437.png&quot; alt=&quot;image-20251121164242437&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以上就是朴素贝叶斯算法的一个应用。&lt;/p&gt;

&lt;h1 id=&quot;2朴素贝叶斯算法&quot;&gt;2.朴素贝叶斯算法&lt;/h1&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;朴素贝叶斯（Naive Bayes）是一种基于&lt;strong&gt;贝叶斯定理&lt;/strong&gt;的&lt;strong&gt;生成模型&lt;/strong&gt;。它通过计算后验概率 $$P(\text{类别}&lt;/td&gt;
      &lt;td&gt;\text{特征})$$ 来进行分类。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;贝叶斯公式是其理论基础：&lt;/p&gt;

\[P(\text{类别}| \text{特征}) = \frac{P(\text{特征}| \text{类别}) \times P(\text{类别})}{P(\text{特征})}\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;\(P(\text{类别})\) (先验概率):&lt;/strong&gt; 这是在观察任何特征之前，我们对某一类别概率的预估（如您所说，比如上面例子中\(P(\text{瓜熟})=0.6\)）。&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;**$$P(\text{特征}&lt;/td&gt;
          &lt;td&gt;\text{类别})\((似然项):** 在类别已知的情况下，观察到特征的概率（如\)P(\text{瓜蒂脱落}&lt;/td&gt;
          &lt;td&gt;\text{瓜熟})=0.8$$）。&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(P(\text{特征})\) (证据项):&lt;/strong&gt; 观察到特征本身的概率，通过&lt;strong&gt;全概率公式&lt;/strong&gt;计算得出（如 \(P(\text{瓜蒂脱落})\)）。&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;**$$P(\text{类别}&lt;/td&gt;
          &lt;td&gt;\text{特征})\((后验概率):** 这是最终要求的，在特征已知的情况下，类别发生的概率（如\)P(\text{瓜熟}&lt;/td&gt;
          &lt;td&gt;\text{瓜蒂脱落})=0.75$$）。&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;21朴素的含义特征独立性假设&quot;&gt;2.1“朴素”的含义：特征独立性假设&lt;/h2&gt;

&lt;p&gt;在实际的机器学习问题中，特征 \(x\) 往往不止一个，而是多个特征向量 \(x = (x_1, x_2, \dots, x_n)\)。&lt;/p&gt;

&lt;p&gt;朴素贝叶斯名字中的“朴素”指的是它做了一个&lt;strong&gt;强假设&lt;/strong&gt;：&lt;strong&gt;所有特征之间相互独立&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;在类别 \(y\) 已知的情况下，所有特征的联合概率等于它们各自概率的乘积。&lt;/p&gt;

\[P(x_1, x_2, \dots, x_n | y) = P(x_1|y) \times P(x_2|y) \times \dots \times P(x_n|y)\]

&lt;p&gt;这个“朴素”的假设大大简化了计算，使得模型可以在特征数量非常大时依然高效运行，但这也是它&lt;strong&gt;牺牲模型准确性&lt;/strong&gt;的地方（因为现实中特征很少是完全独立的）。&lt;/p&gt;

&lt;h2 id=&quot;22朴素贝叶斯与逻辑回归线性回归的对比&quot;&gt;2.2朴素贝叶斯与逻辑回归、线性回归的对比&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;特性&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;朴素贝叶斯 (Naive Bayes)&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;逻辑回归 (Logistic Regression)&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;线性回归 (Linear Regression)&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;模型类型&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;生成模型&lt;/strong&gt; (Generative Model)&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;判别模型&lt;/strong&gt; (Discriminative Model)&lt;/td&gt;
      &lt;td&gt;判别模型 (Discriminative Model)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;解决问题&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;分类&lt;/strong&gt; (Classification)&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;分类&lt;/strong&gt; (Classification)&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;回归&lt;/strong&gt; (Regression)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;目标输出&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;离散的类别标签 (如“好瓜”/“坏瓜”)&lt;/td&gt;
      &lt;td&gt;类别概率&lt;/td&gt;
      &lt;td&gt;连续值&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;训练速度极快；对缺失数据不敏感；对数据量较小的场景有效。&lt;/td&gt;
      &lt;td&gt;输出是概率值，可解释性强；决策边界是线性的；理论基础坚实。&lt;/td&gt;
      &lt;td&gt;模型简单且可解释性强；计算高效。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;缺点&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;因为强大的&lt;strong&gt;特征独立性&lt;/strong&gt;假设，但是独立性假设往往不成立，可能牺牲准确率。&lt;/td&gt;
      &lt;td&gt;易受异常值影响；只能解决线性可分或近似线性的问题。&lt;/td&gt;
      &lt;td&gt;只能拟合线性关系；对噪声和多重共线性敏感。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;3缺失值的处理&quot;&gt;3.缺失值的处理&lt;/h1&gt;

&lt;p&gt;比如婚恋相亲网站，每个用户信息填写的完整程度不同（用户填写意愿、隐私考量或信息复杂性）。在推荐/匹配/预测场景（机器学习）中，如果碰到缺失值如何处理？&lt;/p&gt;

&lt;p&gt;处理缺失值的方法大致可以分为三类：&lt;strong&gt;删除（Deletion）&lt;/strong&gt;、&lt;strong&gt;插值/填充（Imputation）&lt;/strong&gt;、和&lt;strong&gt;建模（Modeling）&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;31删除&quot;&gt;3.1删除&lt;/h2&gt;

&lt;p&gt;当缺失量极少或缺失模式很随机时可以考虑。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;方法&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;描述&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;适用场景&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;风险/缺点&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;1. 行删除&lt;/strong&gt; (Listwise Deletion)&lt;/td&gt;
      &lt;td&gt;直接删除任何包含缺失值的样本（用户记录）。&lt;/td&gt;
      &lt;td&gt;缺失值占总数据量比例&lt;strong&gt;极低&lt;/strong&gt;（如 &amp;lt; 1%）且缺失是&lt;strong&gt;完全随机&lt;/strong&gt;的。&lt;/td&gt;
      &lt;td&gt;如果缺失值较多，会导致数据量急剧减少，损失大量信息，引入偏差。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;2. 列删除&lt;/strong&gt; (Feature Deletion)&lt;/td&gt;
      &lt;td&gt;如果某个特征（如“年收入”）的缺失率&lt;strong&gt;极高&lt;/strong&gt;（如 &amp;gt; 90%），则直接删除该特征。&lt;/td&gt;
      &lt;td&gt;该特征对核心业务价值不大，且缺失率高到无法有效填充。&lt;/td&gt;
      &lt;td&gt;可能丢失对模型有潜在价值的信息。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;32填充&quot;&gt;3.2填充&lt;/h2&gt;

&lt;p&gt;用某种值替换缺失值，这是最常用的方法。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;方法&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;描述&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;适用场景&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;风险/缺点&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;3. 均值/中位数/众数填充&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;数值特征（如身高、年龄）：用&lt;strong&gt;均值&lt;/strong&gt;或&lt;strong&gt;中位数&lt;/strong&gt;填充。类别特征（如学历、信仰）：用&lt;strong&gt;众数&lt;/strong&gt;填充。&lt;/td&gt;
      &lt;td&gt;缺失值比例适中，或缺失是随机的。&lt;/td&gt;
      &lt;td&gt;这种方法会减小特征的方差，并引入偏差（特别是均值填充），&lt;strong&gt;使数据分布失真&lt;/strong&gt;。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;4. 哨兵值填充&lt;/strong&gt; (Sentinel/Flag Value)&lt;/td&gt;
      &lt;td&gt;用一个特定的值（如 -999 或 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Unknown&lt;/code&gt;）来标记缺失，让模型知道这个值是缺失的。&lt;/td&gt;
      &lt;td&gt;特别适用于类别特征，或当缺失本身可能包含信息（e.g., &lt;strong&gt;“不愿填写”本身就是一种信息&lt;/strong&gt;）。&lt;/td&gt;
      &lt;td&gt;模型可能会错误地将这个哨兵值解释为一个“正常”的极大或极小值。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;5. 基于模型填充&lt;/strong&gt; (Model-based Imputation)&lt;/th&gt;
      &lt;th&gt;使用其他非缺失特征作为输入，训练一个模型（如线性回归、决策树、KNN 等）来预测缺失值。&lt;/th&gt;
      &lt;th&gt;缺失值数量较大，且特征之间有较强相关性。&lt;/th&gt;
      &lt;th&gt;填充值更接近真实数据分布，精度高。常用的方法有 &lt;strong&gt;MICE&lt;/strong&gt;（多重插值）和 &lt;strong&gt;KNN Imputation&lt;/strong&gt;。&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;6. 前后值填充&lt;/strong&gt; (Locally based Imputation)&lt;/td&gt;
      &lt;td&gt;对于时间序列数据（不适用于相亲网站的静态数据），用前一个或后一个观测值填充。&lt;/td&gt;
      &lt;td&gt;数据存在时间或空间上的连续性。&lt;/td&gt;
      &lt;td&gt;不适用于独立的个人信息记录。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;33建模&quot;&gt;3.3建模&lt;/h2&gt;

&lt;p&gt;不直接改变数据，而是修改模型或增加信息。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;方法&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;描述&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;适用场景&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;7. 缺失指示变量&lt;/strong&gt; (Missing Indicator)&lt;/td&gt;
      &lt;td&gt;对于每个有缺失值的特征X，增加一个二元指示变量I。如果 X缺失，则I=1，否则 I=0。然后用均值/中位数等填充 X。&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;强烈推荐&lt;/strong&gt;。假设缺失机制是非随机的（MNAR），即缺失的原因本身带有信息。&lt;/td&gt;
      &lt;td&gt;捕捉了“不愿填写”或“信息不存在”本身所包含的信号，保留了原始数据结构。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;8. 特殊模型&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;使用能够&lt;strong&gt;自动处理缺失值&lt;/strong&gt;的模型，例如基于树的模型（如 XGBoost, LightGBM, CatBoost）。&lt;/td&gt;
      &lt;td&gt;当缺失模式复杂、缺失量较大时。&lt;/td&gt;
      &lt;td&gt;模型在节点划分时可以自动处理或学习缺失值，无需手动填充。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;34案例&quot;&gt;3.4案例&lt;/h2&gt;

&lt;p&gt;在婚恋相亲网站的场景中，&lt;strong&gt;缺失值往往不是随机的，而是带有明确的意图或隐私偏好&lt;/strong&gt;（例如，高收入者可能不填收入，低收入者也可能不填收入）。因此，推荐结合使用以下方法：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;指示变量 + 填充 (方法 7 + 4)：&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;数值特征&lt;/strong&gt;（如年收入、身高）：用中位数填充，并新增一个“年收入_缺失指示”的二元特征。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;类别特征&lt;/strong&gt;（如家庭状况）：用“&lt;strong&gt;Unknown&lt;/strong&gt;”或“&lt;strong&gt;未公开&lt;/strong&gt;”作为单独的类别进行填充。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;使用树模型 (方法 8)：&lt;/strong&gt; 优先使用 XGBoost 或 LightGBM 等集成树模型进行预测/匹配建模，因为它们对缺失值的鲁棒性更好，并且能自动学习缺失值模式。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;领域知识优先：&lt;/strong&gt; 某些关键特征（如“性别”、“年龄”、“城市”）如果缺失，可能直接导致匹配失败，应要求用户必须填写，或者直接删除该记录。&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;4线性回归和逻辑回归极高的耦合度&quot;&gt;4.线性回归和逻辑回归极高的耦合度&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;线性回归（Linear Regression）和逻辑回归（Logistic Regression）在数学和结构上确实存在着极高的耦合度&lt;/strong&gt;。它们常常被一起教授，正是因为它们共享了“广义线性模型”的核心思想。&lt;/p&gt;

&lt;p&gt;无论是在线性回归还是逻辑回归中，模型的第一步都是将输入特征 \(\mathbf{x}\) 进行&lt;strong&gt;线性组合&lt;/strong&gt;（加权求和），得到一个预测值 \(z\)：&lt;/p&gt;

\[z = \mathbf{W}^T \mathbf{x} + b\]

&lt;p&gt;两者都假设输入特征对目标变量的影响是&lt;strong&gt;线性的、可叠加的&lt;/strong&gt;。—-&amp;gt;耦合度很高。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;朴素贝叶斯&lt;/strong&gt;明确且&lt;strong&gt;强制&lt;/strong&gt;地要求&lt;strong&gt;特征之间相互独立&lt;/strong&gt;。这是其“朴素”的来源。&lt;/p&gt;

&lt;p&gt;而&lt;strong&gt;逻辑回归（LR）&lt;/strong&gt;则不同：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;LR&lt;/strong&gt; 是一种&lt;strong&gt;判别模型&lt;/strong&gt;，它直接建模 $$P(y&lt;/td&gt;
          &lt;td&gt;\mathbf{x})\(，并不对输入特征\)\mathbf{x}\(的**联合概率分布**\)P(x_1, x_2, \dots, x_n)$$ 做任何假设。&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;因此，&lt;strong&gt;LR 本身并没有假设特征独立性&lt;/strong&gt;。它只关心 \(\mathbf{W}^T \mathbf{x}\) 这个线性组合，模型参数 $\mathbf{W}$ 会自动学习特征之间的相关性。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;LR 的耦合在于它&lt;strong&gt;强制将特征的贡献以线性和叠加的方式聚合&lt;/strong&gt;，这限制了它无法捕捉特征之间的复杂&lt;strong&gt;非线性交互作用&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;另外，线性部分 \(\mathbf{W}^T \mathbf{x} + b\) 过于紧密地依赖于&lt;strong&gt;特征间的关系&lt;/strong&gt;，从而导致： 如果 \(x_i\) 和 \(x_j\) 强相关，模型很难唯一确定它们各自的权重 \(w_i\) 和 \(w_j\)，从而让模型结构变得脆弱。(解决办法：利用&lt;strong&gt;正则化&lt;/strong&gt;（如 L1 或 L2）来解耦 LR 模型中特征之间的相关性，从而处理多重共线性问题)&lt;/p&gt;

&lt;p&gt;显然，特征之间独立的可能性一般不大。所以朴素贝叶斯使用场景极其有限。&lt;/p&gt;

&lt;p&gt;但是朴素贝叶斯对于  数据缺失，又想要数据解耦  的场景又很友好。&lt;/p&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;计算&lt;strong&gt;后验概率&lt;/strong&gt; $$P(y_k=1&lt;/td&gt;
      &lt;td&gt;\mathbf{x})$$：&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[P(y_k=1|\mathbf{x}) = \frac{P(y_k=1) \cdot P(\mathbf{x}|y_k=1)}{P(\mathbf{x})}\]

&lt;p&gt;从通用贝叶斯公式到&lt;strong&gt;朴素贝叶斯分类器&lt;/strong&gt;的关键一步。&lt;/p&gt;

\[P(y_k=1|\mathbf{x}) = \frac{P(y_k=1) \cdot P(x_1|y_k=1) \cdot P(x_2|y_k=1) \cdot P(x_3|y_k=1)}{P(x_1, x_2, x_3)}\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;这个推导的关键在于分子中对**似然项 $$P(\mathbf{x}&lt;/td&gt;
      &lt;td&gt;y_k=1)$$ 的分解**：&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[P(\mathbf{x}|y_k=1) = P(x_1, x_2, x_3 | y_k=1)\]

&lt;p&gt;根据朴素贝叶斯的&lt;strong&gt;核心假设（朴素假设）&lt;/strong&gt;：&lt;strong&gt;在类别 \(y\) 确定的条件下，所有特征 \(x_i\) 之间相互独立。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;因此，联合条件概率可以分解为各个特征条件概率的乘积：&lt;/p&gt;

\[P(x_1, x_2, x_3 | y_k=1) \approx P(x_1|y_k=1) \cdot P(x_2|y_k=1) \cdot P(x_3|y_k=1)\]

&lt;hr /&gt;

&lt;p&gt;所以，朴素贝叶斯就是搞统计，且样本少的时候，误差就很大了，样本可能存在很强的偶然性，此时做统计就不准确了。&lt;/p&gt;

&lt;p&gt;线性回归抗冗余强，但是朴素贝叶斯抗冗余不强。&lt;/p&gt;

&lt;h1 id=&quot;5拉普拉斯平滑&quot;&gt;5.拉普拉斯平滑&lt;/h1&gt;

&lt;p&gt;在&lt;strong&gt;朴素贝叶斯（Naive Bayes）&lt;/strong&gt;算法中处理&lt;strong&gt;小样本（或零概率）问题&lt;/strong&gt;的一种经典且有效的解决方案：&lt;strong&gt;拉普拉斯平滑（Laplace Smoothing）&lt;/strong&gt;。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;特征 \(x_1=1\) 的条件概率：&lt;/p&gt;

\[P(x_1=1 | y_1=1) = \frac{\text{Count}(x_1=1, y_1=1) + \frac{n}{2}}{\text{Count}(y_1) + n}\]

&lt;p&gt;特征 \(x_1=0\) 的条件概率：&lt;/p&gt;

\[P(x_1=0 | y_1=1) = \frac{\text{Count}(x_1=0, y_1=1) + \frac{n}{2}}{\text{Count}(y_1) + n}\]

&lt;p&gt;&lt;strong&gt;这个n的取值&lt;/strong&gt;：根据人为干预决定。也是根据人的经验得出的。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;拉普拉斯平滑&lt;/strong&gt;通过向分子和分母添加一个&lt;strong&gt;虚拟计数&lt;/strong&gt;（Pseudo-count）\(\alpha\) 来调整概率估计。&lt;/p&gt;

&lt;p&gt;一般的拉普拉斯平滑公式如下：&lt;/p&gt;

\[P_{\text{smooth}}(x_i|y_k) = \frac{\text{Count}(x_i, y_k) + \alpha}{\text{Count}(y_k) + \alpha \cdot D}\]

&lt;p&gt;其中：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(\alpha\)：平滑参数（通常取 1，即“加一平滑”）。&lt;/li&gt;
  &lt;li&gt;\(D\)：特征 \(x_i\) 可能的取值数量（即&lt;strong&gt;维度&lt;/strong&gt;）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;它本质上是&lt;strong&gt;将训练集数据与一个均匀分布进行了加权平均&lt;/strong&gt;。当样本量 \(\text{Count}(y_k)\) 很小时，添加的 \(\alpha \cdot D\) 影响较大，&lt;strong&gt;防止极端概率&lt;/strong&gt;；当样本量很大时，平滑项的影响微乎其微。&lt;/p&gt;

&lt;p&gt;通过这种方式，拉普拉斯平滑有效地解决了小样本数据中由于偶然性导致的零概率问题，使朴素贝叶斯模型在训练集不完备的情况下依然能够给出合理的概率估计。&lt;/p&gt;

&lt;h1 id=&quot;6信息如何量化&quot;&gt;6.信息如何量化&lt;/h1&gt;

&lt;p&gt;1.明天太阳从东边升起&lt;/p&gt;

&lt;p&gt;2.明天下雨&lt;/p&gt;

&lt;p&gt;显然2的信息量更大，因为1发生的概率是1，而2发生的概率显然小于1&lt;/p&gt;

&lt;h2 id=&quot;61信息量--自信息&quot;&gt;6.1信息量 / 自信息&lt;/h2&gt;

&lt;p&gt;信息论认为，一个事件所包含的&lt;strong&gt;信息量&lt;/strong&gt;与其发生的&lt;strong&gt;概率&lt;/strong&gt;成反比。事件发生的概率越低，它所携带的信息量就越大。&lt;/p&gt;

&lt;p&gt;信息论中使用&lt;strong&gt;对数&lt;/strong&gt;来量化信息量 \(I(x)\)，因为信息量具有可加性（独立事件的总信息量等于各自信息量之和），而概率具有可乘性（独立事件的总概率等于各自概率之积）。对数正好能将乘法转化为加法。&lt;/p&gt;

&lt;p&gt;对于一个事件 \(x\)，其&lt;strong&gt;自信息&lt;/strong&gt; \(I(x)\) 的定义为：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;下面公式，香农严格证明过。&lt;/p&gt;
&lt;/blockquote&gt;

\[I(x) = - \log_b P(x)\]

&lt;p&gt;其中：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(P(x)\) 是事件 \(x\) 发生的概率。&lt;/li&gt;
  &lt;li&gt;\(b\) 是对数的底数，它决定了信息量的单位：
    &lt;ul&gt;
      &lt;li&gt;当 \(b=2\) 时，信息量的单位是&lt;strong&gt;比特 (bits)&lt;/strong&gt;。&lt;/li&gt;
      &lt;li&gt;当 \(b=e\) 时，信息量的单位是&lt;strong&gt;奈特 (nats)&lt;/strong&gt;。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;通过这个公式，可以看到：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果 \(P(x) = 1\)，则 \(I(x) = -\log_b(1) = 0\)。&lt;/li&gt;
  &lt;li&gt;如果 \(P(x) \to 0\)，则 \(I(x) \to \infty\)。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这个概念是后续&lt;strong&gt;熵 (Entropy)&lt;/strong&gt;、&lt;strong&gt;交叉熵 (Cross-Entropy)&lt;/strong&gt; 和&lt;strong&gt;信息增益 (Information Gain)&lt;/strong&gt; 等机器学习中核心概念的基石。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;比如推荐系统，喜欢推荐“新奇特”的信息一样，其信息量很大，发生的概率很小。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;62信息熵&quot;&gt;6.2信息熵&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;说白了，信息熵是信息量的期望。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;信息熵是用来量化一个随机变量或一个系统所包含的平均不确定性或信息量。&lt;/strong&gt;衡量在观察到 \(X\) 的任何结果之前，我们需要多少信息才能确定其结果。&lt;/p&gt;

&lt;p&gt;在机器学习中，熵常用于决策树（信息增益）、模型评估（交叉熵损失）等方面。&lt;/p&gt;

&lt;p&gt;熵可以被视为&lt;strong&gt;随机变量 \(X\) 所有可能结果的自信息期望值&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;对于一个离散随机变量 \(X\)，它有 \(n\) 种可能的取值 \(\{x_1, x_2, \dots, x_n\}\)，每种取值的概率是 \(P(x_i)\)，其熵 \(H(X)\) 定义为：&lt;/p&gt;

\[H(X) = E[I(X)] = \sum_{i=1}^{n} P(x_i) \cdot I(x_i)\]

&lt;p&gt;将自信息 \(I(x_i) = -\log_2 P(x_i)\) 代入，得到最终的熵公式（通常以比特为单位，故取底数为 2）：&lt;/p&gt;

\[H(X) = - \sum_{i=1}^{n} P(x_i) \log_2 P(x_i)\]

&lt;p&gt;&lt;strong&gt;单位：&lt;/strong&gt; 比特（bits）。熵的数值代表了要对该随机变量进行编码所需的&lt;strong&gt;平均最小比特数&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;熵值越高，不确定性越大。&lt;/strong&gt; 样本的分布越均匀，熵越大。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;熵值越低，不确定性越小。&lt;/strong&gt; 样本的分布越集中，熵越小。&lt;/p&gt;

&lt;p&gt;熵给出了对随机变量编码所需的&lt;strong&gt;理论平均最短长度&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;例如，如果一个系统的信息熵是 3 比特，那么在平均意义上，你需要 3 个二元问题（是/否）才能确定该系统的状态。&lt;/p&gt;

&lt;p&gt;熵是计算&lt;strong&gt;信息增益&lt;/strong&gt;的基础。在每次分裂时，决策树选择能最大程度&lt;strong&gt;降低熵&lt;/strong&gt;（即最大程度减少不确定性）的特征，从而达到最佳分类效果。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;交叉熵（Cross-Entropy）&lt;/strong&gt;和&lt;strong&gt;相对熵（KL 散度）&lt;/strong&gt;都是基于信息熵的概念发展而来，用于衡量模型预测的概率分布与真实概率分布之间的差异。&lt;/p&gt;
</description>
        <pubDate>Sat, 22 Nov 2025 00:00:00 +0000</pubDate>
        <link>https://kirsten-1.github.io/2025/11/22/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9910/</link>
        <guid isPermaLink="true">https://kirsten-1.github.io/2025/11/22/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9910/</guid>
        
        <category>AI思想启蒙</category>
        
        
      </item>
    
      <item>
        <title>【AI思想启蒙09】逻辑回归5让学习更高效，数值优化和一只看不见的手 </title>
        <description>&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG&quot;&gt;
&lt;/script&gt;

&lt;h1 id=&quot;1特征缩放-z-score标准化归一化&quot;&gt;1.特征缩放-Z-score标准化/归一化&lt;/h1&gt;

&lt;p&gt;回顾逻辑回归的损失函数，及其导数：&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;损失函数是BCE：$$\mathcal{L}_{\text{BCE}}(P&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Q) = - \sum_{k \in {0, 1}} P(Y=k) \log Q(Y=k) = - [y \log \hat{y} + (1 - y) \log (1 - \hat{y})]=\ \sum_{i=1}^{n} \left[ y_i \log \frac{y_i}{f_i} + (1 - y_i) \log \frac{1 - y_i}{1 - f_i} \right]$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;导数：损失函数 $$\mathcal{L}_{\text{BCE}}(P&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Q)\(对权重向量\)\mathbf{w}\(中任一分量\)w_j\(的偏导数\)\frac{\partial L_i}{\partial w_j}$$：&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[\frac{\partial L_i}{\partial w_j} = - (y_i - \hat{y}_i) x_{i,j} = (\hat{y}_i - y_i) x_{i,j}\]

&lt;p&gt;总体损失梯度如下：&lt;/p&gt;

&lt;p&gt;对于整个训练集（所有 \(N\) 个样本），总损失 \(L(\mathbf{w}) = \frac{1}{N} \sum_{i=1}^{N} L_i(\mathbf{w})\) 对 \(w_j\) 的梯度为：&lt;/p&gt;

\[\frac{\partial L}{\partial w_j} = \frac{1}{N} \sum_{i=1}^{N} \frac{\partial L_i}{\partial w_j} = \frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i - y_i) x_{i,j}\]

&lt;hr /&gt;

&lt;p&gt;梯度下降：对单个权重 \(w_j\) 的更新:&lt;/p&gt;

\[w_{j, \text{new}} = w_{j, \text{old}} - \alpha \cdot \frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i - y_i) x_{i,j}\]

&lt;p&gt;如果特征都是大于0的取值，根据梯度下降的式子，参数\(w\)只会越来越小。反之如果特征都是小于0的数值，参数只会越来越大。如果用4个象限的等高线描述梯度下降的过程，那么梯度只会往第一象限/第三象限走。此时就会使得收敛过程发生巨大的震荡。&lt;/p&gt;

&lt;p&gt;这些都属于&lt;strong&gt;未归一化/未标准化特征&lt;/strong&gt;在梯度下降优化过程中的&lt;strong&gt;效率和稳定性&lt;/strong&gt;问题。&lt;strong&gt;特征尺度的不一致或不平衡，会导致损失函数的等高线变得极度扁平狭长，使得梯度下降路径低效且震荡。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;解决这个问题的最优方案是使用 &lt;strong&gt;特征缩放（Feature Scaling）&lt;/strong&gt;，特别是 &lt;strong&gt;Z-Score 归一化（标准化）&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;每个特征 \(x_j\) 转换为标准正态分布，使其均值 \(\mu=0\)，标准差 \(\sigma=1\)。&lt;/p&gt;

\[x_{\text{new}} = \frac{x - \mu}{\sigma}\]

&lt;p&gt;这是最推荐的解决方案，尤其适用于基于梯度下降的线性模型（如逻辑回归）和神经网络。&lt;/p&gt;

&lt;p&gt;当然也可以用Min-Max 归一化 (Normalization)，但是Min-Max 归一化对异常值很敏感。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251121003720143.png&quot; alt=&quot;image-20251121003720143&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2逻辑回归的总结&quot;&gt;2.逻辑回归的总结&lt;/h1&gt;

&lt;p&gt;1.sigmoid伯努利分布   特殊的softmax（多项分布）&lt;/p&gt;

&lt;p&gt;2.BCE  不用MSE&lt;/p&gt;

&lt;p&gt;3.L1/L2正则&lt;/p&gt;

&lt;p&gt;4.归一化&lt;/p&gt;

&lt;p&gt;5.指标  ： 准确率/召回率/查准率/AUC-ROC&lt;/p&gt;

&lt;h1 id=&quot;3先验条件&quot;&gt;3.先验条件&lt;/h1&gt;

&lt;p&gt;一元高斯分布（Univariate Gaussian Distribution），也称为&lt;strong&gt;一维正态分布&lt;/strong&gt;，其概率密度函数（Probability Density Function, PDF）为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251121004636434.png&quot; alt=&quot;image-20251121004636434&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

\[f(x | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x - \mu)^2}{2\sigma^2}}\]

&lt;p&gt;其中：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(x\) 是随机变量的取值。&lt;/li&gt;
  &lt;li&gt;\(\mu\) 是分布的&lt;strong&gt;均值&lt;/strong&gt;（Mean），决定了分布的中心位置。&lt;/li&gt;
  &lt;li&gt;\(\sigma^2\) 是分布的&lt;strong&gt;方差&lt;/strong&gt;（Variance），决定了分布的形状，即数据的分散程度。\(\sigma\)越大，越分散。&lt;/li&gt;
  &lt;li&gt;\(\sigma\) 是标准差（Standard Deviation）。&lt;/li&gt;
  &lt;li&gt;\(\frac{1}{\sqrt{2\pi\sigma^2}}\) 是归一化常数，确保概率密度函数在整个实数域上的积分为 $1$。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;相对论的成功在于它基于最少的公理，得到了最大的推论，构建了一个自洽的宇宙模型。&lt;/p&gt;

&lt;p&gt;即：假设（公理）—-&amp;gt;推论&lt;/p&gt;

&lt;p&gt;机器学习中，这个假设（公理）就是：&lt;strong&gt;对于某一类来说，分布符合正态分布&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;其实严格来说，判别模型（逻辑回归/softmax回归等）应该符合的是伯努利分布/多项分布（统称为指数族分布）。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;4贝叶斯公式与高斯分布的结合&quot;&gt;4.贝叶斯公式与高斯分布的结合&lt;/h1&gt;

&lt;p&gt;贝叶斯公式是所有生成模型的理论基础。&lt;/p&gt;

\[P(y|x) = \frac{P(x|y) \cdot P(y)}{P(x)} \quad \text{（后验概率）}\]

&lt;p&gt;例如身高判断 \(x=170\) 是男还是女&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;**$$P(y=1&lt;/td&gt;
      &lt;td&gt;x)\(：** 在已知身高\)x$$ 的情况下，是&lt;strong&gt;男&lt;/strong&gt;的概率。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;**$$P(y=0&lt;/td&gt;
      &lt;td&gt;x)\(：** 在已知身高\)x$$ 的情况下，是&lt;strong&gt;女&lt;/strong&gt;的概率。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;由于 \(P(x)\) 对两个类别的比较是相同的，我们只需要比较&lt;strong&gt;分子&lt;/strong&gt;：&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;选择$$\quad y = \arg\max_{y \in {\text{男}, \text{女}}} \left{ P(x=170&lt;/td&gt;
      &lt;td&gt;y) \cdot P(y) \right}$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;还有已知条件：&lt;/p&gt;

&lt;p&gt;\(P(y=\text{男}) + P(y=\text{女}) = 1\)，这是先验概率 (Prior Probability)。&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;在观察到特定数据 \(x\)（例如，身高 \(x=170\)）之后，其对应的后验概率之和也必须为 1：$$P(y=\text{男}&lt;/td&gt;
      &lt;td&gt;x=170) + P(y=\text{女}&lt;/td&gt;
      &lt;td&gt;x=170) = 1$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;p&gt;假设特征 \(x\) 在每个类别下服从&lt;strong&gt;正态分布&lt;/strong&gt;（高斯分布），另外假设&lt;strong&gt;方差 \(\sigma^2\) 相等&lt;/strong&gt;，即两个类别（\(y=1\) 和 \(y=0\)）的方差相等，即 \(\sigma_1^2 = \sigma_0^2 = \sigma^2\)。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;类别 \(y=1\) 的分布：$$P(x&lt;/td&gt;
          &lt;td&gt;y=1) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x - \mu_1)^2}{2\sigma^2}}$$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;类别 \(y=0\) 的分布：$$P(x&lt;/td&gt;
          &lt;td&gt;y=0) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x - \mu_0)^2}{2\sigma^2}}$$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;计算两个类别似然项的比值 $$\frac{P(x&lt;/td&gt;
      &lt;td&gt;y=1)}{P(x&lt;/td&gt;
      &lt;td&gt;y=0)}$$：&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[\frac{P(x|y=1)}{P(x|y=0)} = \frac{\frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x - \mu_1)^2}{2\sigma^2}}}{\frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x - \mu_0)^2}{2\sigma^2}}}\]

&lt;p&gt;由于 \(\sigma^2\) 相等，系数 \(\frac{1}{\sqrt{2\pi\sigma^2}}\) 被抵消：&lt;/p&gt;

\[\frac{P(x|y=1)}{P(x|y=0)} = e^{-\frac{1}{2\sigma^2} \left[ (x - \mu_1)^2 - (x - \mu_0)^2 \right]}\]

&lt;p&gt;化简指数上的项 \((x - \mu_1)^2 - (x - \mu_0)^2\) 的负值：&lt;/p&gt;

\[\begin{aligned} \text{指数项} &amp;amp;= -(x - \mu_1)^2 + (x - \mu_0)^2 \\ &amp;amp;= - (x^2 - 2x\mu_1 + \mu_1^2) + (x^2 - 2x\mu_0 + \mu_0^2) \\ &amp;amp;= -x^2 + 2x\mu_1 - \mu_1^2 + x^2 - 2x\mu_0 + \mu_0^2 \\ &amp;amp;=  (2x\mu_1 - 2x\mu_0) + (\mu_0^2 - \mu_1^2) \\ &amp;amp;= 2x(\mu_1 - \mu_0) + (\mu_0^2 - \mu_1^2) \end{aligned}\]

&lt;p&gt;将化简后的结果代回似然比的指数：&lt;/p&gt;

\[\log \left( \frac{P(x|y=1)}{P(x|y=0)} \right) = \frac{1}{2\sigma^2} \left[ 2x(\mu_1 - \mu_0) + (\mu_0^2 - \mu_1^2) \right]\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;最终目标是后验概率 $$P(y=1&lt;/td&gt;
      &lt;td&gt;x)$$。在贝叶斯公式中：&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[\frac{P(y=1|x)}{P(y=0|x)} = \frac{P(x|y=1) P(y=1)}{P(x|y=0) P(y=0)} = \left( \frac{P(x|y=1)}{P(x|y=0)} \right) \cdot \left( \frac{P(y=1)}{P(y=0)} \right)\]

&lt;p&gt;取对数，得到&lt;strong&gt;对数几率 (Log-Odds)&lt;/strong&gt;：&lt;/p&gt;

\[\log \left( \frac{P(y=1|x)}{P(y=0|x)} \right) = \log \left( \frac{P(x|y=1)}{P(x|y=0)} \right) + \log \left( \frac{P(y=1)}{P(y=0)} \right)\]

&lt;p&gt;将结果代入：&lt;/p&gt;

\[\log \left( \frac{P(y=1|x)}{P(y=0|x)} \right) = \underbrace{\left[ \frac{1}{\sigma^2} (\mu_1 - \mu_0) \right]}_{W} x + \underbrace{\left[ \frac{1}{2\sigma^2} (\mu_0^2 - \mu_1^2) + \log \left( \frac{P(y=1)}{P(y=0)} \right) \right]}_{W_0}\]

&lt;p&gt;模型的对数几率被表示成了特征 \(x\) 的&lt;strong&gt;线性函数&lt;/strong&gt; \(W x + W_0\)。&lt;/p&gt;

\[\log \left( \frac{P(y=1|x)}{P(y=0|x)} \right) = W x + W_0 = \mathbf{z}\]

&lt;p&gt;两边同时取 \(e\) 的指数：&lt;/p&gt;

\[\frac{P(y=1|x)}{P(y=0|x)} = e^{\mathbf{z}}\]

&lt;p&gt;在二分类问题中，事件 \(y=1\) 和 \(y=0\) 是互斥且穷尽的，因此它们的概率之和必须为 1：&lt;/p&gt;

\[P(y=1|x) + P(y=0|x) = 1\]

&lt;p&gt;从上式可得：&lt;/p&gt;

\[P(y=0|x) = 1 - P(y=1|x)\]

&lt;p&gt;代入：&lt;/p&gt;

\[\frac{P(y=1|x)}{1 - P(y=1|x)} = e^{\mathbf{z}}\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;现在开始代数求解 $$P(y=1&lt;/td&gt;
      &lt;td&gt;x)\(（设\)\hat{y} = P(y=1&lt;/td&gt;
      &lt;td&gt;x)$$ 方便书写）：&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[\frac{\hat{y}}{1 - \hat{y}} = e^{\mathbf{z}}\]

\[\hat{y} = e^{\mathbf{z}} (1 - \hat{y})\]

\[\hat{y} = e^{\mathbf{z}} - \hat{y} e^{\mathbf{z}}\]

&lt;p&gt;将包含 \(\hat{y}\) 的项移到等式左侧：&lt;/p&gt;

\[\hat{y} + \hat{y} e^{\mathbf{z}} = e^{\mathbf{z}}\]

&lt;p&gt;提取 \(\hat{y}\)：&lt;/p&gt;

\[\hat{y} (1 + e^{\mathbf{z}}) = e^{\mathbf{z}}\]

&lt;p&gt;最终解出 \(\hat{y}\)：&lt;/p&gt;

\[\hat{y} = \frac{e^{\mathbf{z}}}{1 + e^{\mathbf{z}}}\]

&lt;p&gt;为了得到更标准的 Sigmoid 形式，我们将分子和分母同时除以 \(e^{\mathbf{z}}\)：&lt;/p&gt;

\[\hat{y} = \frac{e^{\mathbf{z}} / e^{\mathbf{z}}}{(1 + e^{\mathbf{z}}) / e^{\mathbf{z}}} = \frac{1}{1/e^{\mathbf{z}} + e^{\mathbf{z}}/e^{\mathbf{z}}} = \frac{1}{e^{-\mathbf{z}} + 1}\]

&lt;p&gt;最后，用 \(\mathbf{z} = W x + W_0\) 替换 \(\mathbf{z}\)：&lt;/p&gt;

\[P(y=1|x) = \frac{1}{1 + e^{-(W x + W_0)}}\]

&lt;p&gt;这就是&lt;strong&gt;逻辑函数（Sigmoid 函数）&lt;/strong&gt; 的形式。&lt;/p&gt;

&lt;p&gt;这证明了在特征服从高斯分布且&lt;strong&gt;方差相等&lt;/strong&gt;的假设下，&lt;strong&gt;线性判别分析 (LDA)&lt;/strong&gt; 的结果在数学上与 &lt;strong&gt;逻辑回归&lt;/strong&gt; 是等价的。&lt;/p&gt;

&lt;p&gt;或者说上面的内容论证了&lt;strong&gt;生成模型&lt;/strong&gt;（基于贝叶斯公式和高斯分布假设）如何&lt;strong&gt;推导出&lt;/strong&gt;这个判别模型的形式。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;将生成模型（假设特征服从高斯分布的贝叶斯分类器）推导至逻辑回归形式&lt;/strong&gt;所需的特定条件：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;满足正态分布&lt;/li&gt;
  &lt;li&gt;方差相等&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;当数据满足“高斯分布”和“同方差”这两个条件时，基于贝叶斯和高斯分布的生成模型（即LDA）的决策边界形式，会自然地推导出与判别模型“逻辑回归”完全一致的形式。&lt;/strong&gt; 换句话说，在这些假设下，两个模型本质上是相同的线性分类器。如果&lt;strong&gt;类别条件概率&lt;/strong&gt;服从&lt;strong&gt;同方差高斯分布&lt;/strong&gt;，那么从贝叶斯公式推导出的&lt;strong&gt;后验概率&lt;/strong&gt; $$P(y&lt;/td&gt;
      &lt;td&gt;x)$$ 必然是&lt;strong&gt;逻辑回归&lt;/strong&gt;的Sigmoid形式。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;5最大似然估计到bcekl散度&quot;&gt;5.最大似然估计到BCE/KL散度&lt;/h1&gt;

&lt;p&gt;对于二分类问题，最大似然估计（Maximum Likelihood Estimation, MLE）的目标是找到一组参数 \(\mathbf{W}\) 和 \(b\) (或 \(\mathbf{W}\) 和 \(W_0\))，使得观测到的训练数据出现的&lt;strong&gt;总概率最大化&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;对于逻辑回归（Logistic Regression）模型，最大化似然函数（Likelihood Function）的等价操作就是最小化&lt;strong&gt;二元交叉熵损失（Binary Cross-Entropy Loss, BCE）&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;下面是详细的推导过程。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;【1】逻辑回归的二分类模型&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;在二分类问题中，我们通常使用逻辑回归（Sigmoid 函数）来建模&lt;strong&gt;后验概率&lt;/strong&gt; $$P(y=1&lt;/td&gt;
      &lt;td&gt;x)$$。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;设输入特征为 \(\mathbf{x}\)，模型参数为 \(\boldsymbol{\theta} = \{\mathbf{W}, b\}\)。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;线性组合 (Logit):&lt;/p&gt;

\[z = \mathbf{W}^T \mathbf{x} + b\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;类别 1 的概率 (Sigmoid 函数):&lt;/p&gt;

\[\hat{y} = P(y=1|\mathbf{x}; \boldsymbol{\theta}) = \frac{1}{1 + e^{-z}}\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;类别 0 的概率:&lt;/p&gt;

\[P(y=0|\mathbf{x}; \boldsymbol{\theta}) = 1 - \hat{y} = 1 - \frac{1}{1 + e^{-z}} = \frac{e^{-z}}{1 + e^{-z}}\]
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;【2】似然函数&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;对于单个训练样本 \((\mathbf{x}_i, y_i)\)，其中 \(y_i \in \{0, 1\}\)，我们可以将 $$P(y_i&lt;/td&gt;
      &lt;td&gt;\mathbf{x}_i; \boldsymbol{\theta})$$ 写成一个紧凑的形式：&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[P(y_i|\mathbf{x}_i; \boldsymbol{\theta}) = (\hat{y}_i)^{y_i} \cdot (1 - \hat{y}_i)^{1 - y_i}\]

&lt;ul&gt;
  &lt;li&gt;如果 \(y_i = 1\)，则概率为 \(\hat{y}_i^1 (1 - \hat{y}_i)^0 = \hat{y}_i\)。&lt;/li&gt;
  &lt;li&gt;如果 \(y_i = 0\)，则概率为 \(\hat{y}_i^0 (1 - \hat{y}_i)^1 = 1 - \hat{y}_i\)。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;假设我们有 \(N\) 个独立同分布的训练样本 \((\mathbf{x}_1, y_1), \dots, (\mathbf{x}_N, y_N)\)。&lt;strong&gt;似然函数 \(\mathcal{L}(\boldsymbol{\theta})\)&lt;/strong&gt; 是所有样本概率的乘积：&lt;/p&gt;

\[\mathcal{L}(\boldsymbol{\theta}) = P(Y|\mathbf{X}; \boldsymbol{\theta}) = \prod_{i=1}^{N} P(y_i|\mathbf{x}_i; \boldsymbol{\theta})\]

\[\mathcal{L}(\boldsymbol{\theta}) = \prod_{i=1}^{N} (\hat{y}_i)^{y_i} \cdot (1 - \hat{y}_i)^{1 - y_i}\]

&lt;p&gt;最大似然估计（MLE）的目标是找到 \(\boldsymbol{\theta}\) 使得 \(\mathcal{L}(\boldsymbol{\theta})\) 最大化：&lt;/p&gt;

\[\boldsymbol{\theta}_{\text{MLE}} = \arg \max_{\boldsymbol{\theta}} \mathcal{L}(\boldsymbol{\theta})\]

&lt;p&gt;【3】对数似然函数（Log-Likelihood Function）&lt;/p&gt;

&lt;p&gt;为了简化计算（将乘积转化为求和，且避免浮点数下溢），我们通常最大化&lt;strong&gt;对数似然函数 \(\ell(\boldsymbol{\theta})\)&lt;/strong&gt;：&lt;/p&gt;

\[\ell(\boldsymbol{\theta}) = \log \mathcal{L}(\boldsymbol{\theta}) = \log \left( \prod_{i=1}^{N} (\hat{y}_i)^{y_i} \cdot (1 - \hat{y}_i)^{1 - y_i} \right)\]

&lt;p&gt;根据对数运算的性质:&lt;/p&gt;

\[\ell(\boldsymbol{\theta}) = \sum_{i=1}^{N} \left[ \log \left( (\hat{y}_i)^{y_i} \right) + \log \left( (1 - \hat{y}_i)^{1 - y_i} \right) \right]\]

\[\ell(\boldsymbol{\theta}) = \sum_{i=1}^{N} \left[ y_i \log (\hat{y}_i) + (1 - y_i) \log (1 - \hat{y}_i) \right]\]

&lt;p&gt;最大化对数似然函数的等价于最大化原始似然函数：&lt;/p&gt;

\[\boldsymbol{\theta}_{\text{MLE}} = \arg \max_{\boldsymbol{\theta}} \ell(\boldsymbol{\theta})\]

&lt;p&gt;【4】损失函数：最小化负对数似然（Negative Log-Likelihood）&lt;/p&gt;

&lt;p&gt;在优化领域，习惯于将优化问题转化为&lt;strong&gt;最小化损失函数&lt;/strong&gt;的形式。因此，我们定义&lt;strong&gt;损失函数 \(J(\boldsymbol{\theta})\)&lt;/strong&gt; 为负的对数似然函数（Negative Log-Likelihood, NLL）：&lt;/p&gt;

\[J(\boldsymbol{\theta}) = - \ell(\boldsymbol{\theta})\]

\[\boldsymbol{\theta}_{\text{MLE}} = \arg \min_{\boldsymbol{\theta}} J(\boldsymbol{\theta})\]

&lt;p&gt;将 NLL 展开：&lt;/p&gt;

\[J(\boldsymbol{\theta}) = - \sum_{i=1}^{N} \left[ y_i \log (\hat{y}_i) + (1 - y_i) \log (1 - \hat{y}_i) \right]\]

&lt;p&gt;【5】得到二元交叉熵损失 (BCE Loss)&lt;/p&gt;

&lt;p&gt;最终得到的这个损失函数 \(J(\boldsymbol{\theta})\) &lt;strong&gt;正是二元交叉熵损失（Binary Cross-Entropy Loss, BCE）&lt;/strong&gt;，通常也称为对数损失（Log Loss）。&lt;/p&gt;

&lt;p&gt;通常，损失函数还会在前面加上 \(\frac{1}{N}\) 进行平均：&lt;/p&gt;

\[L_{\text{BCE}}(\boldsymbol{\theta}) = - \frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log (\hat{y}_i) + (1 - y_i) \log (1 - \hat{y}_i) \right]\]

&lt;hr /&gt;

&lt;p&gt;总结来说：对于逻辑回归模型，&lt;strong&gt;最大化似然函数&lt;/strong&gt; \(\mathcal{L}(\boldsymbol{\theta})\) 在数学上等价于&lt;strong&gt;最小化二元交叉熵损失函数 \(L_{\text{BCE}}(\boldsymbol{\theta})\)&lt;/strong&gt;。交叉熵损失来源于最大似然估计在伯努利分布假设下的自然推导。&lt;/p&gt;
</description>
        <pubDate>Fri, 21 Nov 2025 00:00:00 +0000</pubDate>
        <link>https://kirsten-1.github.io/2025/11/21/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9909/</link>
        <guid isPermaLink="true">https://kirsten-1.github.io/2025/11/21/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9909/</guid>
        
        <category>AI思想启蒙</category>
        
        
      </item>
    
      <item>
        <title>【AI思想启蒙08】逻辑回归4让模型看的更准更稳，正则优化 </title>
        <description>&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG&quot;&gt;
&lt;/script&gt;

&lt;h1 id=&quot;1参数冗余性&quot;&gt;1.参数冗余性&lt;/h1&gt;

&lt;p&gt;对于同一条决策边界（直线），可以有&lt;strong&gt;无数个&lt;/strong&gt; \(W\)（或 \(W\) 和 \(W_0\)）进行表达。例如，如果 \(W\) 和 \(W_0\) 变为 \(-W\) 和 \(-W_0\)，决策边界不变，但预测概率 \(f(x)\) 变为 \(1-f(x)\)。&lt;/p&gt;

&lt;p&gt;另外，如果\(W\)变成\(10W\)，此时要考虑参数大小的影响（过拟合风险）&lt;/p&gt;

&lt;p&gt;当权重 \(W\) 很大时（例如 \(W=100\)），输入 \(x\) 的微小变化会导致 \(\text{Sigmoid}\) 函数（\(\frac{1}{1+e^{-(Wx+W_0)}}\)）的输出变化非常大。&lt;/p&gt;

&lt;p&gt;这表明&lt;strong&gt;大的 \(W\) 值会使模型对输入敏感（高方差）&lt;/strong&gt;，容易导致&lt;strong&gt;过拟合&lt;/strong&gt;。这解释了为什么在训练中需要使用&lt;strong&gt;正则化&lt;/strong&gt;来约束 \(W\) 的大小。&lt;/p&gt;

&lt;p&gt;在没有正则化的情况下，优化器可能会在这些等效的 \(W\) 组合中来回震荡，导致训练过程不稳定，并且最终得到的 \(W\) 缺乏可解释性。&lt;/p&gt;

&lt;p&gt;逻辑回归模型在没有正则化时，一个潜在的问题就是&lt;strong&gt;数值稳定性和过度自信&lt;/strong&gt;。&lt;/p&gt;

&lt;h1 id=&quot;2正则化的概念和作用&quot;&gt;2.正则化的概念和作用&lt;/h1&gt;

&lt;p&gt;正则化用于防止模型在训练数据上&lt;strong&gt;过拟合&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;正则化通过惩罚大的权重 \(W\)，降低模型的复杂度，使模型在 &lt;strong&gt;测试集&lt;/strong&gt; 上的误差（泛化误差）尽可能小。&lt;/p&gt;

&lt;p&gt;L2 正则化（也称为 &lt;strong&gt;Ridge 正则化&lt;/strong&gt;或&lt;strong&gt;权重衰减&lt;/strong&gt;）通过在标准损失函数 \(J(\theta)\) 中添加一个与权重向量 \(W\) 的平方范数成比例的惩罚项来实现。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;L2 正则化后的损失函数 \(J_{\text{reg}}(W)\)：&lt;/strong&gt;&lt;/p&gt;

\[J_{\text{reg}}(W) = \underbrace{J(W)}_{\text{原始损失（交叉熵）}} + \underbrace{\lambda \sum W_i^2}_{\text{L2 正则项}}\]

&lt;p&gt;其中 \(\lambda\) 是正则化系数，用于控制惩罚的强度。&lt;/p&gt;

&lt;p&gt;【正则化的作用】：&lt;/p&gt;

&lt;p&gt;1.从机器角度考虑：抑制 W 在分类正确情况下，按比例无限增大&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在训练集中，一旦模型找到了一个能够正确分类所有样本的权重 \(W\)，那么将 \(W\) 扩大任意倍数 \(c &amp;gt; 1\)（即 \(cW\)），模型损失（交叉熵）会更小。但是随着 \(W\) 无限增大，模型的损失会&lt;strong&gt;无限减小&lt;/strong&gt;。在数学上，梯度下降会推动 $W$ 不断增大，直到发生&lt;strong&gt;数值溢出&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;此时加入正则化就不同了。L2 正则项 \(\lambda \sum W_i^2\) 成为一个&lt;strong&gt;“约束”&lt;/strong&gt;。当 \(W\) 增大时，惩罚项也会&lt;strong&gt;二次方地快速增大&lt;/strong&gt;。这迫使优化器在减小原始损失 \(J(W)\) 的同时，必须&lt;strong&gt;付出越来越大的代价来增加 \(W\)&lt;/strong&gt;。最终，模型会找到一个 &lt;strong&gt;\(W\) 相对较小&lt;/strong&gt;的解，这个解既能正确分类，又能避免 \(W\) 无限膨胀和潜在的数值溢出问题。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;2.减少测试集和训练集的差异性（提高泛化能力）&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;过拟合的模型过度拟合了训练数据中的&lt;strong&gt;噪声&lt;/strong&gt;，导致其学习到的权重 \(W\) 过于复杂和极端。这种&lt;strong&gt;复杂的 \(W\) 使得决策边界在训练集上表现完美，但在测试集上表现糟糕&lt;/strong&gt;。&lt;/p&gt;

  &lt;p&gt;L2 正则化倾向于使所有权重 \(W_i\) 的值&lt;strong&gt;趋于零&lt;/strong&gt;。&lt;/p&gt;

  &lt;p&gt;小的 \(W_i\) 意味着模型对单个输入特征 \(x_i\) 的依赖程度减小(对噪声的依赖也会减小)。这使得模型的决策边界更加&lt;strong&gt;平滑&lt;/strong&gt;和&lt;strong&gt;简单&lt;/strong&gt;，降低了模型的方差。&lt;/p&gt;

  &lt;p&gt;L2 正则化强制模型关注那些对大多数样本都有效的&lt;strong&gt;核心特征&lt;/strong&gt;，忽略训练集中的噪声和异常值，从而&lt;strong&gt;提高模型在测试集上的泛化能力&lt;/strong&gt;，减小训练集和测试集性能的差异。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;3.破坏训练集的效果（引入偏差，降低方差）&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;从统计学的偏差-方差权衡角度来看，正则化通过牺牲一点训练集的完美性，来换取测试集的稳定性。&lt;/p&gt;

  &lt;p&gt;正则化项 \(\lambda \sum W_i^2\) &lt;strong&gt;不是在帮助最小化训练误差&lt;/strong&gt;，它是在&lt;strong&gt;增加一个额外的损失&lt;/strong&gt;。为了让 \(\sum W_i^2\) 减小，模型必须将权重 \(W\) 往零的方向拉，即使这会导致原始的交叉熵损失 \(J(W)\) 略微增大。&lt;/p&gt;

  &lt;p&gt;因为模型被迫将 \(W\) 约束得很小，它可能无法完美拟合训练集中的每一个点，导致训练集上的损失（偏差）略微增加。&lt;/p&gt;

  &lt;p&gt;正则化使得模型对数据的微小变动（即测试集与训练集的差异）不再那么敏感，极大地降低了模型的方差。&lt;/p&gt;

  &lt;p&gt;最终的 \(J_{\text{reg}}(W)\) 追求的是 &lt;strong&gt;“训练误差”&lt;/strong&gt; 和 &lt;strong&gt;“模型复杂度”&lt;/strong&gt; 之间的最佳平衡点，这正是我们希望在&lt;strong&gt;测试集上得到最小总误差&lt;/strong&gt;所需的特性。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;3l1-正则化lasso和-l2-正则化ridge&quot;&gt;3.L1 正则化（Lasso）和 L2 正则化（Ridge）&lt;/h1&gt;

&lt;p&gt;L2 正则项是权重W的平方和，乘以一个超参数 \(\lambda\)。损失函数变为 \(J_{\text{L2}}(W) = J(W) + \lambda \sum W_i^2\)。&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;L1 正则项是权重W&lt;strong&gt;绝对值&lt;/strong&gt;的和，乘以一个超参数 \(\lambda\)。损失函数变为 $$J_{\text{L1}}(W) = J(W) + \lambda \sum&lt;/td&gt;
      &lt;td&gt;W_i&lt;/td&gt;
      &lt;td&gt;$$。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;L2 惩罚项对&lt;strong&gt;大的权重&lt;/strong&gt;施加的惩罚更大（二次方增长）。在梯度下降时，权重 \(W\) 的每一次更新都会被拉向零点，但拉力与 \(W\) 的值成正比（梯度为 \(2W\)）。&lt;/p&gt;

&lt;p&gt;L1 惩罚项在 \(W\) 不为零时，施加的是一个&lt;strong&gt;恒定的惩罚&lt;/strong&gt;（梯度为 \(\pm 1\)）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/1*nrWncnoJ4V_BkzEf1pd4MA.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;L2约束区域是一个&lt;strong&gt;圆形&lt;/strong&gt;。相切点往往落在非坐标轴上，这意味着所有权重都会被缩小，但很少会精确地变为零。&lt;/p&gt;

&lt;p&gt;L1约束区域是一个&lt;strong&gt;菱形&lt;/strong&gt;（或正方形）。由于菱形的尖角位于坐标轴上，损失函数的等值线更容易与这些尖角相切，使得相切点的某些维度 \(W_i\) 恰好为零。所以L1 正则化的独特之处在于它能够产生&lt;strong&gt;稀疏解&lt;/strong&gt;，从而实现&lt;strong&gt;特征选择&lt;/strong&gt;。L1 倾向于将那些对模型贡献不大的特征所对应的权重&lt;strong&gt;直接压缩为零&lt;/strong&gt;。当数据集中包含大量冗余或不重要的特征时，L1 可以帮助我们自动识别并保留最重要的特征。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;如果目标是特征选择或降维&lt;/strong&gt;，L1 正则化通常是更好的选择。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;如果目标是确保所有特征都保留下来，只是希望减小它们的权重以提高模型的鲁棒性和稳定性&lt;/strong&gt;，L2 正则化是更常见的选择。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在实践中，人们常结合两者，使用 &lt;strong&gt;Elastic Net&lt;/strong&gt; 正则化来兼顾特征选择和模型平滑。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果不指定正则，一般也会默认用L2正则，因为要防止参数溢出。&lt;/p&gt;

  &lt;p&gt;互联网行业，一般特征比较多（维度爆炸），一般采用L1正则，为了降维。&lt;/p&gt;

  &lt;p&gt;特征比较少的情况（比如生物），可以只采用L2正则（这也是默认的）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;4归一化&quot;&gt;4.归一化&lt;/h1&gt;

&lt;p&gt;归一化（Normalization，或标准化）通常是指对输入特征 \(x\) 进行缩放，使其落入特定范围（如 \([0, 1]\)）或具有标准分布（如均值 \(0\)，方差 \(1\)）。&lt;/p&gt;

&lt;h2 id=&quot;41归一化的重要性&quot;&gt;4.1归一化的重要性&lt;/h2&gt;

&lt;p&gt;模型的梯度（参数更新方向）依赖于输入特征 \(x\)。&lt;/p&gt;

&lt;p&gt;回顾逻辑回归的梯度：https://kirsten-1.github.io/2025/11/20/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9906/&lt;/p&gt;

&lt;p&gt;对于整个训练集（所有 \(N\) 个样本），总损失 \(L(\mathbf{w}) = \frac{1}{N} \sum_{i=1}^{N} L_i(\mathbf{w})\) 对 \(w_j\) 的梯度为：&lt;/p&gt;

\[\frac{\partial L}{\partial w_j} = \frac{1}{N} \sum_{i=1}^{N} \frac{\partial L_i}{\partial w_j} = \frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i - y_i) x_{i,j}\]

&lt;p&gt;显然，这个梯度依赖于x，并且梯度更新时，模型会沿着大范围特征（如 \(x_1\)）对应的维度进行大步更新，而在小范围特征（如 \(x_2\)）对应的维度进行小步更新。&lt;/p&gt;

&lt;p&gt;这会导致&lt;strong&gt;梯度下降的等高线变得非常扁平狭长&lt;/strong&gt;，优化过程需要很小的学习率才能避免振荡，导致收敛速度非常慢。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251120233233215.png&quot; alt=&quot;image-20251120233233215&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;归一化使得所有特征 \(x_i\) 具有相似的尺度。&lt;/p&gt;

&lt;p&gt;这保证了所有权重 \(W_i\) 的梯度大致位于同一数量级，使得&lt;strong&gt;等高线更接近圆形&lt;/strong&gt;，梯度下降可以沿着最陡峭的方向平稳快速地收敛。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;归一化间接帮助控制模型内部的线性得分（\(z = W^T x\)），这对于激活函数的稳定性非常重要。&lt;/p&gt;

&lt;p&gt;Softmax 或 Sigmoid 函数的输出 \(f(x)\) 依赖于线性得分 \(z = W^T x\)​。如果输入特征 \(x\) 的值很大，即使 \(W\) 很小， \(z\) 也可能非常大或非常小。&lt;/p&gt;

&lt;p&gt;当 \(z\) 的绝对值过大时，Sigmoid函数会输出接近 0或 1的值(模型可能一开始就学不到新东西，梯度消失了，参数不更新，模型还没怎么训练或者训练其实不到位就认为已经收敛了)，此时函数的&lt;strong&gt;导数（梯度）会非常小&lt;/strong&gt;（进入饱和区）。归一化确保 \(x\) 的尺度适中，可以帮助控制 \(W^T x\) 的范围。&lt;/p&gt;

&lt;p&gt;配合&lt;strong&gt;正则化&lt;/strong&gt;（它限制了 \(W\) 的大小），可以共同确保线性得分 \(W^T x\) 不会过度膨胀，从而&lt;strong&gt;避免激活函数进入饱和区&lt;/strong&gt;，保证训练过程中梯度的有效性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251120232445510.png&quot; alt=&quot;image-20251120232445510&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如何选择归一化的方法？是Min-Max 归一化还是Z-score？&lt;/p&gt;

&lt;p&gt;【Min-Max 归一化】缺点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;对异常值（Outliers）非常敏感。&lt;/strong&gt; 如果数据中存在极大的或极小的异常值，它们会严重挤压其余数据的范围，导致大部分数据点集中在 \([0, 1]\) 范围的一小部分，失去区分度。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;【Z-score归一化】缺点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;不将数据限制在特定的范围 \([0, 1]\) 内，缩放后的特征值可能超出此范围。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;【Min-Max 归一化】优点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;将所有特征值限制在固定的 \([0, 1]\) 范围内，易于解释和比较。&lt;/li&gt;
  &lt;li&gt;在特征数量很少，且特征间差异不大的情况下表现良好。&lt;/li&gt;
  &lt;li&gt;不改变数据的原始分布形状。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;【Z-score归一化】优点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;使得数据符合标准正态分布（但不会改变原始分布的形状，只是进行平移和缩放）。&lt;/li&gt;
  &lt;li&gt;鲁棒性好。算法使用均值和标准差进行缩放，受异常值的影响较小（尤其当数据集较大时）。&lt;/li&gt;
  &lt;li&gt;适用于&lt;strong&gt;要求数据符合正态分布&lt;/strong&gt;或&lt;strong&gt;不依赖于固定范围&lt;/strong&gt;的算法，例如梯度下降法（有助于收敛）和许多线性模型。&lt;/li&gt;
  &lt;li&gt;适用于不知道数据确切范围，但需要保证特征同尺度的场景。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Z-Score 归一化 (Standardization)&lt;/strong&gt; 通常是更优的选择，因为它确保了所有特征的尺度一致，有助于梯度下降算法更快、更稳定地收敛。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Min-Max 归一化&lt;/strong&gt; 也可使用，但在处理带有极端异常值的数据时，需要格外小心。&lt;/p&gt;
</description>
        <pubDate>Thu, 20 Nov 2025 00:00:00 +0000</pubDate>
        <link>https://kirsten-1.github.io/2025/11/20/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9908/</link>
        <guid isPermaLink="true">https://kirsten-1.github.io/2025/11/20/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9908/</guid>
        
        <category>AI思想启蒙</category>
        
        
      </item>
    
      <item>
        <title>【AI思想启蒙07】逻辑回归3到底好不好？模型评价指标 </title>
        <description>&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG&quot;&gt;
&lt;/script&gt;

&lt;h1 id=&quot;1逻辑回归指标&quot;&gt;1.逻辑回归指标&lt;/h1&gt;

&lt;h2 id=&quot;11混淆矩阵&quot;&gt;1.1混淆矩阵&lt;/h2&gt;

&lt;p&gt;混淆矩阵 (Confusion Matrix)是评估分类模型性能的基础。它的四个象限记录了模型预测结果与真实标签之间的四种组合：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;预测为正 (Positive, P)&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;预测为负 (Negative, N)&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;行总计&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;真实为正 (y=1)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;真阳性 (TP)&lt;/strong&gt; \(\text{①}\)&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;假阴性 (FN)&lt;/strong&gt; \(\text{②}\)&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;MP&lt;/strong&gt; (模型预测总正类)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;真实为负 (y=0)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;假阳性 (FP)&lt;/strong&gt; \(\text{③}\)&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;真阴性 (TN)&lt;/strong&gt; \(\text{④}\)&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;MN&lt;/strong&gt; (模型预测总负类)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;各项定义：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;① 真阳性 (True Positive, TP):&lt;/strong&gt; 真实值是 1，模型&lt;strong&gt;正确预测&lt;/strong&gt;为1。 (击中目标)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;② 假阴性 (False Negative, FN):&lt;/strong&gt; 真实值是 1，模型&lt;strong&gt;错误预测&lt;/strong&gt;为0。 (漏报)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;③ 假阳性 (False Positive, FP):&lt;/strong&gt; 真实值是0，模型&lt;strong&gt;错误预测&lt;/strong&gt;为1。 (误报)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;④ 真阴性 (True Negative, TN):&lt;/strong&gt; 真实值是0，模型&lt;strong&gt;正确预测&lt;/strong&gt;为0。 (正确拒绝)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;12准确率&quot;&gt;1.2准确率&lt;/h2&gt;

\[\text{准确率} = \frac{\text{正确预测的样本总数}}{\text{样本总数}}\]

\[\text{准确率} = \frac{\text{TP} + \text{TN}}{\text{MP} + \text{MN}}\]

&lt;p&gt;或者用预测总数表示：&lt;/p&gt;

\[\text{准确率} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{FN} + \text{FP} + \text{TN}}\]

&lt;p&gt;【&lt;strong&gt;数据不平衡问题下准确率的欺骗性&lt;/strong&gt;】尽管准确率计算简单，但在数据不平衡的情况下，它具有欺骗性。如果一个模型总是预测 0，其准确率仍高达 99%，但它在识别关键的&lt;strong&gt;少数类1&lt;/strong&gt; 上的能力（即 &lt;strong&gt;TP&lt;/strong&gt; 和 &lt;strong&gt;FN&lt;/strong&gt;）极差。&lt;/p&gt;

&lt;p&gt;例如一个极度不平衡的二分类场景，总样本量为100个：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;多数类（正样本）：&lt;/strong&gt; 95个正样本（通常记为 \(P\) 或 \(y=1\)）。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;少数类（负样本）：&lt;/strong&gt; 5个负样本（通常记为 \(N\) 或 \(y=0\)）。&lt;/li&gt;
&lt;/ul&gt;

\[\text{准确率} = \frac{\text{TP} + \text{TN}}{\text{样本总数}} = \frac{94 + 1}{100} = \frac{95}{100} = 95\%\]

&lt;p&gt;尽管这个模型的&lt;strong&gt;准确率高达 \(95\%\)&lt;/strong&gt;，但它在&lt;strong&gt;少数类&lt;/strong&gt;上的性能是极差的&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;对多数类（95 个正样本）：&lt;/strong&gt; 模型表现极好，只错判了 1个 \((\text{FN}=1)\)。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;对少数类（5 个负样本）：&lt;/strong&gt; 模型表现极差。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;真阴性 (TN) 只有 1 个&lt;/strong&gt;：在 5 个负样本中，模型只正确识别了 1 个负样本。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;假阳性 (FP) 有 4个&lt;/strong&gt;：模型将 4 个负样本错误地判断为正样本，&lt;strong&gt;识别错误率高达 \(80\%\)&lt;/strong&gt; (\(4/5\))。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;这个例子强有力地证明了，在数据不平衡的情况下，我们必须使用对少数类性能更敏感的指标，例如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;召回率 (Recall)&lt;/strong&gt;：衡量模型发现所有少数类的能力（在这个例子中：\(\text{Recall} = \frac{\text{TP}}{\text{TP}+\text{FN}} = \frac{94}{95} \approx 98.9\%\)）。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;特异度 (Specificity)&lt;/strong&gt;：衡量模型正确识别负类的能力（在这个例子中：\(\text{Specificity} = \frac{\text{TN}}{\text{TN}+\text{FP}} = \frac{1}{1+4} = 20\%\)）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;低特异度 \(20\%\)&lt;/strong&gt; 清晰地揭示了这个模型的真正缺陷，而这是 \(95\%\) 准确率所掩盖的。&lt;/p&gt;

&lt;h2 id=&quot;13召回率&quot;&gt;1.3召回率&lt;/h2&gt;

&lt;p&gt;召回率，也称为&lt;strong&gt;查全率 (Sensitivity)&lt;/strong&gt;，衡量的是模型&lt;strong&gt;找出所有真正正样本的能力&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;召回率的计算公式是：&lt;/p&gt;

\[\text{召回率 (Recall)} = \frac{\text{真阳性}}{\text{真阳性} + \text{假阴性}}\]

\[\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;TP (True Positive, 真阳性):&lt;/strong&gt; 模型正确地预测为正类的样本数。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;FN (False Negative, 假阴性):&lt;/strong&gt; 模型错误地预测为负类的样本数（即&lt;strong&gt;漏掉的正样本&lt;/strong&gt;）。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;分母 \(\text{TP} + \text{FN}\):&lt;/strong&gt; 等于&lt;strong&gt;所有真实的正样本总数&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;召回率回答了这个问题：“在所有真正是正样本的数据中，模型成功找出了多少比例？”&lt;/p&gt;

&lt;p&gt;召回率在那些&lt;strong&gt;“漏报”的成本非常高&lt;/strong&gt;的场景中至关重要。这意味着我们宁愿多报一些假的正样本 (FP)，也不能漏掉任何一个真正的正样本 (FN)。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;应用场景&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;正类 (1) 的定义&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;召回率的重要性&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;医学诊断&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;患者患有某种疾病。&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;高召回率是必需的。&lt;/strong&gt; 漏诊（FN，把患病病人判为健康）可能导致生命危险。多报（FP，把健康人判为患病）只是增加进一步检查的成本。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;反欺诈/安全&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;交易是欺诈。&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;高召回率至关重要。&lt;/strong&gt; 漏掉欺诈交易（FN）会导致巨大的经济损失。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;推荐系统&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;用户对某商品感兴趣。&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;高召回率是基础。&lt;/strong&gt; 必须确保将用户可能感兴趣的所有商品都纳入推荐池中，以供用户选择。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;召回率通常与另一个重要指标&lt;strong&gt;查准率 (Precision)&lt;/strong&gt; 相互制约，二者构成著名的&lt;strong&gt;Precision-Recall 权衡&lt;/strong&gt;：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;查准率 (Precision):&lt;/strong&gt; \(\frac{\text{TP}}{\text{TP} + \text{FP}}\)。衡量模型在所有预测为正的样本中，有多少是真正正确的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;通常，提高召回率（找到更多的正样本）往往是以降低查准率（误报更多的负样本）为代价的。模型设计者需要根据具体业务需求（例如，是“宁愿不错杀一个”还是“宁愿不放过一个”）来调整阈值，在召回率和查准率之间找到最佳平衡点。&lt;/p&gt;

&lt;h2 id=&quot;14准确率和召回率和阀值有关&quot;&gt;1.4准确率和召回率和阀值有关&lt;/h2&gt;

&lt;p&gt;逻辑回归和 Softmax 回归的&lt;strong&gt;正向传播&lt;/strong&gt;（计算 \(h_{\theta}(x)\)）会给每个样本分配一个概率 \(\phi\)。默认情况下，这个阈值通常设定为0.5。&lt;/p&gt;

&lt;p&gt;改变这个阈值，会直接改变模型预测 \(\hat{y}=1\) 和 \(\hat{y}=0\) 的样本数量，从而改变混淆矩阵的四个值（TP, FN, FP, TN），最终影响所有指标。&lt;/p&gt;

&lt;p&gt;这种阈值对指标的影响，引出了 &lt;strong&gt;查准率-召回率权衡 (Precision-Recall Trade-off)&lt;/strong&gt;：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;如果业务目标是“不放过任何一个”（高召回率）：&lt;/strong&gt; 应该选择一个&lt;strong&gt;较低的阈值&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;如果业务目标是“不误判任何一个”（高查准率）：&lt;/strong&gt; 应该选择一个&lt;strong&gt;较高的阈值&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在实际建模中，通常会绘制 &lt;strong&gt;ROC 曲线&lt;/strong&gt;或 &lt;strong&gt;Precision-Recall 曲线&lt;/strong&gt;，来可视化模型在所有可能的阈值下的表现，从而选择最符合业务需求的最佳阈值。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;另外，&lt;strong&gt;阈值与产品形态有关&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;不同的产品形态，其对错误类型的容忍度不同，从而要求模型在召回率和查准率之间做出不同的权衡，而这种权衡是通过调整阈值来实现的。&lt;/p&gt;

&lt;p&gt;模型算法提供的是&lt;strong&gt;概率&lt;/strong&gt;，而&lt;strong&gt;产品形态决定了你如何使用这个概率&lt;/strong&gt;，即决定了要设定一个什么样的阈值，来将模型的通用能力，转化为符合特定商业需求的决策。&lt;/p&gt;

&lt;p&gt;例如：反政治反动暴力黄色，追求的一定是高的召回率（不放过任何一个）。&lt;/p&gt;

&lt;p&gt;这种和产品形态有关的事情，应该由产品经理去做。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;准确和召回跟阈值有关，而阈值的选择依赖于产品形态。那么到底该用什么单纯评价模型的好坏呢？到底什么指标和阈值无关呢？&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;将模型的内在质量（与阈值无关）与应用时的决策（与阈值有关）区分开来。&lt;/strong&gt;当我们要&lt;strong&gt;单纯评价模型“好坏”&lt;/strong&gt;，即评价模型&lt;strong&gt;对概率的排序能力&lt;/strong&gt;时，确实需要使用与阈值无关的指标。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;评价模型&lt;strong&gt;内在质量&lt;/strong&gt;，即评价模型&lt;strong&gt;将正样本和负样本的概率正确分开的能力&lt;/strong&gt;，主要使用以下两个指标，它们基于模型在&lt;strong&gt;所有可能阈值&lt;/strong&gt;下的表现&lt;/p&gt;

&lt;h2 id=&quot;15auc-roc&quot;&gt;1.5AUC-ROC&lt;/h2&gt;

&lt;p&gt;AUC-ROC (Area Under the Receiver Operating Characteristic Curve)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ROC是曲线，AUC是一个值，代表曲线下面的面积。不同模型的优劣可以通过比较AUC值判断。AUC越大，越优秀。AUC值衡量的是模型对正负样本的&lt;strong&gt;排序能力&lt;/strong&gt;。&lt;/p&gt;

  &lt;p&gt;AUC 的核心定义是：&lt;/p&gt;

\[AUC = \frac{\text{正样本比负样本预测分值大的组合数}}{\text{正反样本的组合数量}}\]

  &lt;p&gt;如果从数据集中随机抽取一个正样本和一个负样本，模型给正样本的预测概率（或分数）高于给负样本的预测概率的概率，就是 AUC 值。这个定义与任何具体的阈值无关，它只关心模型输出的概率分数是否能正确地将正样本排在负样本前面。在实际计算中，尤其是当预测分数是&lt;strong&gt;离散&lt;/strong&gt;的时，AUC 可以通过对 ROC 曲线下的&lt;strong&gt;梯形面积&lt;/strong&gt;求和来近似或精确计算&lt;/p&gt;

  &lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251120210220924.png&quot; alt=&quot;image-20251120210220924&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

  &lt;p&gt;AUC-ROC 是评估 GLM 模型（如逻辑回归和 Softmax 回归）&lt;strong&gt;内在能力&lt;/strong&gt;的最佳指标。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ROC 曲线描绘了在所有可能的分类阈值下，模型的&lt;strong&gt;真阳性率 (True Positive Rate, TPR)&lt;/strong&gt; 和 &lt;strong&gt;假阳性率 (False Positive Rate, FPR)&lt;/strong&gt; 之间的关系。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ROC 曲线是从 (0, 0) 到 (1, 1) 的一条曲线。一个优秀的模型应该使得曲线尽可能靠近左上角 (0, 1)，这意味着在很低的误报率（FPR）下，就能获得很高的召回率（TPR）。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;计算方式：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251120194316982.png&quot; alt=&quot;image-20251120194316982&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;TPR (召回率/敏感度):&lt;/strong&gt; \(\frac{\text{TP}}{\text{TP} + \text{FN}}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;FPR (特异度补充):&lt;/strong&gt; \(\frac{\text{FP}}{\text{FP} + \text{TN}}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;AUC-ROC&lt;/strong&gt; 就是这条曲线下的面积。&lt;/li&gt;
  &lt;li&gt;ROC 曲线绘制的是 &lt;strong&gt;真阳性率 (True Positive Rate, TPR)&lt;/strong&gt; 随 &lt;strong&gt;假阳性率 (False Positive Rate, FPR)&lt;/strong&gt; 变化的关系。ROC 曲线代表了分类器&lt;strong&gt;敏感度 (Sensitivity)&lt;/strong&gt; 和 &lt;strong&gt;特异度 (Specificity)&lt;/strong&gt; 之间的权衡。如果你想要提高召回率（TPR），你将不可避免地提高误报率（FPR）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;AUC-ROC 衡量的是模型将随机选择的一个正样本排在随机选择的一个负样本之前的概率。&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;值范围：&lt;/strong&gt; \([0.5, 1]\)。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;值解释：&lt;/strong&gt; 0.5代表随机猜测；1.0代表完美分类。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ROC 曲线本身就是&lt;strong&gt;通过遍历所有阈值&lt;/strong&gt;得到的。因此，&lt;strong&gt;AUC-ROC 作为一个单一数值，总结了模型在所有阈值下的整体性能，与最终选定的特定阈值无关。&lt;/strong&gt; 它评价的是模型对概率的&lt;strong&gt;排序能力&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&quot;auc的值一定越高越好吗不会过拟合吗&quot;&gt;AUC的值一定越高越好吗？不会过拟合吗？&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;AUC 的值是越高越好，但前提是这个高 AUC 是在&lt;/strong&gt; &lt;strong&gt;独立的测试集或验证集&lt;/strong&gt; &lt;strong&gt;上获得的。&lt;/strong&gt; 如果高 AUC 仅在训练集上取得，则很可能存在&lt;strong&gt;过拟合&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;高 AUC（接近 1.0）意味着模型能够更好地将正样本（高概率/分数）排在负样本（低概率/分数）之前。AUC 衡量的是模型概率分数本身的质量。AUC 越高，说明模型在所有可能的阈值下，其表现都越优秀。&lt;/p&gt;

&lt;p&gt;只有当测试集 AUC 较高时，我们才能确信这是一个既具有强大区分能力，又具有良好泛化能力的优秀模型。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;在训练集上，我们希望 AUC 尽可能高（趋近 1.0）。&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;在测试集上，我们希望 AUC 尽可能高，并且与训练集 AUC 的差距尽可能小。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了防止过拟合，我们会在训练 Softmax 回归和逻辑回归等模型时，引入 &lt;strong&gt;L1 或 L2 正则化&lt;/strong&gt;（也称为权重衰减），通过惩罚过大的参数 \(\theta\) 来降低模型复杂度，从而提高模型的泛化能力和测试集 AUC。&lt;/p&gt;

&lt;h2 id=&quot;16auprc&quot;&gt;1.6AUPRC&lt;/h2&gt;

&lt;p&gt;AUPRC (Area Under the Precision-Recall Curve)&lt;/p&gt;

&lt;p&gt;PR 曲线描绘了在所有可能的分类阈值下，模型的&lt;strong&gt;查准率 (Precision)&lt;/strong&gt; 和 &lt;strong&gt;召回率 (Recall)&lt;/strong&gt; 之间的关系。&lt;/p&gt;

&lt;p&gt;AUPRC 衡量的是模型在不同召回水平下查准率的平均表现。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;AUPRC 对数据不平衡问题更敏感。&lt;/strong&gt; 在数据高度不平衡时，AUPRC 的值能更准确地反映模型在少数类上的识别能力。如果产品形态涉及罕见事件，AUPRC 往往是比 AUC-ROC 更好的“纯模型”评估指标。&lt;/p&gt;

&lt;h1 id=&quot;2总结&quot;&gt;2.总结&lt;/h1&gt;

&lt;p&gt;1.正确率    问题：容易被两类不平衡所影响 指标被阈值所影响&lt;/p&gt;

&lt;p&gt;2.准确率和召回率 单独看一类预测结果的指标 问题：指标被阈值所影响&lt;/p&gt;

&lt;p&gt;3.ROC曲线 和auc值：真正反映了模型的能力，表达了正负样本分数的区分度
问题：推理过程不好理解  auc值一般是0.7～0.85之间（面试不要吹的太夸张）&lt;/p&gt;

</description>
        <pubDate>Thu, 20 Nov 2025 00:00:00 +0000</pubDate>
        <link>https://kirsten-1.github.io/2025/11/20/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9907/</link>
        <guid isPermaLink="true">https://kirsten-1.github.io/2025/11/20/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9907/</guid>
        
        <category>AI思想启蒙</category>
        
        
      </item>
    
      <item>
        <title>【AI思想启蒙06】逻辑回归2损失函数推到解析和特征选择优化 </title>
        <description>&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG&quot;&gt;
&lt;/script&gt;

&lt;h1 id=&quot;1逻辑回归回顾&quot;&gt;1.逻辑回归回顾&lt;/h1&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c1&quot;&gt;# -*- encoding:utf-8 -*-
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LogisticRegression&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cross_val_predict&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log_loss&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;readlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;curve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{},{}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;read_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;read_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;test_data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LogisticRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;w0&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# y_pred=model.predict_proba(X_test)
# print(y_pred)
#loss=log_loss(y_test,y_pred)
#print (&quot;KL_loss:&quot;,loss)
#loss=log_loss(y_pred,y_test)
#print (&quot;KL_loss:&quot;,loss)
&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&apos;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
curve_results=curve(X_train,model.coef_.tolist()[0],model.intercept_.tolist()[0])
with open(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;train_with_splitline&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;) as f :
	f.writelines(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;.join(curve_results))
&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&apos;&apos;&lt;/span&gt;

&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251118170657789.png&quot; alt=&quot;image-20251118170657789&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;predict_proba&lt;/code&gt;是用来预测概率的。如果解开下面2行注释：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;predict_proba&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看到：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251118171146410.png&quot; alt=&quot;image-20251118171146410&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到，应该是大于0.5就会有预测结果0，小于0.5预测结果就是1.&lt;/p&gt;

&lt;p&gt;且每一行求和其实是1，因为是/非  是互斥的事件。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;计算KL距离（即损失函数）的函数是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;log_loss&lt;/code&gt;：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251118172001139.png&quot; alt=&quot;image-20251118172001139&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;注意：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;model.fit(X_train, y_train)&lt;/code&gt;就是模型不断学习的过程。即学习合适的参数\(w\)。&lt;/p&gt;

&lt;h1 id=&quot;2逻辑回归的损失函数bce求导与梯度下降&quot;&gt;2.逻辑回归的损失函数BCE求导与梯度下降&lt;/h1&gt;

&lt;p&gt;二元逻辑回归（Binary Logistic Regression）的损失函数——&lt;strong&gt;二元交叉熵损失 (Binary Cross-Entropy Loss, BCE Loss)&lt;/strong&gt; ：&lt;/p&gt;

\[\mathcal{L}_{\text{BCE}}(P || Q) = - \sum_{k \in \{0, 1\}} P(Y=k) \log Q(Y=k) = - [y \log \hat{y} + (1 - y) \log (1 - \hat{y})]=\\ \sum_{i=1}^{n} \left[ y_i \log \frac{y_i}{f_i} + (1 - y_i) \log \frac{1 - y_i}{1 - f_i} \right]\]

&lt;p&gt;逻辑回归模型 (Hypothesis):&lt;/p&gt;

\[\hat{y}_i = \sigma(z_i) = \frac{1}{1 + e^{-z_i}}\]

&lt;p&gt;其中 \(z_i\) 是线性得分：&lt;/p&gt;

\[z_i = \mathbf{w}^T \mathbf{x}_i + b\]

&lt;p&gt;（这里我们把偏置 \(b\) 视为 \(\mathbf{w}\) 中的 \(w_0\) 且 \(\mathbf{x}_i\) 扩展了 \(x_{i,0}\)=1维，简化为 \(\mathbf{w}^T \mathbf{x}_i\)。）&lt;/p&gt;

&lt;h2 id=&quot;21求导&quot;&gt;2.1求导&lt;/h2&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;目标：&lt;/strong&gt; 求损失函数 $$\mathcal{L}_{\text{BCE}}(P&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Q)\(对权重向量\)\mathbf{w}\(中任一分量\)w_j\(的偏导数\)\frac{\partial L_i}{\partial w_j}$$。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;使用链式法则，从 \(L_i\) 逐步向 \(w_j\) 追溯：&lt;/p&gt;

\[\frac{\partial L_i}{\partial w_j} = \frac{\partial L_i}{\partial \hat{y}_i} \cdot \frac{\partial \hat{y}_i}{\partial z_i} \cdot \frac{\partial z_i}{\partial w_j}\]

&lt;p&gt;【步骤 A】: \(\frac{\partial L_i}{\partial \hat{y}_i}\) (损失对预测概率的导数)&lt;/p&gt;

\[\frac{\partial L_i}{\partial \hat{y}_i} = - \left[ y_i \cdot \frac{1}{\hat{y}_i} + (1 - y_i) \cdot \frac{1}{1 - \hat{y}_i} \cdot (-1) \right]\]

\[\frac{\partial L_i}{\partial \hat{y}_i} = - \left[ \frac{y_i}{\hat{y}_i} - \frac{1 - y_i}{1 - \hat{y}_i} \right]\]

\[\frac{\partial L_i}{\partial \hat{y}_i} = - \left[ \frac{y_i (1 - \hat{y}_i) - \hat{y}_i (1 - y_i)}{\hat{y}_i (1 - \hat{y}_i)} \right]\]

\[\frac{\partial L_i}{\partial \hat{y}_i} = - \left[ \frac{y_i - y_i \hat{y}_i - \hat{y}_i + y_i \hat{y}_i}{\hat{y}_i (1 - \hat{y}_i)} \right] = - \frac{y_i - \hat{y}_i}{\hat{y}_i (1 - \hat{y}_i)}\]

&lt;p&gt;【步骤 B】: \(\frac{\partial \hat{y}_i}{\partial z_i}\) (Sigmoid 函数对线性得分的导数)&lt;/p&gt;

&lt;p&gt;Sigmoid 函数 \(\sigma(z) = \frac{1}{1 + e^{-z}}\) 的导数有一个非常简洁的形式：&lt;/p&gt;

\[\frac{\partial \sigma(z_i)}{\partial z_i} = \sigma(z_i) (1 - \sigma(z_i)) = \hat{y}_i (1 - \hat{y}_i)\]

&lt;p&gt;【步骤 C】: \(\frac{\partial z_i}{\partial w_j}\) (线性得分对权重的导数)&lt;/p&gt;

\[z_i = w_0 x_{i,0} + w_1 x_{i,1} + \dots + w_j x_{i,j} + \dots\]

\[\frac{\partial z_i}{\partial w_j} = \frac{\partial}{\partial w_j} (\mathbf{w}^T \mathbf{x}_i) = x_{i,j}\]

&lt;p&gt;【步骤 D】: 合并结果 (最终梯度)&lt;/p&gt;

&lt;p&gt;将 A、B、C 三个结果相乘：&lt;/p&gt;

\[\frac{\partial L_i}{\partial w_j} = \left[ - \frac{y_i - \hat{y}_i}{\hat{y}_i (1 - \hat{y}_i)} \right] \cdot \left[ \hat{y}_i (1 - \hat{y}_i) \right] \cdot \left[ x_{i,j} \right]\]

&lt;p&gt;观察到中间两项相乘可以抵消：&lt;/p&gt;

\[\frac{\partial L_i}{\partial w_j} = - (y_i - \hat{y}_i) x_{i,j} = (\hat{y}_i - y_i) x_{i,j}\]

&lt;hr /&gt;

&lt;p&gt;所以总体损失梯度如下：&lt;/p&gt;

&lt;p&gt;对于整个训练集（所有 \(N\) 个样本），总损失 \(L(\mathbf{w}) = \frac{1}{N} \sum_{i=1}^{N} L_i(\mathbf{w})\) 对 \(w_j\) 的梯度为：&lt;/p&gt;

\[\frac{\partial L}{\partial w_j} = \frac{1}{N} \sum_{i=1}^{N} \frac{\partial L_i}{\partial w_j} = \frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i - y_i) x_{i,j}\]

&lt;h2 id=&quot;22梯度下降逼近最优解&quot;&gt;2.2梯度下降逼近最优解&lt;/h2&gt;

&lt;p&gt;得到梯度后，就可以使用梯度下降法来迭代更新权重 \(\mathbf{w}\)，以最小化总体损失 \(L(\mathbf{w})\)。&lt;/p&gt;

&lt;p&gt;在每次迭代中，权重 \(\mathbf{w}\) 会沿着梯度的&lt;strong&gt;负方向&lt;/strong&gt;进行更新。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;更新公式:&lt;/p&gt;

\[\mathbf{w}_{\text{new}} = \mathbf{w}_{\text{old}} - \alpha \nabla_{\mathbf{w}} L(\mathbf{w}_{\text{old}})\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;对单个权重 \(w_j\) 的更新:&lt;/p&gt;

\[w_{j, \text{new}} = w_{j, \text{old}} - \alpha \cdot \frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i - y_i) x_{i,j}\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其中 \(\alpha\) 是&lt;strong&gt;学习率 (Learning Rate)&lt;/strong&gt;，它控制了每一步更新的步长。&lt;/p&gt;

&lt;p&gt;整个迭代过程如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;初始化：&lt;/strong&gt; 随机初始化权重向量 \(\mathbf{w}\)。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;迭代循环 (直到收敛)：&lt;/p&gt;

    &lt;p&gt;a. 计算预测值： 对于所有样本 \(i=1\) 到 \(N\)，计算线性得分 \(z_i = \mathbf{w}^T \mathbf{x}_i\)，并计算预测概率 \(\hat{y}_i = \sigma(z_i)\)。&lt;/p&gt;

    &lt;p&gt;b. 计算梯度： 计算每个权重 \(w_j\) 的平均梯度 \(\frac{\partial L}{\partial w_j} = \frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i - y_i) x_{i,j}\)。&lt;/p&gt;

    &lt;p&gt;c. 更新权重： 使用更新公式 \(w_{j, \text{new}} = w_{j, \text{old}} - \alpha \cdot \frac{\partial L}{\partial w_j}\) 更新所有权重。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;收敛：&lt;/strong&gt; 当权重向量 \(\mathbf{w}\) 在后续迭代中的变化小于一个预设的阈值，或者达到最大迭代次数时，停止迭代。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这个梯度 \(\frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i - y_i) x_{i,j}\) 直观地表示了&lt;strong&gt;“平均预测误差”&lt;/strong&gt;乘以&lt;strong&gt;“输入特征”&lt;/strong&gt;，模型会根据这个误差调整权重，使预测概率 \(\hat{y}_i\) 更接近真实标签 \(y_i\)。&lt;/p&gt;

&lt;h1 id=&quot;3逻辑回归不用mse而用bce&quot;&gt;3.逻辑回归不用MSE而用BCE&lt;/h1&gt;

&lt;p&gt;MSE均方误差：\(L_{MSE}=\frac{1}{N}\sum_{i=1}^N(f_i-y_i)^2\)&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;BCE二元交叉熵损失：$$\mathcal{L}_{\text{BCE}}(P&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Q) = - \sum_{k \in {0, 1}} P(Y=k) \log Q(Y=k) = - [y \log \hat{y} + (1 - y) \log (1 - \hat{y})]=\ \sum_{i=1}^{n} \left[ y_i \log \frac{y_i}{f_i} + (1 - y_i) \log \frac{1 - y_i}{1 - f_i} \right]$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;MSE求导：对于逻辑回归，模型预测为 \(\hat{y}_i = \sigma(z_i)\)，代入 MSE 损失公式并对权重 \(w_j\) 求导：&lt;/p&gt;

\[L_{\text{MSE}}=\frac{1}{N}\sum_{i=1}^N(\hat{y}_i-y_i)^2\]

\[\frac{\partial L_{\text{MSE}}}{\partial w_j} = \frac{2}{N} \sum_{i} (\hat{y}_i - y_i) \cdot \underbrace{\hat{y}_i (1 - \hat{y}_i)}_{\text{Sigmoid 导数}} \cdot x_{i,j}\]

&lt;p&gt;而BCE求导上面已经求过了：&lt;/p&gt;

\[\frac{\partial L_i}{\partial w_j} = - (y_i - \hat{y}_i) x_{i,j} = (\hat{y}_i - y_i) x_{i,j}\]

&lt;hr /&gt;

&lt;p&gt;为什么逻辑回归不用MSE而用BCE？&lt;/p&gt;

&lt;p&gt;【1】若用MSE，如果初始权重 \(\mathbf{w}\) 被设置得&lt;strong&gt;非常大&lt;/strong&gt;（在绝对值意义上），那么对于大多数样本 \(\mathbf{x}_i\)：&lt;/p&gt;

\[|z_i| = |\mathbf{w}^T \mathbf{x}_i + b|\]

&lt;p&gt;\(z_i\) 的绝对值也会变得&lt;strong&gt;非常大&lt;/strong&gt;。也就是说，当权重很大时，即使特征值 \(x_{i,j}\) 变化很小，也会导致得分 \(z_i\) 发生巨大的变化。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;补充：Sigmoid 函数 \(\sigma(z) = \frac{1}{1 + e^{-z}}\) 具有以下特性：&lt;/p&gt;

  &lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251118191312829.png&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

  &lt;table&gt;
    &lt;thead&gt;
      &lt;tr&gt;
        &lt;th&gt;&lt;strong&gt;\(z_i\) 的值&lt;/strong&gt;&lt;/th&gt;
        &lt;th&gt;&lt;strong&gt;\(y_i=\frac{1}{1 + e^{-z_i}}\) 的值&lt;/strong&gt;&lt;/th&gt;
        &lt;th&gt;&lt;strong&gt;\(y_i\) 接近&lt;/strong&gt;&lt;/th&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;&lt;strong&gt;非常大的正数&lt;/strong&gt; (\(\gg 0\))&lt;/td&gt;
        &lt;td&gt;趋近于 $\frac{1}{1 + 0}$&lt;/td&gt;
        &lt;td&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;&lt;strong&gt;非常大的负数&lt;/strong&gt; (\(\ll 0\))&lt;/td&gt;
        &lt;td&gt;趋近于 $\frac{1}{1 + \infty}$&lt;/td&gt;
        &lt;td&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;接近 0&lt;/td&gt;
        &lt;td&gt;趋近于 $\frac{1}{1 + 1} = 0.5$&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;由于初始权重 \(w\) 很大，使得大多数 \(z_i\) 的绝对值 $$&lt;/td&gt;
      &lt;td&gt;z_i&lt;/td&gt;
      &lt;td&gt;$$ 非常大：&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;如果 \(z_i\) 是一个&lt;strong&gt;非常大的正数&lt;/strong&gt;（例如，100），则 \(\hat{y}_i \approx 1\)。&lt;/li&gt;
  &lt;li&gt;如果 \(z_i\) 是一个&lt;strong&gt;非常大的负数&lt;/strong&gt;（例如，-100），则 \(\hat{y}_i \approx 0\)。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，&lt;strong&gt;当初始权重非常大时，模型对大部分样本的预测会非常自信地给出接近 0 或接近 1 的概率。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当 \(\hat{y}_i\) 非常接近 0 或 1 时，Sigmoid 导数项 \(\hat{y}_i (1 - \hat{y}_i)\) 的值会变得&lt;strong&gt;极小&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;即使模型预测错误（即 \((\hat{y}_i - y_i)\) 不为 0），由于 \(\hat{y}_i (1 - \hat{y}_i)\) 接近 0，&lt;strong&gt;整个梯度也会趋于 0&lt;/strong&gt;。这就是&lt;strong&gt;梯度消失问题&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;即：若初始化W非常大，此时还没有正确分类，模型就已经不太能够学到东西了。&lt;/p&gt;

&lt;p&gt;而且其实就算不考虑极端的情况，本身\(f_i\)就很小，范围就是0到1，根据\(L_{MSE}== \frac{2}{N} \sum_{i} (\hat{y}_i - y_i) \cdot \underbrace{\hat{y}_i (1 - \hat{y}_i)}_{\text{Sigmoid 导数}} \cdot x_{i,j}\)，即\({\hat{y}_i (1 - \hat{y}_i)}\)本身就很小，梯度更新本身就很小了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251118193101978.png&quot; alt=&quot;image-20251118193101978&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;【2】逻辑回归若用MSE，其曲线并不是一个凸函数，可能存在多个局部极小值的点，即非凸的损失曲面意味着它可能存在多个“小山谷”或“小坑”，梯度下降算法可能会收敛到一个局部极小值点，这个点的损失值大于全局最小值。此时就无法找到损失值最小的最佳模型了。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;问：多选几个初始点w能不能避免  存在多个局部极小值的问题呢？&lt;/p&gt;

  &lt;p&gt;其实在机器学习的前沿领域，很多研究都是在讨论如何选初始点，这个策略叫做 &lt;strong&gt;Multi-start Optimization&lt;/strong&gt;（多点启动优化）。但是达不到很好的效果。&lt;/p&gt;

  &lt;p&gt;而且维度如果很大，鞍点（Saddle Points）的数量急剧增加，成为主要的优化障碍。鞍点在某些方向是最小值，但在其他方向是最大值。SGD 可能会在鞍点附近停滞，因为所有方向的梯度都接近零，这比局部极小值更难逃逸。&lt;/p&gt;

  &lt;p&gt;而且在高维空间中，很多“足够好”的局部极小值点的损失值&lt;strong&gt;非常接近&lt;/strong&gt;全局最优解。研究发现，许多局部极小值在泛化能力（即在测试集上的性能）上与全局最优解几乎没有区别。&lt;/p&gt;

  &lt;p&gt;在现代 ML 中，初始化研究的意义在于&lt;strong&gt;确保训练过程稳定、高效&lt;/strong&gt;，并引导模型找到&lt;strong&gt;泛化能力强&lt;/strong&gt;的局部最优解，而不是徒劳地去寻找理论上存在的、但在高维空间中难以捕捉的绝对全局最优解。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;4多分类任务-ovr&quot;&gt;4.多分类任务-OVR&lt;/h1&gt;

&lt;p&gt;为每一个类别训练一个二元分类器，叫做&lt;strong&gt;One-vs-Rest (OvR)&lt;/strong&gt;或者&lt;strong&gt;One-vs-All (OvA)&lt;/strong&gt;。具体逻辑如下：&lt;/p&gt;

&lt;p&gt;假设有 \(N\) 个类别，OvR 方法会训练 \(N\) 个独立的逻辑回归分类器：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;训练 \(N\) 个分类器：&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;为每个类别 \(k \in \{1, 2, \ldots, N\}\) 训练一个二元分类器 \(C_k\)。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;目标：&lt;/strong&gt; \(C_k\) 的任务是判断一个样本&lt;strong&gt;是否属于类别 \(k\)&lt;/strong&gt;，或者说，输出一个概率。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;构造数据集：&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;在训练 \(C_k\) 时，所有属于类别 $k$ 的样本被标记为&lt;strong&gt;正类（Positive, \(y=1\)）&lt;/strong&gt;。&lt;/li&gt;
      &lt;li&gt;所有不属于类别 \(k\) 的样本（即剩下的 \(N-1\) 个类别的样本）都被标记为&lt;strong&gt;负类（Negative, \(y=0\)）&lt;/strong&gt;。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;预测：&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;当一个新样本 \(\mathbf{x}\) 输入时，它会被馈送到所有的 \(N\) 个分类器 \(C_1, C_2, \ldots, C_N\) 中。&lt;/li&gt;
      &lt;li&gt;每个分类器 \(C_k\) 都会输出一个概率 \(P(\mathbf{x} \in \text{Class } k)\)。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;最终决策：&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;样本 \(\mathbf{x}\) 被最终分配给 输出概率最高的那个类别。&lt;/p&gt;

\[\text{Class}(\mathbf{x}) = \underset{k}{\operatorname{argmax}} \left( P(\mathbf{x} \in \text{Class } k) \right)\]
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;OvR概念简单，易于并行化；可以使用任何二元分类器（如 SVM、决策树等）。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;这种方法适合工程，具有一定的开闭原则。&lt;/p&gt;

&lt;p&gt;开闭原则是面向对象设计（OOD）的五大原则之一，它要求：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;“软件实体（类、模块、函数等）应该是对扩展开放的，对修改封闭的。”&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这意味着：当需要添加新功能（例如，增加一个新类别）时，应该通过&lt;strong&gt;扩展&lt;/strong&gt;现有代码来实现，而不是&lt;strong&gt;修改&lt;/strong&gt;已经稳定运行的代码。&lt;/p&gt;

&lt;p&gt;OvR对扩展开放是因为：如果需要从 10 个类别增加到 11 个类别（比如新增一个“短裤”类别），只需要&lt;strong&gt;训练和部署第 11 个独立的二元分类器 \(C_{11}\)&lt;/strong&gt;。你不需要触碰或重新训练那 10 个已经存在的、稳定运行的分类器 \(C_1\) 到 \(C_{10}\)。&lt;/p&gt;

&lt;p&gt;而如果用softmax回归，必须&lt;strong&gt;修改&lt;/strong&gt;模型的输出层（从 10 维改为 11 维），并且必须&lt;strong&gt;使用所有数据&lt;/strong&gt;从头重新训练整个模型，因为所有权重都相互关联。&lt;/p&gt;

&lt;p&gt;因此，在需要&lt;strong&gt;频繁增加新类别&lt;/strong&gt;、追求&lt;strong&gt;模块化&lt;/strong&gt;和&lt;strong&gt;服务高可用性&lt;/strong&gt;的工程实践中，OvR 策略（尤其是使用轻量级模型时）确实展现出更高的工程价值和更好的可扩展性。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;举例：更加形象的理解&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251119143435260.png&quot; alt=&quot;image-20251119143435260&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于上面的多分类任务，可以用下面的方式解决：&lt;/p&gt;

&lt;p&gt;第一：三角形的分类器&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251119143518462.png&quot; alt=&quot;image-20251119143518462&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;第二：叉叉的分类器&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251119143604594.png&quot; alt=&quot;image-20251119143604594&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;第三：正方形的分类器&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251119143628491.png&quot; alt=&quot;image-20251119143628491&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;5多分类任务-softmax回归&quot;&gt;5.多分类任务-softmax回归&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251120155712073.png&quot; alt=&quot;image-20251120155712073&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Softmax 回归可以看作是&lt;strong&gt;逻辑回归的推广&lt;/strong&gt;（从二分类推广到多分类）。&lt;/p&gt;

&lt;h2 id=&quot;51原理&quot;&gt;5.1原理&lt;/h2&gt;

&lt;p&gt;Softmax 回归是假设多项分布的，多项分布可以理解为二项分布的扩展。投硬币是二项分布，掷骰子是多项分布。&lt;/p&gt;

&lt;p&gt;多分类任务中，\(y\) 有多个可能的分类：\(y \in \{1, 2, 3, \ldots, k\}\)，&lt;/p&gt;

&lt;p&gt;每种分类对应的概率：\(\phi_1, \phi_2, \ldots, \phi_k\)。由于 \(\sum_{i=1}^{k} \phi_i = 1\)，所以一般用 \(k-1\) 个参数 \(\phi_1, \phi_2, \ldots, \phi_{k-1}\)。其中：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
\[p(y = i; \phi) = \phi_i\]
  &lt;/li&gt;
  &lt;li&gt;
\[p(y = k; \phi) = 1 - \sum_{i=1}^{k-1} \phi_i\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了将多项分布表达为指数族分布，做以下工作：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;定义 \(T(y) \in \mathbb{R}^{k-1}\) 它不再是一个数而是一个变量&lt;/li&gt;
&lt;/ul&gt;

\[\begin{aligned} T(1) = \begin{bmatrix} 1 \\ 0 \\ \vdots \\ 0 \end{bmatrix}, &amp;amp; T(2) = \begin{bmatrix} 0 \\ 1 \\ \vdots \\ 0 \end{bmatrix}, T(3) = \begin{bmatrix} 0 \\ 0 \\ 1 \\ \vdots \\ 0 \end{bmatrix}, \ldots, \\ &amp;amp; T(k-1) = \begin{bmatrix} 0 \\ 0 \\ \vdots \\ 1 \\ 0 \end{bmatrix}, T(k) = \begin{bmatrix} 0 \\ 0 \\ \vdots \\ 0 \end{bmatrix} \end{aligned}\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;引入指示函数：\(\mathbb{I}\{True\} = 1, \mathbb{I}\{False\} = 0\)&lt;/p&gt;

    &lt;p&gt;$E(T(y)_i) = p(y = i) = \phi_i$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;为什么要将多项分布表达为指数族分布&quot;&gt;为什么要将多项分布表达为指数族分布？&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;指数族分布 (Exponential Family Distribution)&lt;/strong&gt; 是统计学中一类重要的概率分布家族（包括正态分布、伯努利分布、泊松分布、伽马分布等）。&lt;/p&gt;

&lt;p&gt;要注意，学习过的线性回归中，变量服从&lt;strong&gt;高斯分布（正态分布）&lt;/strong&gt;，它属于指数族。&lt;strong&gt;逻辑回归&lt;/strong&gt;变量服从&lt;strong&gt;伯努利分布&lt;/strong&gt;，它也属于指数族。&lt;/p&gt;

&lt;p&gt;现在对于&lt;strong&gt;多分类问题&lt;/strong&gt;，它的输出是 \(k\) 种可能中的一种，服从&lt;strong&gt;多项分布&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;指数族分布是&lt;strong&gt;广义线性模型（GLM）&lt;/strong&gt; 这个“模型大厦”的基石。 GLM 提供了一个&lt;strong&gt;统一的建模流程&lt;/strong&gt;：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;线性部分&lt;/strong&gt;（熟悉的 \(\theta^T x\)）：所有模型都用它来计算“分数”。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;连接函数&lt;/strong&gt;（把分数转成概率或输出）：这个函数是根据分布的性质自动推导出来的。
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;线性回归&lt;/strong&gt;：连接函数是“恒等”（分数就是输出）。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;逻辑回归&lt;/strong&gt;：连接函数是 &lt;strong&gt;Sigmoid&lt;/strong&gt; 函数。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Softmax 回归&lt;/strong&gt;：连接函数是 &lt;strong&gt;Softmax&lt;/strong&gt; 函数。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;通过这种统一，不需要为 Softmax 回归设计一套全新的理论，只是在 GLM 框架下，将随机分量从伯努利（二元）换成了多项（多分类）。&lt;/p&gt;

&lt;p&gt;另外，在线性回归中用 &lt;strong&gt;MSE&lt;/strong&gt;，在逻辑回归中用 &lt;strong&gt;BCE&lt;/strong&gt;。这两种损失函数其实都是&lt;strong&gt;最大似然估计（MLE）&lt;/strong&gt; 的结果。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;MSE&lt;/strong&gt; 是高斯分布下 MLE 的结果。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;BCE&lt;/strong&gt; 是伯努利分布下 MLE 的结果。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;指数族分布有一个极好的数学性质：当用 MLE 的方法来构建&lt;strong&gt;损失函数&lt;/strong&gt;时，这个损失函数（即对数似然函数）通常是&lt;strong&gt;凸函数&lt;/strong&gt;（或凹函数）。这保证了在训练 Softmax 模型时，使用梯度下降等优化算法能够&lt;strong&gt;稳定、快速地找到最佳的模型参数&lt;/strong&gt;，而不用担心陷入局部最优解。&lt;/p&gt;

&lt;p&gt;所有指数族分布都可以写成统一的规范形式：&lt;/p&gt;

\[p(y; \eta) = b(y) \exp(\eta^T T(y) - a(\eta))\]

&lt;p&gt;其中，\(\eta\) 是自然参数（或规范参数），\(T(y)\) 是充分统计量，\(a(\eta)\) 是对数配分函数（用于确保概率之和为 1）。&lt;/p&gt;

&lt;p&gt;一旦将多项分布（或任何其他分布）写成这种形式，就可以利用指数族分布的通用性质来推导其&lt;strong&gt;连接函数&lt;/strong&gt;（link function）、&lt;strong&gt;均值和方差&lt;/strong&gt;等，无需为每种分布从头开始推导。&lt;/p&gt;

&lt;p&gt;解释：&lt;/p&gt;

&lt;p&gt;【1】自然参数是什么？在所有 GLM 模型中，自然参数 \(\eta\) 总是由输入特征的线性组合得到的：&lt;/p&gt;

\[\eta = \theta^T x\]

&lt;p&gt;可以把它理解为&lt;strong&gt;数据特征 \(x\) 经过线性组合后得到的“原始分数”&lt;/strong&gt;，这个分数直接决定了数据服从的概率分布的形状。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;\(η=θ^Tx\) 的含义&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;原始参数 (μ 或 ϕ)&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;线性回归&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;期望本身&lt;/strong&gt;。 \(\eta\) 直接等于我们想要预测的连续值 \(\mu\)（假设 \(\sigma^2=1\)）。&lt;/td&gt;
      &lt;td&gt;均值 \(\mu\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;逻辑回归&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Log-Odds&lt;/strong&gt;。 \(\eta\) 是用来衡量 \(\frac{P(y=1)}{P(y=0)}\) 这个比率的对数。&lt;/td&gt;
      &lt;td&gt;概率 \(\phi\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Softmax 回归&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Log-Odds Ratio&lt;/strong&gt;。 \(\eta_i\) 是衡量第 \(i\) 类相对于基准类 \(k\) 的对数几率比。\(\eta = \begin{bmatrix} \log(\phi_1/\phi_k) \\ \log(\phi_2/\phi_k) \\ \vdots \\ \log(\phi_{k-1}/\phi_k) \end{bmatrix}\)&lt;/td&gt;
      &lt;td&gt;概率向量 \(\phi\)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;【2】什么是响应函数 (\(h(\cdot)\))?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;将模型的原始分数 (\(\eta\))，转化为我们真正想预测和解释的概率、均值或计数（\(\mu\)）&lt;/strong&gt;。&lt;/p&gt;

\[\mu = h(\eta)\]

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;自然参数 η&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;响应函数 μ=h(η)&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;最终输出 μ&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;线性回归&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(\eta = \theta^T x\)&lt;/td&gt;
      &lt;td&gt;\(\mu = \eta\) &lt;strong&gt;(恒等函数)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;均值 \(\mu\)&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;逻辑回归&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(\eta = \text{Logit}(\phi)\)&lt;/td&gt;
      &lt;td&gt;\(\mu = \frac{e^\eta}{1+e^\eta}\) &lt;strong&gt;(Sigmoid 函数)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;概率 \(\phi\)&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Softmax 回归&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(\eta_i = \text{Log-Odds Ratio}\)&lt;/td&gt;
      &lt;td&gt;\(\mu_i = \frac{e^{\eta_i}}{\sum e^{\eta_j}}\) &lt;strong&gt;(Softmax 函数)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;概率 \(\phi_i\)&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;简单来说，如果把 \(\theta^T x\) 看作原始的“火力值”，响应函数 \(h(\cdot)\) 就是将这个火力值转化为&lt;strong&gt;实际命中目标的概率&lt;/strong&gt;（逻辑/Softmax 回归），或者&lt;strong&gt;实际的数值&lt;/strong&gt;（线性回归）。&lt;/p&gt;

&lt;h3 id=&quot;指数族分布&quot;&gt;指数族分布&lt;/h3&gt;

&lt;p&gt;所有指数族分布都可以写成统一的规范形式：&lt;/p&gt;

\[p(y; \eta) = b(y) \exp(\eta^T T(y) - a(\eta))\]

&lt;p&gt;其中，\(b(y)\) 被称为残余项（Base Measure Term）或基测度，\(\eta\) 是自然参数（或规范参数），是一个&lt;strong&gt;只依赖于原分布参数&lt;/strong&gt;（如 \(\mu\) 和 \(\sigma^2\)）的函数，它&lt;strong&gt;不依赖于数据 $y$&lt;/strong&gt;。\(T(y)\) 是充分统计量，只依赖于数据 \(y\)。\(a(\eta)\) 是对数配分函数（用于确保概率之和为 1）。在广义线性模型 (GLM) 中，主要通过&lt;strong&gt;最大似然估计（MLE）&lt;/strong&gt; 来学习参数 \(\theta\)（它隐藏在 \(\eta\) 中）。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(b(y)\) 一般包含原始概率分布函数（PDF 或 PMF）中所有与 \(y\) 相关但与模型参数 \(\eta\) 无关的项。&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;对于连续分布（如高斯分布），\(b(y)\) 通常包含像 \(\frac{1}{\sqrt{2\pi}}\) 或 \(\exp(-\frac{y^2}{2\sigma^2})\) 这样的因子。&lt;/li&gt;
    &lt;li&gt;对于某些离散分布（如伯努利分布），\(b(y)\) 可能只等于 \(1\)。对于泊松分布，它可能包含 \(\frac{1}{y!}\)。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;以线性回归遵循的高斯分布为例&lt;/strong&gt;，通常假设响应变量 \(y\) 服从均值为 \(\mu\)、方差为 \(\sigma^2\) 的高斯分布，即 \(y \sim N(\mu, \sigma^2)\)。为了简化，在 GLM 的推导中，我们通常假设 \(\sigma^2\) 是固定的常数（或为 1）。&lt;/p&gt;

&lt;p&gt;高斯分布的概率密度函数 (PDF) 为：&lt;/p&gt;

\[p(y; \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y - \mu)^2}{2\sigma^2}\right)\]

&lt;p&gt;对上式进行代数展开，并&lt;strong&gt;将 \(\mu\) 作为参数&lt;/strong&gt;：&lt;/p&gt;

\[\begin{aligned} p(y; \mu) &amp;amp;= \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{1}{2\sigma^2}(y^2 - 2y\mu + \mu^2)\right) \\ &amp;amp;= \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{y^2}{2\sigma^2}\right) \cdot \exp\left(\frac{2y\mu}{2\sigma^2} - \frac{\mu^2}{2\sigma^2}\right) \\ &amp;amp;= \left(\frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{y^2}{2\sigma^2}\right)\right) \cdot \exp\left(\left(\frac{\mu}{\sigma^2}\right)y - \left(\frac{\mu^2}{2\sigma^2}\right)\right)\end{aligned}\]

&lt;p&gt;通过与规范形式 \(p(y; \eta) = b(y) \exp(\eta^T T(y) - a(\eta))\) 对比，我们可以确定各部分：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;注意：&lt;strong&gt;充分统计量\(T(y)\)&lt;/strong&gt;只依赖于数据 \(y\)。而\(\eta\) 是一个&lt;strong&gt;只依赖于原分布参数&lt;/strong&gt;（如 \(\mu\) 和 \(\sigma^2\)）的函数，它&lt;strong&gt;不依赖于数据 \(y\)&lt;/strong&gt;。所以\(T(y) = y\)，\(\eta = \frac{\mu}{\sigma^2}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;部分&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;高斯分布 (N(μ,σ2)) 的对应项&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;充分统计量 \(T(y)\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(T(y) = y\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;自然参数 \(\eta\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(\eta = \frac{\mu}{\sigma^2}\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;对数配分函数 \(a(\eta)\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(a(\eta) = \frac{\mu^2}{2\sigma^2} = \frac{(\eta\sigma^2)^2}{2\sigma^2} = \frac{1}{2}\sigma^2 \eta^2\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;残余项 \(b(y)\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(b(y) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{y^2}{2\sigma^2}\right)\)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;自然参数 \(\eta\)​ 和均值 \(\mu\)​ 的关系是 \(\mu = \sigma^2 \eta\)​。在高斯分布的标准 GLM 中，通常假设方差 \(\sigma^2\) 是常数，并且为了简化，我们常取 \(\sigma^2 = 1\)。&lt;/p&gt;

\[\text{如果}\ \sigma^2 = 1\ \text{，则}\ \eta = \frac{\mu}{1} = \mu\]

&lt;p&gt;所以，只有在这种特殊情况下（方差为 1），高斯分布的&lt;strong&gt;规范连接函数&lt;/strong&gt;才是 \(\eta = \mu\)（即恒等连接）。&lt;/p&gt;

&lt;p&gt;所以，在标准 GLM 中，响应函数就是 \(\mu = h(\eta) = \eta\)，这正是&lt;strong&gt;线性回归&lt;/strong&gt;的连接函数（恒等连接）。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;再说逻辑回归（伯努利分布）：响应变量 \(y\) 是二元的（0 或 1），服从均值为 \(\phi\) 的伯努利分布，即 \(y \sim \text{Bernoulli}(\phi)\)。&lt;/p&gt;

&lt;p&gt;伯努利分布的概率质量函数 (PMF) 为：&lt;/p&gt;

\[p(y; \phi) = \phi^y (1 - \phi)^{1-y}\]

&lt;p&gt;转化为指数族规范形式&lt;/p&gt;

&lt;p&gt;对上式进行代数重写：&lt;/p&gt;

\[\begin{aligned} p(y; \phi) &amp;amp;= \exp\left( \log\left(\phi^y (1 - \phi)^{1-y}\right) \right) \\ &amp;amp;= \exp\left( y \log(\phi) + (1-y) \log(1 - \phi) \right) \\ &amp;amp;= \exp\left( y \log(\phi) - y \log(1 - \phi) + \log(1 - \phi) \right) \\ &amp;amp;= \exp\left( y \log\left(\frac{\phi}{1 - \phi}\right) + \log(1 - \phi) \right)\end{aligned}\]

&lt;p&gt;通过与规范形式 $p(y; \eta) = b(y) \exp(\eta^T T(y) - a(\eta))$ 对比，我们可以确定各部分：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;部分&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;伯努利分布 (Bernoulli(ϕ)) 的对应项&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;充分统计量 \(T(y)\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(T(y) = y\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;自然参数 \(\eta\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(\eta = \log\left(\frac{\phi}{1 - \phi}\right)\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;对数配分函数 \(a(\eta)\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(a(\eta) = -\log(1 - \phi) = \log\left(\frac{1}{1 - \phi}\right)\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;残余项 \(b(y)\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(b(y) = 1\)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;自然参数 \(\eta\) 与均值 \(\phi\) 的关系（连接函数）：&lt;/p&gt;

\[\eta = \log\left(\frac{\phi}{1 - \phi}\right)\]

    &lt;p&gt;这就是著名的 Log-Odds 或 Logit 函数。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;响应函数（反向）：&lt;/p&gt;

    &lt;p&gt;将 \(\phi\) 解出来：&lt;/p&gt;

\[e^\eta = \frac{\phi}{1 - \phi} \implies e^\eta (1 - \phi) = \phi \implies e^\eta - \phi e^\eta = \phi\]

\[e^\eta = \phi (1 + e^\eta) \implies \phi = \frac{e^\eta}{1 + e^\eta}\]

    &lt;p&gt;这就是 Sigmoid 函数！&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;关键点：&lt;/strong&gt; &lt;strong&gt;逻辑回归&lt;/strong&gt;的理论基础，正是通过将伯努利分布转化为指数族规范形式，自动推导出了 \(\phi = \frac{e^\eta}{1 + e^\eta}\) 这个 Sigmoid 函数作为它的&lt;strong&gt;响应函数&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;通过这两个例子，可以看到，指数族分布的规范形式确实是&lt;strong&gt;统一各种回归模型的理论框架&lt;/strong&gt;。对于多项分布（Softmax 回归），其过程与伯努利分布的推导非常相似，最终会自动推导出 Softmax 函数作为它的响应函数。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;下面就是softmax回归的推导：&lt;/p&gt;

&lt;p&gt;为了将多项分布纳入广义线性模型 (GLM) 框架，通常需要将其写成指数族分布的标准形式：&lt;/p&gt;

\[p(y; \eta) = b(y) \exp(\eta^T T(y) - a(\eta))\]

&lt;p&gt;在多分类问题中，单个数值 \(y\) 不足以直接作为 \(T(y)\)。因此，引入一个 \((k-1)\) 维的向量 $T(y)$，采用 &lt;strong&gt;“One-Hot Encoding”&lt;/strong&gt;（独热编码）的思想：&lt;/p&gt;

&lt;p&gt;如果 \(y=i\) (对于 \(i=1, \ldots, k-1\))，则 $T(y)$ 的第 \(i\) 个分量是1，其余分量是 0。即：&lt;/p&gt;

\[\begin{aligned} T(1) = \begin{bmatrix} 1 \\ 0 \\ \vdots \\ 0 \end{bmatrix}, &amp;amp; T(2) = \begin{bmatrix} 0 \\ 1 \\ \vdots \\ 0 \end{bmatrix}, T(3) = \begin{bmatrix} 0 \\ 0 \\ 1 \\ \vdots \\ 0 \end{bmatrix}, \ldots, \\ &amp;amp; T(k-1) = \begin{bmatrix} 0 \\ 0 \\ \vdots \\ 1 \\ 0 \end{bmatrix}, T(k) = \begin{bmatrix} 0 \\ 0 \\ \vdots \\ 0 \end{bmatrix} \end{aligned}\]

&lt;p&gt;如果 \(y=k\)，则 \(T(k)\) 是一个全零向量 \(\mathbf{0}\)。&lt;/p&gt;

&lt;p&gt;另外，引入指示函数和期望，&lt;strong&gt;指示函数&lt;/strong&gt; \(\mathbb{I}\{\cdot\}\) 用于将分类结果转化为数学表达式。&lt;/p&gt;

&lt;p&gt;\(\mathbb{I}\{y=i\}\) 的值：如果分类结果是 \(i\)，则为1；否则为0。&lt;/p&gt;

&lt;p&gt;期望 \(E(T(y)_i)\)：&lt;/p&gt;

&lt;p&gt;\(T(y)_i\) 代表向量 \(T(y)\) 的第 $i$ 个分量。&lt;/p&gt;

\[E(T(y)_i) = \sum_{y \in \{1, \ldots, k\}} T(y)_i \cdot p(y) = 1 \cdot p(y=i) + 0 \cdot p(y \ne i) = p(y=i)\]

&lt;p&gt;这验证了 \(T(y)\) 向量的第 \(i\) 个分量的期望，正是第 \(i\) 类发生的概率 \(\phi_i\)（对于 \(i=1, \ldots, k-1\)）。在 Softmax 回归的推导中，这个 \(E(T(y))\) 会被设为 \(\phi\)，并与线性预测 \(\eta\) 通过连接函数联系起来。&lt;/p&gt;

&lt;p&gt;多项分布 PMF（使用指示函数）：&lt;/p&gt;

\[p(y; \phi) = \phi_1^{\mathbb{I}\{y=1\}} \phi_2^{\mathbb{I}\{y=2\}} \cdots \phi_k^{\mathbb{I}\{y=k\}}\]

&lt;p&gt;其中，\(\mathbb{I}\{y=i\}\) 是指示函数，只有当 \(y=i\) 时取 1，否则取 0。&lt;/p&gt;

&lt;p&gt;由于 \(\phi_k = 1 - \sum_{i=1}^{k-1} \phi_i\)，且指示函数的和 \(\sum_{i=1}^{k} \mathbb{I}\{y=i\} = 1\)，所以 \(\mathbb{I}\{y=k\} = 1 - \sum_{i=1}^{k-1} \mathbb{I}\{y=i\}\)。&lt;/p&gt;

\[p(y; \phi) = \phi_1^{\mathbb{I}\{y=1\}} \phi_2^{\mathbb{I}\{y=2\}} \cdots \phi_k^{1 - \sum_{i=1}^{k-1} \mathbb{I}\{y=i\}}\]

&lt;p&gt;即\(p(y; \phi) = \phi_1^{T(y)_1} \phi_2^{T(y)_2} \cdots \phi_k^{1 - \sum_{i=1}^{k-1} T(y)_i}\)&lt;/p&gt;

&lt;p&gt;取对数并写成 \(\exp(\cdot)\) 形式：&lt;/p&gt;

\[\begin{aligned} p(y; \phi) &amp;amp;= \exp\left( T(y)_1 \log(\phi_1) + T(y)_2 \log(\phi_2) + \cdots + \left(1 - \sum_{i=1}^{k-1} T(y)_i\right) \log(\phi_k) \right) \\ &amp;amp;= \exp\left( \sum_{i=1}^{k-1} T(y)_i \log(\phi_i) + \log(\phi_k) - \sum_{i=1}^{k-1} T(y)_i \log(\phi_k) \right)\end{aligned}\]

&lt;p&gt;整理成指数族形式（引入 \(\phi_k\) 作为分母）：将所有 \(T(y)_i\) 对应的项归类，并提取 \(\log(\phi_k)\)：&lt;/p&gt;

\[\begin{aligned} p(y; \phi) &amp;amp;= \exp\left( \sum_{i=1}^{k-1} T(y)_i \left(\log(\phi_i) - \log(\phi_k)\right) + \log(\phi_k) \right) \\ &amp;amp;= \exp\left( \sum_{i=1}^{k-1} T(y)_i \log\left(\frac{\phi_i}{\phi_k}\right) + \log(\phi_k) \right) \\ &amp;amp;= \exp\left( \begin{bmatrix} T(y)_1 \\ \vdots \\ T(y)_{k-1} \end{bmatrix}^T \begin{bmatrix} \log(\phi_1/\phi_k) \\ \vdots \\ \log(\phi_{k-1}/\phi_k) \end{bmatrix} - (-\log(\phi_k)) \right)\end{aligned}\]

&lt;p&gt;与指数族规范形式 \(p(y; \eta) = b(y) \exp(\eta^T T(y) - a(\eta))\) 进行比对，得到最终的模型参数：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;参数&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;多项分布 (Softmax) 的对应项&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;解释&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;\(T(y)\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(T(y) = \begin{bmatrix} \mathbb{I}\{y=1\} \\ \mathbb{I}\{y=2\} \\ \vdots \\ \mathbb{I}\{y=k-1\} \end{bmatrix}\)&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;充分统计量&lt;/strong&gt;，一个 \((k-1)\) 维的独热编码向量。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;\(\eta\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(\eta = \begin{bmatrix} \log(\phi_1/\phi_k) \\ \log(\phi_2/\phi_k) \\ \vdots \\ \log(\phi_{k-1}/\phi_k) \end{bmatrix}\)&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;自然参数&lt;/strong&gt;，一个 \((k-1)\) 维向量，每个分量是 Log-Odds Ratio。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;\(a(\eta)\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(a(\eta) = -\log(\phi_k)\)&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;对数配分函数&lt;/strong&gt;，确保概率总和为 1。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;\(b(y)\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(b(y) = 1\)&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;残余项&lt;/strong&gt;。对于多项分布（没有阶乘项），\(b(y)\) 恒为 1。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;softmax-回归的核心理论基础&quot;&gt;&lt;strong&gt;Softmax 回归&lt;/strong&gt;的核心理论基础&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;自然参数 \(\eta\) 即 Log-Odds Ratio&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;自然参数 \(\eta_i\) 被定义为第 \(i\) 类相对于基准类 \(k\) 的对数几率比 (Log-Odds Ratio)：&lt;/p&gt;

\[\eta_i = \log\left(\frac{\phi_i}{\phi_k}\right)\]

&lt;ol&gt;
  &lt;li&gt;推导出 Softmax 函数（响应函数）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;从 \(\eta\) 的定义，我们可以反推出 Softmax 函数 \(\phi\)：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;步骤 1： 对 \(\eta_i\) 取指数：&lt;/p&gt;

\[e^{\eta_i} = \frac{\phi_i}{\phi_k} \quad \implies \quad \phi_i = \phi_k e^{\eta_i} \quad (\text{for } i=1, \ldots, k-1)\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;步骤 2：&lt;/strong&gt; 第 \(k\) 类可以定义为 \(\phi_k = \phi_k e^{\eta_k}\)，其中 \(\eta_k\) 被隐含地设定为 \(0\)。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;步骤 3： 利用概率总和为 1 的约束：\(\sum_{j=1}^{k} \phi_j = 1\)&lt;/p&gt;

\[\sum_{j=1}^{k} \phi_j = \sum_{j=1}^{k} \phi_k e^{\eta_j} = \phi_k \sum_{j=1}^{k} e^{\eta_j} = 1\]

    &lt;p&gt;解出 \(\phi_k\)：&lt;/p&gt;

\[\phi_k = \frac{1}{\sum_{j=1}^{k} e^{\eta_j}}\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;步骤 4： 将 \(\phi_k\) 代回 \(\phi_i\) 的表达式，即将\(\phi_i = \phi_k e^{\eta_i} \quad (\text{for } i=1, \ldots, k-1)\)带入求和项&lt;/p&gt;

    &lt;p&gt;\(\sum_{j=1}^{k-1} \phi_j + \phi_k = 1\)中，得到\(\sum_{j=1}^{k-1} (\phi_k e^{\eta_j}) + \phi_k = 1\)，从等式左边提取公因式 \(\phi_k\)​：\(\phi_k \left( \sum_{j=1}^{k-1} e^{\eta_j} + 1 \right) = 1\)&lt;/p&gt;

    &lt;p&gt;将括号里的项重新写成一个包含 \(k\) 个类别的求和：(注意，这里的 \(+1\) 其实代表了 \(e^{\eta_k}\)，因为我们隐含地设定了 \(\eta_k = 0\) (\(e^0 = 1\))。)&lt;/p&gt;

\[\phi_k \left( \sum_{j=1}^{k} e^{\eta_j} \right) = 1\]

    &lt;p&gt;现在，解出基准类别 $\phi_k$ 的表达式：&lt;/p&gt;

\[\phi_k = \frac{1}{\sum_{j=1}^{k} e^{\eta_j}} \quad\]

    &lt;p&gt;最后一步，我们回到关系式 （$\phi_i = \phi_k e^{\eta_i}$），将我们刚刚解出的表达式  代入 \(\phi_k\) 的位置：&lt;/p&gt;

    &lt;p&gt;得到著名的 Softmax 函数：&lt;/p&gt;

\[\phi_i = \frac{e^{\eta_i}}{\sum_{j=1}^{k} e^{\eta_j}}\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这一步是标准的归一化技巧：先用基准项（\(\phi_k\)）表示所有其他项（\(\phi_i\)），然后利用所有项的和等于 1 的约束，解出基准项，最后代回得到通用公式。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Log-Odds Ratio（对数几率比）&lt;/strong&gt; 是 Softmax 回归（和 Logit 回归）中 \(\eta\) 的核心意义。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Odds (几率)：&lt;/strong&gt; \(\frac{P(\text{事件发生})}{P(\text{事件不发生})} = \frac{\phi}{1-\phi}\)。几率告诉我们事件发生的可能性是不发生的可能性的多少倍。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Log-Odds (对数几率)：&lt;/strong&gt; \(\log(\frac{\phi}{1-\phi})\)。取对数是为了将范围 \([0, \infty)\) 映射到 \((-\infty, \infty)\)，从而可以与线性模型 \(\theta^T x\) 相匹配。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在 Softmax 回归 中，面对 \(k\) 个类别，用的是 Ratio (比率)：&lt;/p&gt;

\[\eta_i = \log\left(\frac{\phi_i}{\phi_k}\right)\]

&lt;p&gt;这意味着：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;不再与“不发生”作比较，而是与&lt;strong&gt;一个选定的基准类别 \(k\)&lt;/strong&gt; 作比较。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;特殊意义：&lt;/strong&gt; \(\eta_i\) 的数值直接告诉我们，&lt;strong&gt;第 \(i\) 类发生的对数几率，相对于第 \(k\) 类发生的对数几率，高出了多少。&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;如果 \(\theta_i\) 是特征 \(x_j\) 对应的模型系数，那么 \(\theta_i\) 代表着：&lt;strong&gt;当 \(x_j\) 增加 1 个单位时，第 \(i\) 类相对于基准类 \(k\) 的对数几率比 \(\eta_i\) 增加 \(\theta_i\) 个单位。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这种 Log-Odds Ratio 的形式，在统计学上是处理多项分布参数的最自然、最简洁的方式，也是确保 Softmax 模型能够被完美纳入指数族和 GLM 框架的关键。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;注意：\(\eta_k = \log\left(\frac{\phi_k}{\phi_k}\right) = \log(1) = 0\)&lt;/p&gt;

&lt;p&gt;将 \(\eta_k\) 设为 \(0\) 意味着&lt;strong&gt;第 \(k\) 类被选定为所有比较的基准类别&lt;/strong&gt;。所有其他的线性预测器 \(\eta_1, \ldots, \eta_{k-1}\) 都被解释为相对于 \(\eta_k\) 的差异。&lt;/p&gt;

&lt;p&gt;这种设置与处理多项分布参数时使用 \(k-1\) 个参数（因为 \(\sum \phi_i = 1\)）的，最终只需要学习 \(k-1\) 组系数向量 \(\theta_1, \ldots, \theta_{k-1}\)。第 \(k\) 组系数 \(\theta_k\) 被隐含地设定为&lt;strong&gt;零向量&lt;/strong&gt;（或被吸收进截距项）。&lt;/p&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;概率表示： Softmax 回归预测的是在给定输入 \(x\) 和模型参数 \(\theta\) 的条件下，输出为类别 \(i\) 的概率 $$p(y=i&lt;/td&gt;
      &lt;td&gt;x; \theta)\(，记为\)\phi_i$$。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[p(y = i | x; \theta) = \phi_i\]

&lt;p&gt;响应函数： 根据指数族分布的推导（我们之前讨论过），概率 \(\phi_i\) 由自然参数 \(\eta_i\) 经 Softmax 函数转换得到：&lt;/p&gt;

\[\phi_i = \frac{e^{\eta_i}}{\sum_{j=1}^{k} e^{\eta_j}}\]

&lt;p&gt;线性预测子： Softmax 回归作为广义线性模型（GLM），其自然参数 \(\eta_i\) 由输入 \(x\) 的线性组合构成：&lt;/p&gt;

\[\eta_i = \theta_i^T x\]

&lt;p&gt;注意：这里 \(\theta_i\) 是一个与类别 \(i\) 相关的参数向量，整个模型有 \(k\) 个这样的向量 \(\theta_1, \theta_2, \ldots, \theta_k\)。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;最终假设函数:&lt;/strong&gt; 将线性预测子代入响应函数，得到了 Softmax 回归的最终假设函数 \(h_{\theta}(x)\)，它输出一个 \(k\) 维的概率向量：&lt;/p&gt;

\[h_{\theta}(x) = \begin{cases} P(y=1|x) = \frac{e^{\theta_1^T x}}{\sum_{j=1}^{k} e^{\theta_j^T x}}, &amp;amp; y=1 \\ P(y=2|x) = \frac{e^{\theta_2^T x}}{\sum_{j=1}^{k} e^{\theta_j^T x}}, &amp;amp; y=2 \\ \vdots \\ P(y=k|x) = \frac{e^{\theta_k^T x}}{\sum_{j=1}^{k} e^{\theta_j^T x}}, &amp;amp; y=k \end{cases}\]

&lt;p&gt;&lt;strong&gt;\(h_{\theta}(x)\) 的输出&lt;/strong&gt; 是一个向量 \([\phi_1, \phi_2, \ldots, \phi_k]^T\)，其中 \(\sum_{i=1}^k \phi_i = 1\)，且 \(0 \le \phi_i \le 1\)。&lt;/p&gt;

&lt;p&gt;Softmax 是一个&lt;strong&gt;归一化指数函数&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251120141218434.png&quot; alt=&quot;image-20251120141218434&quot; /&gt;&lt;/p&gt;

&lt;p&gt;假设我们有 \(k=3\) 个类别，输入 \(x\) 经过线性预测（即 \(\eta_i = \theta_i^T x\)）后，得到了 \(k=3\) 个原始分数 \(z_1, z_2, z_3\)：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;步骤&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;原始分数 (自然参数 η)&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;转换操作&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;结果值 (指数项 eη)&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;最终概率 ϕi&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;1.&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(z_1 = 3\)&lt;/td&gt;
      &lt;td&gt;\(e^{z_1}\)&lt;/td&gt;
      &lt;td&gt;\(e^3 \approx 20\)&lt;/td&gt;
      &lt;td&gt;\(y_1 = \frac{20}{23.75} \approx 0.88\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;2.&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(z_2 = 1\)&lt;/td&gt;
      &lt;td&gt;\(e^{z_2}\)&lt;/td&gt;
      &lt;td&gt;\(e^1 \approx 2.7\)&lt;/td&gt;
      &lt;td&gt;\(y_2 = \frac{2.7}{23.75} \approx 0.12\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;3.&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(z_3 = -3\)&lt;/td&gt;
      &lt;td&gt;\(e^{z_3}\)&lt;/td&gt;
      &lt;td&gt;\(e^{-3} \approx 0.05\)&lt;/td&gt;
      &lt;td&gt;\(y_3 = \frac{0.05}{23.75} \approx 0\)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Softmax 机制:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1.&lt;strong&gt;指数化 (Exponentiation):&lt;/strong&gt; 对每个原始分数 \(z_i\)（即 \(\eta_i\)）取指数 \(e^{z_i}\)。将分数映射到 \((0, \infty)\) 的范围内，确保输出的概率是非负的。同时，指数函数会&lt;strong&gt;放大分数之间的差异&lt;/strong&gt;，分数越高，其指数值增长得越快。&lt;/li&gt;
  &lt;li&gt;2.&lt;strong&gt;求和 (Normalization Term):&lt;/strong&gt; 计算所有指数项的和 \(\sum_{j=1}^3 e^{z_j}\)，确保所有概率之和为 1 的&lt;strong&gt;归一化因子&lt;/strong&gt;（对应于指数族中的 \(e^{a(\eta)}\)）。&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;3.&lt;strong&gt;归一化 (Division):&lt;/strong&gt; 将每个指数项除以总和，得到最终的概率 $$y_i = P(C_i&lt;/td&gt;
          &lt;td&gt;x)$$。&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;softmax输出的是概率分布，但其名称“Softmax”来源于它是一个&lt;strong&gt;平滑的、可微分的“argmax”函数&lt;/strong&gt;的近似。它会给最大的输入分数（比如上面的\(z_1=3\)）分配一个&lt;strong&gt;远大于&lt;/strong&gt;其他分数的概率（\(0.88\)），从而&lt;strong&gt;放大最大值&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;多分类交叉熵损失&quot;&gt;多分类交叉熵损失&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251120143158820.png&quot; alt=&quot;image-20251120143158820&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Softmax 回归的损失函数是通过最大化数据样本的&lt;strong&gt;对数似然函数&lt;/strong&gt;推导出来的，这个函数就是著名的&lt;strong&gt;多分类交叉熵损失 (Multiclass Cross-Entropy Loss)&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;【1.似然函数 (Likelihood Function)】&lt;/p&gt;

&lt;p&gt;假设有一个包含 \(m\) 个独立同分布 (i.i.d.) 训练样本的数据集 \(\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \ldots, (x^{(m)}, y^{(m)})\}\), 其中 \(y^{(i)} \in \{1, \ldots, k\}\)。&lt;/p&gt;

&lt;p&gt;模型的参数是 \(\theta = \{\theta_1, \ldots, \theta_k\}\)。&lt;/p&gt;

&lt;p&gt;似然函数 \(\mathcal{L}(\theta)\) 是观察到整个数据集的概率，根据独立性原则，它是每个样本概率的乘积：&lt;/p&gt;

\[\mathcal{L}(\theta) = P(y^{(1)}, \ldots, y^{(m)} | x^{(1)}, \ldots, x^{(m)}; \theta) = \prod_{i=1}^{m} P(y^{(i)} | x^{(i)}; \theta)\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;对于单个样本 \((x, y)\)，我们知道 $$P(y=j&lt;/td&gt;
      &lt;td&gt;x) = \phi_j\(。由于\)y\(只有一个取值，我们可以使用我们之前定义的指示函数\)\mathbb{I}{y=j}\(或充分统计量\)T(y)_j$$ 来简洁地表示这个概率：&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[P(y | x; \theta) = \prod_{j=1}^{k} \left( \phi_j \right)^{\mathbb{I}\{y=j\}}\]

&lt;p&gt;其中 \(\phi_j\) 是 Softmax 函数：\(\phi_j = \frac{e^{\theta_j^T x}}{\sum_{l=1}^{k} e^{\theta_l^T x}}\)。&lt;/p&gt;

&lt;p&gt;将这个概率代入似然函数：&lt;/p&gt;

\[\mathcal{L}(\theta) = \prod_{i=1}^{m} \left[ \prod_{j=1}^{k} \left( \phi_j^{(i)} \right)^{\mathbb{I}\{y^{(i)}=j\}} \right]\]

&lt;p&gt;【2.对数似然函数 (Log-Likelihood Function)】&lt;/p&gt;

&lt;p&gt;为了简化计算（将乘积转化为求和）并利用指数族分布的优点，我们取对数似然 \(\ell(\theta) = \log \mathcal{L}(\theta)\)：&lt;/p&gt;

\[\ell(\theta) = \log \left( \prod_{i=1}^{m} \prod_{j=1}^{k} \left( \phi_j^{(i)} \right)^{\mathbb{I}\{y^{(i)}=j\}} \right)\]

\[\ell(\theta) = \sum_{i=1}^{m} \sum_{j=1}^{k} \mathbb{I}\{y^{(i)}=j\} \log\left( \phi_j^{(i)} \right)\]

&lt;p&gt;【3.损失函数 (Loss Function)】&lt;/p&gt;

&lt;p&gt;在机器学习中，我们通常采用&lt;strong&gt;最小化损失函数&lt;/strong&gt;的方式来训练模型，而不是最大化对数似然函数。&lt;/p&gt;

&lt;p&gt;损失函数 \(J(\theta)\) 被定义为负的平均对数似然函数：&lt;/p&gt;

\[J(\theta) = - \frac{1}{m} \ell(\theta) = - \frac{1}{m} \sum_{i=1}^{m} \sum_{j=1}^{k} \mathbb{I}\{y^{(i)}=j\} \log\left( \phi_j^{(i)} \right)\]

&lt;p&gt;【4.交叉熵的本质】&lt;/p&gt;

&lt;p&gt;这个函数 \(J(\theta)\) 就是&lt;strong&gt;多分类交叉熵损失 (Multiclass Cross-Entropy Loss)&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;为什么叫交叉熵？在信息论中，交叉熵 \(H(p, q)\) 衡量的是用分布 \(q\)（模型预测的概率 \(\phi\)）来编码分布 \(p\)（真实标签 \(y\) 的概率分布）所需要的平均比特数。&lt;/p&gt;

&lt;p&gt;真实标签 \(y\) 的概率分布 \(p\) 是一个独热编码的分布，例如，如果真实标签是类别 3，那么 \(p\) 就是 \([0, 0, 1, 0, \ldots]^T\)。&lt;/p&gt;

&lt;p&gt;对于一个样本 \(i\)，其真实概率分布 \(p^{(i)}\) 是 \(p_j^{(i)} = \mathbb{I}\{y^{(i)}=j\}\)。&lt;/p&gt;

&lt;p&gt;样本 \(i\) 的交叉熵损失为：&lt;/p&gt;

\[J^{(i)}(\theta) = - \sum_{j=1}^{k} p_j^{(i)} \log\left( \phi_j^{(i)} \right)\]

&lt;p&gt;由于 \(p_j^{(i)}\) 只有在 \(j\) 等于真实标签 \(y^{(i)}\) 时才为1，其余为0 ，所以上式简化为：&lt;/p&gt;

\[J^{(i)}(\theta) = - \log\left( \phi_{y^{(i)}}^{(i)} \right)\]

&lt;p&gt;其中&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;\(\phi_{y^{(i)}}^{(i)}\)&lt;/strong&gt; 是模型预测的&lt;strong&gt;正确类别&lt;/strong&gt;的概率。&lt;/li&gt;
  &lt;li&gt;\(\log(\phi_{y^{(i)}}^{(i)})\) 随着正确概率的增大而增大（但仍为负数）。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;最小化&lt;/strong&gt; \(J(\theta)\) 等同于&lt;strong&gt;最大化&lt;/strong&gt;正确类别的预测概率 \(\phi_{y^{(i)}}^{(i)}\)。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最大化多项分布的对数似然，等价于最小化&lt;strong&gt;多分类交叉熵损失&lt;/strong&gt;。这一损失函数具有&lt;strong&gt;凸性&lt;/strong&gt;（由于指数族分布的良好性质），保证了模型可以通过梯度下降等优化算法稳定地找到全局最优参数。&lt;/p&gt;

&lt;h3 id=&quot;损失函数的梯度&quot;&gt;损失函数的梯度&lt;/h3&gt;

&lt;p&gt;现在来推导 Softmax 回归损失函数（多分类交叉熵）相对于模型参数 \(\theta_j\) 的梯度。这个梯度是训练模型时使用梯度下降法的核心。&lt;/p&gt;

&lt;p&gt;为了简洁，我们只推导&lt;strong&gt;单个样本&lt;/strong&gt;的损失函数 \(J^{(i)}(\theta)\) 相对于&lt;strong&gt;某个特定类别 \(j\) 的参数向量 \(\theta_j\)&lt;/strong&gt; 的梯度。&lt;/p&gt;

&lt;p&gt;单个样本 \((x, y)\) 的损失函数（负对数似然）为：&lt;/p&gt;

\[J(\theta) = - \log\left( \phi_{y} \right)\]

&lt;p&gt;其中，\(\phi_{y}\) 是模型对真实类别 \(y\) 预测的概率。&lt;/p&gt;

&lt;p&gt;\(\phi_j\) 是 Softmax 函数：&lt;/p&gt;

\[\phi_j = \frac{e^{\eta_j}}{\sum_{l=1}^{k} e^{\eta_l}}\]

&lt;p&gt;并且 \(\eta_j = \theta_j^T x\)。&lt;/p&gt;

&lt;p&gt;我们的目标是计算损失函数 \(J(\theta)\) 对第 \(j\) 个类别的参数向量 \(\theta_j\) 的偏导数：&lt;/p&gt;

\[\nabla_{\theta_j} J(\theta) = \frac{\partial J(\theta)}{\partial \theta_j}\]

&lt;hr /&gt;

&lt;p&gt;\(J(\theta)\) 是关于 \(\phi_y\) 的函数，\(\phi_y\) 是关于 \(\eta_l\) 的函数，而 \(\eta_l\) 是关于 \(\theta_j\) 的函数，我们需要使用链式法则：&lt;/p&gt;

\[\frac{\partial J(\theta)}{\partial \theta_j} = \sum_{l=1}^{k} \left( \frac{\partial J(\theta)}{\partial \phi_l} \cdot \frac{\partial \phi_l}{\partial \eta_j} \cdot \frac{\partial \eta_j}{\partial \theta_j} \right)\]

&lt;p&gt;\(\frac{\partial J(\theta)}{\partial \phi_l}\) 只有在 \(l=y\) 时非零，所以简化为：&lt;/p&gt;

\[\frac{\partial J(\theta)}{\partial \theta_j} = \frac{\partial J(\theta)}{\partial \phi_y} \cdot \frac{\partial \phi_y}{\partial \eta_j} \cdot \frac{\partial \eta_j}{\partial \theta_j}\]

&lt;p&gt;然后计算各部分偏导数：&lt;/p&gt;

&lt;p&gt;A. \(\frac{\partial J(\theta)}{\partial \phi_y}\) (损失函数对概率的导数)&lt;/p&gt;

\[J(\theta) = - \log(\phi_y)\]

\[\frac{\partial J(\theta)}{\partial \phi_y} = \frac{\partial (-\log(\phi_y))}{\partial \phi_y} = - \frac{1}{\phi_y}\]

&lt;p&gt;B. \(\frac{\partial \eta_j}{\partial \theta_j}\) (自然参数对参数的导数)&lt;/p&gt;

\[\eta_j = \theta_j^T x\]

\[\frac{\partial \eta_j}{\partial \theta_j} = x\]

&lt;p&gt;(注意 \(\frac{\partial}{\partial \theta_j}\) 意味着对向量 \(\theta_j\) 求梯度，结果是向量 \(x\)。)&lt;/p&gt;

&lt;p&gt;C. \(\frac{\partial \phi_y}{\partial \eta_j}\) (Softmax 对原始分数的导数)&lt;/p&gt;

&lt;p&gt;这是最复杂的一步，需要根据 \(j\) 是否等于真实类别 \(y\) 进行分情况讨论：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Case 1: \(j = y\) (计算 \(\phi_y\) 对 \(\eta_y\) 的导数)&lt;/strong&gt;&lt;/p&gt;

\[\phi_y = \frac{e^{\eta_y}}{\sum_{l=1}^{k} e^{\eta_l}}\]

&lt;p&gt;使用商法则 \(\left(\frac{u}{v}\right)&apos; = \frac{u&apos;v - uv&apos;}{v^2}\)，其中 \(u = e^{\eta_y}\)，\(v = \sum_{l=1}^{k} e^{\eta_l}\)。&lt;/p&gt;

\[\frac{\partial \phi_y}{\partial \eta_y} = \frac{(e^{\eta_y}) \sum_{l=1}^{k} e^{\eta_l} - e^{\eta_y} (e^{\eta_y})}{\left(\sum_{l=1}^{k} e^{\eta_l}\right)^2}\]

\[= \frac{e^{\eta_y}}{\sum_{l=1}^{k} e^{\eta_l}} - \frac{e^{\eta_y} e^{\eta_y}}{\left(\sum_{l=1}^{k} e^{\eta_l}\right)^2} = \phi_y - \phi_y \cdot \phi_y\]

\[\frac{\partial \phi_y}{\partial \eta_y} = \phi_y (1 - \phi_y)\]

&lt;p&gt;&lt;strong&gt;Case 2: \(j \ne y\) (计算 \(\phi_y\) 对 \(\eta_j\) 的导数)&lt;/strong&gt;&lt;/p&gt;

\[\frac{\partial \phi_y}{\partial \eta_j} = \frac{(0) \sum_{l=1}^{k} e^{\eta_l} - e^{\eta_y} (e^{\eta_j})}{\left(\sum_{l=1}^{k} e^{\eta_l}\right)^2}\]

\[= - \frac{e^{\eta_y}}{\sum_{l=1}^{k} e^{\eta_l}} \cdot \frac{e^{\eta_j}}{\sum_{l=1}^{k} e^{\eta_l}} = - \phi_y \cdot \phi_j\]

\[\frac{\partial \phi_y}{\partial \eta_j} = - \phi_y \phi_j\]

&lt;hr /&gt;

&lt;p&gt;现在，将 A, B, C 代回链式法则，同样分 \(j=y\) 和 \(j \ne y\) 两种情况。&lt;/p&gt;

\[\frac{\partial J(\theta)}{\partial \theta_j} = \frac{\partial J(\theta)}{\partial \phi_y} \cdot \frac{\partial \phi_y}{\partial \eta_j} \cdot \frac{\partial \eta_j}{\partial \theta_j}\]

&lt;p&gt;&lt;strong&gt;Case 1: \(j = y\) (真实类别的参数梯度)&lt;/strong&gt;&lt;/p&gt;

\[\nabla_{\theta_y} J(\theta) = \underbrace{\left(- \frac{1}{\phi_y}\right)}_{\text{A}} \cdot \underbrace{\left(\phi_y (1 - \phi_y)\right)}_{\text{C1}} \cdot \underbrace{(x)}_{\text{B}}\]

\[= - (1 - \phi_y) x = (\phi_y - 1) x\]

&lt;p&gt;&lt;strong&gt;Case 2: \(j \ne y\) (非真实类别的参数梯度)&lt;/strong&gt;&lt;/p&gt;

\[\nabla_{\theta_j} J(\theta) = \underbrace{\left(- \frac{1}{\phi_y}\right)}_{\text{A}} \cdot \underbrace{\left(- \phi_y \phi_j\right)}_{\text{C2}} \cdot \underbrace{(x)}_{\text{B}}\]

\[= \phi_j x\]

&lt;blockquote&gt;
  &lt;p&gt;可以用一个统一的公式来表达梯度 \(\nabla_{\theta_j} J(\theta)\)：&lt;/p&gt;

\[\nabla_{\theta_j} J(\theta) = (\phi_j - \mathbb{I}\{y=j\}) x\]

  &lt;p&gt;其中，\(\mathbb{I}\{y=j\}\) 是指示函数：如果 \(j\) 是真实类别 \(y\)，则为1；否则为0。&lt;/p&gt;

  &lt;p&gt;【注意】括号内的项 \((\phi_j - \mathbb{I}\{y=j\})\) 是&lt;strong&gt;预测概率&lt;/strong&gt;和&lt;strong&gt;真实标签&lt;/strong&gt;之间的&lt;strong&gt;误差&lt;/strong&gt;。&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;如果 \(j\) 是真实类别 \(y\)：&lt;/strong&gt; 误差是 \((\phi_y - 1)\)。由于 \(\phi_y &amp;lt; 1\)，误差是负的。梯度下降会向&lt;strong&gt;增加&lt;/strong&gt; \(\phi_y\) 的方向调整 \(\theta_y\)。&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;如果 \(j\) 不是真实类别 \(y\)：&lt;/strong&gt; 误差是 \((\phi_j - 0) = \phi_j\)。梯度是正的。梯度下降会向&lt;strong&gt;减少&lt;/strong&gt; \(\phi_j\) 的方向调整 \(\theta_j\)。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;模型的参数 \(\theta_j\) 的更新量正比于：&lt;/p&gt;

\[\text{误差} \times \text{输入特征}\]

&lt;p&gt;&lt;strong&gt;这个公式与线性回归和逻辑回归的梯度公式形式惊人地相似，展现了 GLM 框架的统一性。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;有了这个梯度，我们就可以使用梯度下降（或其变体）来迭代更新所有 \(\theta_j\) 向量，直到损失函数收敛到最小值。&lt;/p&gt;

&lt;h2 id=&quot;案例&quot;&gt;案例&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision.transforms&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 1. 数据加载与预处理 ---
# 定义转换：将图像转换为张量，并归一化到 [0, 1]
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 将 PIL Image 或 NumPy ndarray 转换为 Tensor
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# PyTorch 的 ToTensor 默认会将像素值除以 255.0，实现归一化
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 加载 FashionMNIST 数据集
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mnist_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FashionMNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;./data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mnist_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FashionMNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;./data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 数据读取
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mnist_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mnist_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 标签对应的服饰名字
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_text_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;text_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;t-shirt&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;trouser&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;pullover&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;dress,&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;coat&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sandal&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;shirt&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sneaker&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;bag&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;ankle boot&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# label 是一个 Tensor 或 NumPy 数组
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 2. 定义模型 ---
# 在 PyTorch 中，我们使用 nn.Module 来定义模型。
# Softmax 回归本质上是一个线性层。
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SoftmaxRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SoftmaxRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# 784 (输入特征) -&amp;gt; 10 (输出类别)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# x 的形状是 (batch_size, 1, 28, 28)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# 我们需要将其展平为 (batch_size, 784)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
        &lt;span class=&quot;c1&quot;&gt;# 然后通过线性层 (这一步包含了 wx + b)
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 初始化模型
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 28 * 28
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SoftmaxRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 3. 定义损失函数和优化器 ---
# PyTorch 的 nn.CrossEntropyLoss 包含了 Softmax 运算和交叉熵计算，因此
# 模型的 forward 函数只需要输出未经 Softmax 的原始得分 (logits)。
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 损失函数: 交叉熵 (会自动应用 Softmax)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; 

&lt;span class=&quot;c1&quot;&gt;# 优化器: 随机梯度下降 (SGD)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 4. 辅助函数 ---
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;evaluate_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;acc_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 在测试阶段禁用梯度计算
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# net(X) 返回 logits (未经 Softmax 的得分)
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# argmax(dim=1) 找到概率最高的类别
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;acc_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 5. 训练模型 ---
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;开始训练...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_loss_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_acc_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# 清除梯度
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; 
        
        &lt;span class=&quot;c1&quot;&gt;# 前向传播 (计算预测的 logits)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# 计算损失
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# 反向传播 (计算梯度)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# 更新模型参数
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# 统计训练指标
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;train_loss_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_acc_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 模型训练完之后进行测试
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;test_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;evaluate_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch %d. Loss: %f, Train acc %f, Test acc %f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loss_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_acc_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;训练完成。&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 6. 对新的样本进行标签预测 ---
# 取测试集前 9 个样本
# --- 6. 对新的样本进行标签预测 ---
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 从数据集中提取前 num_samples 个样本
# mnist_test[i] 返回的是 (Image Tensor, label scalar)
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 存储提取出的图像和标签
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;true_labels_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;img_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label_scalar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mnist_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;true_labels_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label_scalar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 将图像列表堆叠成一个大的 Tensor (batch_size, channels, height, width)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;c1&quot;&gt;# 将标签列表转换为 Tensor
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;true_labels_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;true labels:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 使用新的 label Tensor
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get_text_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 禁用梯度，进行预测
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 确保模型使用的是展平的输入 (784)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;y_hat_logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;c1&quot;&gt;# 找到预测概率最高的类别
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;predicted_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_hat_logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;predicted labels:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get_text_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predicted_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251118205831477.png&quot; alt=&quot;image-20251118205831477&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;6逻辑回归的线性不可分&quot;&gt;6.逻辑回归的线性不可分&lt;/h1&gt;

&lt;p&gt;例子：有4个坐标(0,0),(0,1),(1,0),(1,1)，每个坐标对应了一个图形，能找得到一个边界区分下面的2类图形吗？&lt;/p&gt;

&lt;p&gt;答：找不到。这就是&lt;strong&gt;线性不可分&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;实际工程的项目，一定是线性不可分的场景更加多。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251119004243945.png&quot; alt=&quot;image-20251119004243945&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;线性可分是指：在一个 $D$ 维特征空间中，如果存在一个 $D-1$ 维的超平面（例如，在二维空间中是一条直线），能够将两类样本完全、准确地划分开，那么称这两类样本是&lt;strong&gt;线性可分&lt;/strong&gt;的。&lt;/p&gt;

&lt;p&gt;上图是一个异或问题 (XOR)。这个问题的逻辑是：&lt;strong&gt;当且仅当 \(x_1\) 和 \(x_2\) 不同时，类别为 1 (三角形)&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;此时用逻辑回归就不能解决这个问题了。逻辑回归（以及其他任何&lt;strong&gt;线性分类器&lt;/strong&gt;，如感知机 Perceptron）的核心是找到一个线性决策边界 \(\mathbf{w}^T \mathbf{x} + b = 0\)。由于 &lt;strong&gt;XOR 问题是线性不可分的&lt;/strong&gt;，这个模型无论如何优化权重 \(\mathbf{w}\) 和偏置 \(b\)，都无法找到一条直线来正确地对所有四个点进行分类。&lt;/p&gt;

&lt;p&gt;要解决像 XOR 这样的线性不可分问题，我们必须引入&lt;strong&gt;非线性&lt;/strong&gt;。主要有两种策略：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;策略 A：特征变换 (Feature Transformation)&lt;/li&gt;
  &lt;li&gt;策略 B：引入非线性模型 (多层神经网络)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;61策略a-特征变换&quot;&gt;6.1策略A-特征变换&lt;/h2&gt;

&lt;p&gt;特征变化是最直接的方法，目标是将数据映射到一个&lt;strong&gt;更高维的空间&lt;/strong&gt;，在这个新空间中，数据变得线性可分。&lt;/p&gt;

&lt;p&gt;核技巧的思路：&lt;strong&gt;原始特征：&lt;/strong&gt; \(\mathbf{x} = (x_1, x_2)\)，&lt;strong&gt;添加非线性特征，&lt;/strong&gt; 即引入一个乘积特征 \(x_3 = x_1 x_2\)，最终的&lt;strong&gt;新特征空间 \(\Phi(\mathbf{x})\)：&lt;/strong&gt; \((x_1, x_2, x_3)\)&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;x=(x1,x2)&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;x3=x1x2&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Φ(x)=(x1,x2,x3)&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;类别&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$(0, 0)$&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;$(0, 0, 0)$&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$(0, 1)$&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;$(0, 1, 0)$&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$(1, 0)$&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;$(1, 0, 0)$&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$(1, 1)$&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;$(1, 1, 1)$&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;特征由2维变成3维，在这个三维空间中，可以找到一个超平面（一个平面）来区分这两类点，从而解决线性不可分问题。&lt;/p&gt;

&lt;p&gt;与2维相同的思路，寻找一组新的权重 \(\mathbf{w}&apos; = (w_1, w_2, w_3)\) 和偏置 \(b&apos;\)。&lt;/p&gt;

\[\mathbf{w}&apos;^T \Phi(\mathbf{x}) + b&apos; = 0\]

&lt;p&gt;展开形式（即平面的方程）就是：&lt;/p&gt;

\[w_1 x_1 + w_2 x_2 + w_3 (x_1 x_2) + b&apos; = 0\]

&lt;p&gt;寻找最佳平面就是找到最优的参数集合 \((\mathbf{w}&apos;, b&apos;)\)，使得这个平面能够在新空间中将两类样本准确地分开。&lt;/p&gt;

&lt;p&gt;为了训练模型，需要定义一个损失函数 \(L(\mathbf{w}&apos;, b&apos;)\)。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对于逻辑回归，使用&lt;strong&gt;二元交叉熵损失&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;对于线性 SVM，使用 &lt;strong&gt;Hinge Loss&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;用逻辑回归解决的代码如下：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mpl&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 字体设置 ---
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mpl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;font.sans-serif&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Noto Sans CJK SC&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;SimHei&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mpl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;axes.unicode_minus&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 1. 准备 XOR 数据 ---
# 原始的 XOR 数据点
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_raw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 对应的标签 (0: 圆形, 1: 三角形)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 2. 特征工程: 引入乘积特征 x1*x2 ---
# x3 = x1 * x2
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1_x2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 计算 x1*x2 并增加一个维度
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 拼接原始特征和新特征
# 新特征向量是 (x1, x2, x1*x2)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_extended&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x1_x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;扩展后的特征 X_extended:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_extended&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 3. 定义逻辑回归模型 (使用扩展特征) ---
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LogisticRegressionExtended&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LogisticRegressionExtended&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# 3 (输入特征: x1, x2, x1*x2) -&amp;gt; 1 (输出: 概率)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Sigmoid 激活函数通常在 BCEWithLogitsLoss 中隐式包含，
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# 但为了 forward 明确输出概率，我们在这里加上
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; 

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 模型初始化
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_extended_inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_extended&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 3
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LogisticRegressionExtended&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_extended_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 4. 定义损失函数和优化器 ---
# nn.BCELoss 需要模型直接输出概率 (0到1之间)
# nn.BCEWithLogitsLoss 更稳定，它内部包含 Sigmoid，所以模型forward不需要Sigmoid
# 这里我们的模型forward已经有Sigmoid，所以直接用BCELoss
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;BCELoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 5. 训练模型 ---
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;开始训练...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5000&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 训练更多轮次以确保收敛
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_extended&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;nf&quot;&gt;if &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch [&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;], Loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;训练完成。&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 6. 获取训练后的模型参数 ---
# 提取权重和偏置
# net.linear.weight 是一个 (1, num_inputs) 的张量
# net.linear.bias 是一个 (1,) 的张量
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;最终学习到的权重 w = (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w3&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;最终学习到的偏置 b = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 7. 可视化结果 ---
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 绘制原始数据点
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;150&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;blue&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edgecolor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;black&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;类别 0 (圆形)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;150&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;red&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edgecolor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;black&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;类别 1 (三角形)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 绘制决策边界曲线
# 定义一个网格来评估决策函数
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x1_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x2_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;xx1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xx2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;meshgrid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x1_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x2_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 计算决策函数的值 (Logits)
# Z = w1*x1 + w2*x2 + w3*x1*x2 + b
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xx1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xx2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xx1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xx2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 绘制决策边界 (Z=0 的等高线)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;contour&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xx1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xx2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;levels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;colors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;green&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidths&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyles&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;XOR 问题：通过特征扩展实现的非线性决策边界&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;$x_1$&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;$x_2$&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;xlim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x1_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x2_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;xticks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;yticks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 8. 验证预测结果 ---
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_extended&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;predicted_classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;模型预测结果:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;真实标签:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;预测概率:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()])&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;预测类别:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predicted_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251119142409259.png&quot; alt=&quot;image-20251119142409259&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;虽然是三维的，但是画图，看到的是投影的边界，看上去像双曲线。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以上的特征组合是\(x_1x_2\)，但是特征组合的方式多种多样，可以是\(x_1^2\)，也可以是\(x_2^2\)，…，等等。&lt;/p&gt;

&lt;p&gt;这就是特征工程的任务了，找到最好的某种特征的组合，得到最终的模型，使得分类任务完成的最好。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;另外，要注意，对于0.5的边界，其实也不一定合理，因为&lt;strong&gt;分类器有一定的概率预测错误&lt;/strong&gt;。比如癌症，建议边界卡的低一点。宁可让小概率得癌症的人多检查几次，也不要认为他没有得癌症回家了，这是需要编程自己根据实际情况调整边界的。&lt;/p&gt;

&lt;h2 id=&quot;62策略b-引入非线性模型-多层神经网络&quot;&gt;6.2策略B-引入非线性模型 (多层神经网络)&lt;/h2&gt;

&lt;p&gt;这是现代机器学习中最常用的方法：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;多层感知机 (MLP)：&lt;/strong&gt; 在输入层和输出层之间添加一个或多个&lt;strong&gt;隐藏层&lt;/strong&gt;，并在隐藏层中引入&lt;strong&gt;非线性激活函数&lt;/strong&gt;（如 ReLU, Sigmoid）。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;工作原理：&lt;/strong&gt; 每个隐藏层可以被视为一个自动学习特征变换 Φ(x) 的模块。通过堆叠多个非线性层，模型能够学习到任意复杂的非线性决策边界，轻松解决 XOR 等问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;7glm-模型的梯度更新形式都具有高度的统一性&quot;&gt;7.GLM 模型的梯度更新形式都具有高度的统一性&lt;/h1&gt;

&lt;p&gt;来详细对比 Softmax 回归、逻辑回归和线性回归的&lt;strong&gt;单个样本&lt;/strong&gt;的参数更新公式，看看它们的相似之处。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;广义线性模型（GLM）理论中最核心的洞察之一：&lt;strong&gt;所有 GLM 模型的梯度更新形式都具有高度的统一性。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;所有三种模型的参数更新都是基于 梯度下降法 的迭代更新规则：&lt;/p&gt;

\[\theta_{\text{new}} = \theta_{\text{old}} - \alpha \cdot \nabla_{\theta} J(\theta)\]

&lt;p&gt;其中 \(\alpha\) 是学习率，\(\nabla_{\theta} J(\theta)\) 是梯度（损失函数 \(J(\theta)\) 对参数 \(\theta\) 的偏导数）。&lt;/p&gt;

&lt;p&gt;我们关注的重点是&lt;strong&gt;梯度项 \(\nabla_{\theta} J(\theta)\)&lt;/strong&gt;。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Softmax 回归 (多分类)是多分类交叉熵损失 (负对数似然)。梯度公式如下：&lt;/p&gt;

\[\nabla_{\theta_j} J(\theta) = \underbrace{(\phi_j - \mathbb{I}\{y=j\})}_{\text{误差项}} \cdot \underbrace{x}_{\text{输入特征}}\]

&lt;p&gt;逻辑回归 (二分类)是 Softmax 回归在 \(k=2\) 时的特例。它只学习一个参数向量 \(\theta\)（通常 \(\theta_1\)）。损失函数是二元交叉熵损失 (BCE)。梯度公式如下：&lt;/p&gt;

\[\nabla_{\theta} J(\theta) = \underbrace{(\phi - y)}_{\text{误差项}} \cdot \underbrace{x}_{\text{输入特征}}\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;其中，\(\phi = h_{\theta}(x)\) 是模型预测 $$P(y=1&lt;/td&gt;
      &lt;td&gt;x)\(的概率，而\)y$$ 是真实标签（0 或 1）。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;线性回归 (连续值预测)的损失函数是MSE（均方误差），梯度公式是：&lt;/p&gt;

\[\nabla_{\theta} J(\theta) = \underbrace{(h_{\theta}(x) - y)}_{\text{误差项}} \cdot \underbrace{x}_{\text{输入特征}}\]

&lt;p&gt;其中，\(h_{\theta}(x) = \theta^T x\) 是模型的预测值，\(y\) 是真实值。&lt;/p&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;损失函数 J(θ)&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;梯度 ∇θJ(θ)&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;误差项 (预测−真实)&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;基础分布&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;线性回归&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;MSE&lt;/td&gt;
      &lt;td&gt;\((h_{\theta}(x) - y) x\)&lt;/td&gt;
      &lt;td&gt;(预测值-真实值)&lt;/td&gt;
      &lt;td&gt;高斯分布&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;逻辑回归&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;BCE&lt;/td&gt;
      &lt;td&gt;\((\phi - y) x\)&lt;/td&gt;
      &lt;td&gt;\((\text{预测概率} - \text{真实标签})\)&lt;/td&gt;
      &lt;td&gt;伯努利分布&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Softmax 回归&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;交叉熵&lt;/td&gt;
      &lt;td&gt;\((\phi_j - \mathbb{I}\{y=j\}) x\)&lt;/td&gt;
      &lt;td&gt;\((\text{预测概率} - \text{真实标签})\)&lt;/td&gt;
      &lt;td&gt;多项分布&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;所有 GLM 模型的梯度更新都遵循以下结构：&lt;/strong&gt;&lt;/p&gt;

\[\nabla_{\theta} J(\theta) \propto (\text{预测值} - \text{观测值}) \times \text{输入特征}\]

&lt;h1 id=&quot;8正向传播与反向传播&quot;&gt;8.正向传播与反向传播&lt;/h1&gt;

&lt;p&gt;其实表达式计算的过程就是正向传播，利用梯度下降反复更新参数（权重）就是反向传播。&lt;/p&gt;

&lt;p&gt;不论是线性回归、逻辑回归、softmax回归，其实都已经有了正向传播、反向传播的概念。&lt;/p&gt;

&lt;p&gt;在多层神经网络出现之前，这些模型就被称为&lt;strong&gt;“单层网络”&lt;/strong&gt;。它们的反向传播过程之所以看起来简单，是因为它们只有&lt;strong&gt;一个计算层&lt;/strong&gt;（线性组合 \(\theta^T x\)）和一个&lt;strong&gt;激活函数&lt;/strong&gt;（Sigmoid 或 Softmax）&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;正向传播：&lt;/strong&gt; \(x \to \theta^T x \to h(\theta^T x) \to J(\theta)\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;反向传播：&lt;/strong&gt; \(J(\theta) \to \nabla_{\theta} J\) &lt;strong&gt;(通过链式法则) \(\to \theta_{\text{new}}\)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这两种传播机制是所有基于梯度学习的模型（包括深度学习）的根本。&lt;/p&gt;

&lt;h1 id=&quot;9采样的重要性&quot;&gt;9.采样的重要性&lt;/h1&gt;

&lt;p&gt;如果数据集极度不平衡（例如，欺诈检测、罕见疾病诊断、广告点击率），如果不进行采样，模型在训练时会过度关注&lt;strong&gt;多数类 0&lt;/strong&gt;。模型会发现，只要它预测所有样本都是0，它就能达到一个&lt;strong&gt;看似很高&lt;/strong&gt;的准确率（例如 99.9%），因为0的样本占了绝大多数。&lt;/p&gt;

&lt;p&gt;虽然整体准确率高，但模型实际上失去了识别&lt;strong&gt;少数类 1&lt;/strong&gt;（例如，真正欺诈的交易、真正患病的人）的能力。这在关键业务场景中是不可接受的。&lt;/p&gt;

&lt;p&gt;所以需要采样，上采样（复制少数类样本）或下采样（减少多数类样本），有效提高少数类在损失计算中的权重，使其梯度能够充分指导模型的参数更新。&lt;/p&gt;

&lt;h1 id=&quot;总结重点&quot;&gt;总结重点&lt;/h1&gt;

&lt;p&gt;1.逻辑回归损失函数与梯度下降，手推数学公式，即求导。说明逻辑回归迭代的过程。&lt;/p&gt;

&lt;p&gt;2.KL距离（KL散度）与BCE之间的关系。并解释下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251118174428582.png&quot; alt=&quot;image-20251118174428582&quot; /&gt;&lt;/p&gt;

&lt;p&gt;3.为什么逻辑回归不用MSE而用BCE？&lt;/p&gt;

&lt;p&gt;4.softmax&lt;/p&gt;

&lt;h1 id=&quot;补充-colab画图之显示中文字体&quot;&gt;补充-colab画图之显示中文字体&lt;/h1&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mpl&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.font_manager&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fm&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 1. 设置变量 ---
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FONT_FILENAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;NotoSansCJKsc-Regular.otf&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;DOWNLOAD_URL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;https://github.com/googlefonts/noto-cjk/raw/main/Sans/OTF/SimplifiedChinese/NotoSansCJKsc-Regular.otf&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; 

&lt;span class=&quot;c1&quot;&gt;# 找出 Matplotlib 的缓存/配置目录（兼容性写法）
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cache_dir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mpl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get_cachedir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;AttributeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cache_dir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mpl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get_configdir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; 

&lt;span class=&quot;c1&quot;&gt;# 定义下载和目标路径
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FONT_FILENAME&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;font_destination&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FONT_FILENAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;目标缓存目录: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache_dir&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 2. 检查并下载字体 ---
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exists&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getsize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;正在重新下载 &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FONT_FILENAME&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 强制重新下载，覆盖可能存在的空文件
&lt;/span&gt;    &lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wget&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DOWNLOAD_URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;O&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 检查下载是否成功
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getsize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 字体文件通常大于 1MB
&lt;/span&gt;    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;✅ 文件下载成功，大小：&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getsize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; MB&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# --- 3. 复制字体文件到目标路径 ---
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# 使用 shutil.copy 以确保复制成功
&lt;/span&gt;    &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shutil&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;shutil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copyfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;font_destination&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;✅ &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FONT_FILENAME&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; 已成功复制到目标目录。&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# --- 4. 清理并重建 Matplotlib 缓存（关键） ---
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# 清除旧的字体缓存文件（如果存在）
&lt;/span&gt;    &lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rf&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# 强制 Matplotlib 重新扫描并构建缓存
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;fm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;_load_fontmanager&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;try_read_cache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;✅ 字体管理器已强制重新加载和构建缓存。&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;❌ 错误：下载失败或文件大小异常 (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getsize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; 字节)。&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 验证字体是否被管理器识别
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Noto Sans CJK SC&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontManager&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ttflist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;✅ 验证成功：Matplotlib 字体管理器已识别 &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Noto Sans CJK SC&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;❌ 验证失败：字体管理器未识别该字体。&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果验证失败，可以重启会话之后再执行一次。&lt;/p&gt;

&lt;p&gt;如何还是显示“验证失败”，这通常是因为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;font_manager&lt;/code&gt; 模块在重新初始化时，并没有真正将复制到缓存目录的文件视为有效的字体文件，或者读取路径有问题。可以尝试运行下面代码：Python 代码强制指定 Matplotlib 使用这个字体文件，绕过自动识别过程。（注意，最好还是重启下）&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mpl&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.font_manager&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fm&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 1. 定义字体文件路径 ---
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FONT_FILENAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;NotoSansCJKsc-Regular.otf&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 找出 Matplotlib 的缓存/配置目录
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cache_dir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mpl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get_cachedir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;AttributeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cache_dir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mpl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get_configdir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
&lt;span class=&quot;c1&quot;&gt;# 目标路径就是我们复制到的路径
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;font_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FONT_FILENAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 2. 尝试将字体手动添加到字体管理器 ---
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 使用 fontManager.addfont 明确告诉 Matplotlib 这个文件是一个字体
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;fm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontManager&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;addfont&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;font_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;✅ 字体文件 &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FONT_FILENAME&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; 已通过 addfont 明确添加到管理器。&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;❌ 字体手动添加失败: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 3. 强制设置参数 (使用文件名作为字体名称) ---
# Matplotlib 有时会使用文件名作为字体名，我们使用正确的字体名 &apos;Noto Sans CJK SC&apos;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;font_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Noto Sans CJK SC&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt; 

&lt;span class=&quot;c1&quot;&gt;# 检查字体是否已被识别 (重新检查，确保 addfont 有效)
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;font_name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontManager&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ttflist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;✅ 验证成功：Matplotlib 字体管理器已识别 &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Noto Sans CJK SC&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# 强制设置字体参数
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;mpl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;font.sans-serif&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;font_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;SimHei&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 将其设置为首选
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;mpl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;axes.unicode_minus&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;✅ Matplotlib 默认字体已设置为 &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;font_name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# --- 4. 运行一个快速测试图 ---
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;中文显示测试&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;测试文本：逻辑回归&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;center&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;va&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;center&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;❌ 最终验证失败：字体管理器未识别 &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;font_name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;。请确保安装代码运行完整。&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果没有问题会显示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251119142127271.png&quot; alt=&quot;image-20251119142127271&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以画sigmoid函数为例：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.font_manager&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fm&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mpl&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 【关键修复部分：强制刷新字体管理器】 ---
# 这一步尝试强制 Matplotlib 重新加载字体缓存，以确保新安装的字体生效。
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 确保 mpl 模块被正确导入
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mpl&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 尝试重建字体缓存（如果 Matplotlib 版本支持）
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 强制重新加载字体管理器，不使用缓存
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;fm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;_load_fontmanager&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;try_read_cache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;ℹ️ Matplotlib 字体管理器已强制刷新。&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 打印错误，但允许代码继续运行，以防版本兼容问题
&lt;/span&gt;    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;⚠️ 字体管理器刷新失败: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 【设置中文字体】 ---
# 使用思源黑体作为首选，并保留其他常用字体作为备用
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;font.sans-serif&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Noto Sans CJK SC&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;WenQuanYi Zen Hei&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;SimHei&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;axes.unicode_minus&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;# 解决负号显示的问题
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;ℹ️ 当前设置的字体列表: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;font.sans-serif&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# --- 【验证字体是否可用】 ---
# 尝试查找首选字体，如果失败，会发出警告
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;findfont&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;font.sans-serif&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fallback_to_default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;✅ 中文字体验证通过。&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;❌ 警告：首选中文字体仍未找到，可能显示乱码。&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# --- 【绘图逻辑】 ---
# 生成 x 值范围
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 计算 Sigmoid 函数
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 计算 Sigmoid 的导数：σ&apos;(x) = σ(x)*(1-σ(x))
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 绘图
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Sigmoid 函数: σ(x) = 1/(1+e^{-x})&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;blue&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Sigmoid 导数: σ&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;(x) = σ(x)(1-σ(x))&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;red&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 添加标题和标签
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Sigmoid 函数及其导数&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 添加网格、图例、零轴线
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;axhline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;axvline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;axhline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;gray&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;y=0.5&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;axhline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;gray&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;axhline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;gray&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 设置坐标轴范围
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;xlim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 显示图像
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tight_layout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251118191312829.png&quot; alt=&quot;image-20251118191312829&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 20 Nov 2025 00:00:00 +0000</pubDate>
        <link>https://kirsten-1.github.io/2025/11/20/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9906/</link>
        <guid isPermaLink="true">https://kirsten-1.github.io/2025/11/20/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9906/</guid>
        
        <category>AI思想启蒙</category>
        
        
      </item>
    
      <item>
        <title>【AI思想启蒙05】逻辑回归1猛将起于卒伍，工业环境下的分类模型 </title>
        <description>&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG&quot;&gt;
&lt;/script&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251117162736025.png&quot; alt=&quot;image-20251117162736025&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;逻辑回归是线性回归的扩展：&lt;/strong&gt; 它在线性回归的输出上应用了 Sigmoid 变换。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;逻辑回归是最简单的单层神经网络：&lt;/strong&gt; 它相当于一个&lt;strong&gt;只有输入层和输出层（带 Sigmoid 激活函数）&lt;/strong&gt;，并使用&lt;strong&gt;二元交叉熵 (BCE) 损失&lt;/strong&gt;的神经网络。&lt;/p&gt;

&lt;p&gt;当神经网络只有一层（没有隐藏层）时，如果输出层是 Sigmoid 激活函数，它就是逻辑回归；如果输出层是恒等激活函数，它就是线性回归。&lt;/p&gt;

&lt;p&gt;深度学习通过引入&lt;strong&gt;隐藏层&lt;/strong&gt;和使用 &lt;strong&gt;ReLU、Tanh&lt;/strong&gt; 等&lt;strong&gt;非线性激活函数&lt;/strong&gt;，能够学习和建模数据中高度复杂的&lt;strong&gt;非线性&lt;/strong&gt;关系，这是线性回归和逻辑回归作为单层模型所无法实现的。&lt;/p&gt;

&lt;h1 id=&quot;1回顾线性回归&quot;&gt;1.回顾线性回归&lt;/h1&gt;

&lt;p&gt;线性回归是最基础的回归模型，它假设输入特征 \(X\) 和输出目标 \(Y\) 之间存在&lt;strong&gt;线性关系&lt;/strong&gt;。&lt;/p&gt;

\[Y = W^T X + b\]

&lt;p&gt;线性回归是&lt;strong&gt;最简单的神经网络&lt;/strong&gt;。如果一个神经网络&lt;strong&gt;只有输入层和输出层&lt;/strong&gt;，并且&lt;strong&gt;输出层没有激活函数&lt;/strong&gt;（即使用恒等函数 \(f(z)=z\)），那么它执行的操作就是线性回归。&lt;/p&gt;

&lt;p&gt;线性回归的核心在于预测连续数值。建立输入特征（即自变量 \(X\)）与连续输出目标（未知的“另一个坐标”，即因变量 \(Y\)）之间的线性关系。其目标是找到一条最佳拟合的直线或平面，使得模型可以根据输入的 \(X\) 值，直接预测出一个具体、连续的数值，例如预测房价、气温或股票价格，解决的是&lt;strong&gt;回归问题&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;而&lt;strong&gt;逻辑回归的核心在于确定相对位置以进行分类。&lt;/strong&gt; 逻辑回归：知道完整的坐标，计算和直线的相对位置，这就是逻辑回归的分类本质。这里的“直线”是模型的&lt;strong&gt;决策边界&lt;/strong&gt;。逻辑回归首先通过线性计算确定数据点在线性空间中的位置（知道完整的坐标），然后通过 Sigmoid 函数将数据点与决策边界的相对位置转换为一个 \([0, 1]\) 之间的概率值。这个概率值决定了数据点被分到某一类别的可能性，从而解决了&lt;strong&gt;分类问题&lt;/strong&gt;，实现了对离散类别的预测。&lt;/p&gt;

&lt;h1 id=&quot;2逻辑回归&quot;&gt;2.逻辑回归&lt;/h1&gt;

&lt;h2 id=&quot;21原理&quot;&gt;2.1原理&lt;/h2&gt;

&lt;p&gt;线性 + Sigmoid 非线性 = 逻辑回归&lt;/p&gt;

&lt;p&gt;逻辑回归主要用于&lt;strong&gt;二分类&lt;/strong&gt;任务。它在&lt;strong&gt;线性组合&lt;/strong&gt;的基础上，增加了一个 &lt;strong&gt;Sigmoid (S型)&lt;/strong&gt; 激活函数，将输出压缩到 \([0, 1]\) 之间，表示概率。&lt;/p&gt;

\[P(Y=1|X) = \sigma(W^T X + b)\]

&lt;p&gt;其中 \(\sigma(z) = \frac{1}{1 + e^{-z}}\) 是 Sigmoid 函数。&lt;/p&gt;

&lt;p&gt;sigmoid函数图像如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251117173055512.png&quot; alt=&quot;image-20251117173055512&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;为什么是sigmoid函数（或类似的 S 型曲线）？&lt;/p&gt;

  &lt;p&gt;1.虽然逻辑回归本身是线性分类器，但 Sigmoid 函数作为&lt;strong&gt;非线性激活函数&lt;/strong&gt;，使得它能够将线性模型的输出转化为非线性概率。更重要的是，在&lt;strong&gt;深度神经网络&lt;/strong&gt;中，正是非线性激活函数的堆叠（如 Sigmoid）赋予了网络学习和拟合复杂非线性关系的能力。如果没有非线性激活函数，无论堆叠多少层，神经网络仍然只会是一个线性模型。补充：sigmoid作为神经网络的激活函数并不常见。因为在曲线平坦的区域，Sigmoid 的导数（梯度）接近于零。这意味着当模型的输出得分过大或过小时，通过反向传播计算出的梯度会非常小，导致权重 \(W\) 的更新非常缓慢，使得模型训练&lt;strong&gt;停滞不前&lt;/strong&gt;。这也是在现代深度学习中，ReLU 及其变体更常被用作隐藏层激活函数的原因。&lt;/p&gt;

  &lt;p&gt;2.整个曲线是&lt;strong&gt;平滑且可导&lt;/strong&gt;的（没有尖锐的拐角或跳变）。Sigmoid 函数处处可导，其导数（即梯度）也是连续的。这对于使用&lt;strong&gt;梯度下降法&lt;/strong&gt;及其变体（如反向传播）来训练模型至关重要，因为优化算法需要平滑的梯度来稳定地更新模型的权重 \(W\)。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;sigmoid导数图像如下：\(\sigma&apos;(z) = \sigma(z) \cdot (1 - \sigma(z))\)，其中\(\sigma(z) = \frac{1}{1 + e^{-z}}\)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251117173138335.png&quot; alt=&quot;image-20251117173138335&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Sigmoid 导函数的图像是一个&lt;strong&gt;对称的钟形曲线&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&quot;kl散度&quot;&gt;KL散度&lt;/h3&gt;

&lt;p&gt;线性回归的损失函数是MSE，逻辑回归的损失函数能不能也是MSE？&lt;/p&gt;

&lt;p&gt;不能。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;KL 距离，正式名称为 &lt;strong&gt;Kullback-Leibler 散度&lt;/strong&gt;，是一种衡量&lt;strong&gt;两个概率分布之间差异&lt;/strong&gt;的非对称度量。它源自信息论。&lt;/p&gt;

&lt;p&gt;KL 散度的定义如下：&lt;/p&gt;

\[\mathcal{L}_{KL} = \sum_{i=1}^{N} P(x_i) \cdot \log \frac{P(x_i)}{Q(x_i)}\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;\(P(x_i)\) (或图中的 \(y_i\))&lt;/strong&gt;: 真实概率分布（或参考分布 \(P\)）中事件 \(x_i\) 发生的概率。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(Q(x_i)\) (或图中的 \(f(x_i)\))&lt;/strong&gt;: 预测概率分布（或近似分布 \(Q\)）中事件 \(x_i\) 发生的概率。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(N\)&lt;/strong&gt;: 离散事件或状态的总数（在分类中通常是类别数）。&lt;/li&gt;
  &lt;li&gt;衡量使用分布 \(Q\) 来近似分布 \(P\) 时，所&lt;strong&gt;损失的信息量&lt;/strong&gt;或引入的&lt;strong&gt;信息增益&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;举例说明：&lt;/p&gt;

&lt;p&gt;有2枚硬币P和Q，抛硬币向上和向下的概率如下：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;P&lt;/th&gt;
      &lt;th&gt;Q&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;正面朝上&lt;/td&gt;
      &lt;td&gt;\(\frac{1}{3}\)&lt;/td&gt;
      &lt;td&gt;\(\frac{1}{4}\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;反面朝上&lt;/td&gt;
      &lt;td&gt;\(\frac{2}{3}\)&lt;/td&gt;
      &lt;td&gt;\(\frac{3}{4}\)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;计算硬币 \(\mathbf{P}\) 相对于 \(\mathbf{Q}\) 的 KL 散度：$$D_{KL}(P&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Q)$$。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[D_{KL}(P || Q) = \sum_{i} P(x_i) \log \frac{P(x_i)}{Q(x_i)}=P(x_1) \log \frac{P(x_1)}{Q(x_1)}+P(x_2) \log \frac{P(x_2)}{Q(x_2)} = \frac{1}{3} \ln \left( \frac{1/3}{1/4} \right) + \frac{2}{3} \ln \left( \frac{2/3}{3/4} \right)\]

&lt;p&gt;KL 散度的&lt;strong&gt;性质:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;非对称性:&lt;/strong&gt; $$D_{KL}(P&lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;Q) \neq D_{KL}(Q&lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;P)\(。它衡量的是\)P\(相对于\)Q$$ 的散度。&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;非负性:&lt;/strong&gt; $$D_{KL}(P&lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;Q) \geq 0\(。只有当\)P\(和\)Q$$ 完全相同时，$D_{KL}(P&lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;Q) = 0$。&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;一个很重要且有难度的结论：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;散度表达式非对称导致拟合倾向不同&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251117212909037.png&quot; alt=&quot;image-20251117212909037&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;**$$KL(P&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Q)\(** 倾向于让\)Q\(**覆盖**\)P\(的所有模式（**零回避**），因此\)Q\(会尽可能匹配\)P\(的**所有大值区域**，避免在\)P$$ 存在的地方 $Q$ 为零。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;**$$KL(Q&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;P)\(** 倾向于让\)Q\(**聚焦**于\)P\(的主要模式（**零强制**），因此\)Q\(会忽略\)P\(的长尾或不重要的区域，致力于完美匹配\)P\(的**少数几个峰值**，避免在\)P\(不存在的区域\)Q$$ 仍有值。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;损失函数bce&quot;&gt;损失函数BCE&lt;/h3&gt;

&lt;p&gt;逻辑回归的标准损失函数：二元交叉熵 (BCE)&lt;/p&gt;

&lt;p&gt;逻辑回归的训练目标是最大化似然函数，这等价于最小化&lt;strong&gt;二元交叉熵 (Binary Cross Entropy, BCE)&lt;/strong&gt; 损失函数：&lt;/p&gt;

\[\mathcal{L}_{\text{BCE}}(P || Q) = - \sum_{i} [y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i)]\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;真实分布 \(P\) (True Distribution):&lt;/strong&gt; 由真实标签 \(y_i\) 定义，它是一个伯努利分布，概率质量集中在 \(y_i\)上。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;预测分布 \(Q\) (Predicted Distribution):&lt;/strong&gt; 由模型输出 \(\hat{y}_i\) 定义，它也是一个伯努利分布，正类概率为 $\hat{y}_i$，负类概率为 \(1 - \hat{y}_i\)。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;KL 散度 $$D_{KL}(P&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Q)$$ 定义为：&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[D_{KL}(P || Q) = \sum_{i} P(x_i) \log \frac{P(x_i)}{Q(x_i)} = \sum_{i} P(x_i) \log P(x_i) - \sum_{i} P(x_i) \log Q(x_i)\]

&lt;p&gt;在二分类问题中，对于单个样本：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;真实分布 \(P\) 的熵 \(H(P)\)：&lt;/p&gt;

\[H(P) = - \sum_{k \in \{0, 1\}} P(Y=k) \log P(Y=k) = - [y \log y + (1 - y) \log (1 - y)]\]

    &lt;p&gt;由于 \(y\) 是真实标签，只能取 0 或 1，所以 \(H(P) = 0\)（确定分布的熵为零）。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;BCE 损失 $$\mathcal{L}_{\text{BCE}}(P&lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;Q)$$：&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;

\[\mathcal{L}_{\text{BCE}}(P || Q) = - \sum_{k \in \{0, 1\}} P(Y=k) \log Q(Y=k) = - [y \log \hat{y} + (1 - y) \log (1 - \hat{y})]=\\ \sum_{i=1}^{n} \left[ y_i \log \frac{y_i}{f_i} + (1 - y_i) \log \frac{1 - y_i}{1 - f_i} \right]\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;KL 散度 $$D_{KL}(P&lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;Q)$$：&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;

\[\mathbf{D_{KL}(P || Q)} = \mathcal{L}_{\text{BCE}}(P || Q) - H(P)\]
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;由于在逻辑回归中，目标是真实标签 \(y_i\)，其分布 \(P\) 是确定性的（熵 \(H(P)=0\)），所以：&lt;/p&gt;

\[\mathbf{D_{KL}(P || Q)} = \mathcal{L}_{\text{BCE}}(P || Q)\]

&lt;p&gt;因此，&lt;strong&gt;最小化逻辑回归的 BCE 损失，在数学上完全等价于最小化真实分布 \(P\) 和预测分布 \(Q\) 之间的 KL 散度。&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;22牛客习题1&quot;&gt;2.2牛客习题1&lt;/h2&gt;

&lt;p&gt;https://www.nowcoder.com/practice/3718cf46430740c7bbb6cd31fc433b88?tpId=390&amp;amp;tqId=11507519&amp;amp;sourceUrl=%2Fexam%2Foj%2Fta%3Fpage%3D1%26tpId%3D37%26type%3D390%26channelPut%3Dw25post&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decimal&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Decimal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ROUND_HALF_UP&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 1. Sigmoid 函数 ---
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;计算 Sigmoid 激活函数值&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# np.clip 避免指数溢出
&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 2. 预测函数 ---
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;计算预测概率和标签&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 线性组合：Z = X @ W (包含偏置项的矩阵乘法)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 概率：Y_hat = sigmoid(Z)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;Y_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 预测标签：概率 &amp;gt;= 0.5 为 1，否则为 0
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_hat&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# --- 3. 损失函数 (平均交叉熵 + L2 正则) ---
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;计算平均交叉熵损失和 L2 正则化项&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 避免 log(0)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;Y_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 交叉熵损失
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;cross_entropy_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# L2 正则化项 (通常不正则化偏置项 W[0])
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# 注意：W[1:] 对应 w1, w2, w3
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;l2_regularization&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lam&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cross_entropy_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l2_regularization&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# --- 4. 批量梯度下降训练 ---
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;使用批量梯度下降训练逻辑回归模型&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 初始化所有权重 W 为零 (包含 w0, 即 bias)
&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;current_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;inf&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 前向传播：计算预测概率
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Y_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 反向传播：计算梯度 (包含正则项)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 梯度 for 所有权重 (包括偏置 W[0])
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 添加 L2 正则项的梯度 (只对 W[1:] 添加)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;l2_grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;l2_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lam&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l2_grad&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 权重更新
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 计算新的损失并检查收敛
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;new_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 检查收敛条件
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# print(f&quot;Converged at iteration {i+1}. Loss change: {abs(current_loss - new_loss):.6f}&quot;)
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;current_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_loss&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# --- 5. 主程序 ---
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# 读取训练参数 (n max_iter alpha lam tol)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;line1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stdin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;readline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;lam&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 读取训练数据
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;raw_train_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;raw_train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stdin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;readline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())))&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;raw_train_data&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Handle case where n &amp;gt; 0 but data is missing
&lt;/span&gt;            &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Error: Missing training data.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 转换为 NumPy 数组
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;raw_train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 提取特征 X 和标签 Y
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;X_train_raw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# age, inc, dur
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# label
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# 兼容 n=0 的情况
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;X_train_raw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# --- 特征标准化 (Z-Score Normalization) ---
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# 记录训练集的均值和标准差，用于标准化测试集
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train_raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train_raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# 避免除以零：将标准差为零的特征的标准差设为 1 (它们不会被缩放)
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;X_train_normalized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train_raw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# n=0 时，训练数据为空，标准化系数无关紧要
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;X_train_normalized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 添加偏置项 (Intercept/Bias Term)
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;hstack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train_normalized&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# --- 训练模型 ---
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# 特殊情况：max_iter=0，权重保持初始值 W=0
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# n=0，权重 W 仍然为零
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# n&amp;gt;0, max_iter=0, W=0 已经在上面处理
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# --- 读取测试数据 ---
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;line_m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stdin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;readline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line_m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line_m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;raw_test_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;raw_test_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stdin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;readline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())))&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;X_test_raw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;raw_test_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# 使用训练集的均值和标准差标准化测试集
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;X_test_normalized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test_raw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# 添加偏置项
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;hstack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test_normalized&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# --- 进行预测 ---
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probabilities&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# --- 输出结果 ---
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prob&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probabilities&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;# 按照要求，概率保留四位小数，四舍五入
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;prob_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Decimal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 使用 Decimal 实现精确的四舍五入
&lt;/span&gt;                &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prob_str&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# print(f&quot;An error occurred: {e}&quot;, file=sys.stderr)
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 示例环境中通常需要安静失败
&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;__main__&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;23牛客习题2&quot;&gt;2.3牛客习题2&lt;/h2&gt;

&lt;p&gt;https://www.nowcoder.com/practice/d9c4bcf3bc5e426b8a11e690f65ba601?tab=note&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;dataSet.csv&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;labels.csv&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;#补全 sigmoid 函数功能
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;#code start here
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;#code end here
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataMatIn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classLabels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 学习率，也就是题目描述中的 α
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;iteration_nums&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 迭代次数，也就是for循环的次数
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;dataMatrix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataMatIn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;labelMat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classLabels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataMatrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 返回dataMatrix的大小。m为行数,n为列数。
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;weight_mat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#初始化权重矩阵
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;#iteration_nums 即为循环的迭代次数
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;#请在代码完善部分注意矩阵乘法的维度，使用梯度下降矢量化公式
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;#code start here
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iteration_nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataMatrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight_mat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#数据矩阵与权重矩阵点积，是预测值
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataMatrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labelMat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#梯度
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;weight_mat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#权重更新
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight_mat&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;#code end here
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;__main__&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dataMat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labelMat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;gradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataMat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labelMat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;3多分类&quot;&gt;3.多分类&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251117163645461.png&quot; alt=&quot;image-20251117163645461&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;使用&lt;strong&gt;逻辑回归的思想&lt;/strong&gt;来处理多分类问题，这种方法通常被称为 &lt;strong&gt;Softmax 回归 (Softmax Regression)&lt;/strong&gt; 或&lt;strong&gt;多项逻辑回归 (Multinomial Logistic Regression)&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;对于输入特征向量 \(X\)，模型会为每个类别 \(k\) 计算一个&lt;strong&gt;分数&lt;/strong&gt;（或称为 &lt;strong&gt;logit&lt;/strong&gt;）。这个分数是通过输入 \(X\) 和该类别对应的权重向量 \(W_k\) 进行线性组合得到的。&lt;/p&gt;

\[z_k = W_k^T X + b_k\]

&lt;p&gt;其中：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(k = 1, 2, 3, 4\)（对应图中的 \(P_1\) 到 \(P_4\)）。&lt;/li&gt;
  &lt;li&gt;\(z_k\) 是输入 \(X\) 属于类别 \(k\) 的未归一化分数。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这对应了图中 &lt;strong&gt;X&lt;/strong&gt; 经过 &lt;strong&gt;W&lt;/strong&gt; 矩阵变换后的中间结果。&lt;/p&gt;

&lt;p&gt;为了将这些分数 \(z_k\)  转换为符合概率要求的输出（即所有概率值在 \([0, 1]\) 之间，且总和为 1），模型使用 &lt;strong&gt;Softmax 函数&lt;/strong&gt;。Softmax 函数是 &lt;strong&gt;Sigmoid 函数&lt;/strong&gt;（用于二分类逻辑回归）在多分类上的泛化。&lt;/p&gt;

&lt;p&gt;样本 \(X\) 属于类别 \(k\) 的概率 \(P_k\) 为：&lt;/p&gt;

\[P_k = P(Y=k|X) = \frac{e^{z_k}}{\sum_{j=1}^{K} e^{z_j}}\]

&lt;p&gt;这对应了图中 \(P_1, P_2, P_3, P_4\) 的输出，这些输出满足 \(\sum_{k=1}^{4} P_k = 1\)。&lt;/p&gt;

&lt;p&gt;在 Softmax 回归中，我们通常使用&lt;strong&gt;交叉熵损失 (Cross Entropy Loss)&lt;/strong&gt; 来衡量预测概率分布 \(P\) 与真实标签分布 \(Y\) 之间的差异，并指导模型的训练。&lt;/p&gt;

\[\mathcal{L}_{CE} = - \sum_{k=1}^{K} Y_k \log(P_k)\]

&lt;ul&gt;
  &lt;li&gt;\(Y_k\) 是真实标签的 One-hot 编码（如果 \(X\) 属于类别 \(k\)，则 \(Y_k=1\)，否则为 0）。&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Mon, 17 Nov 2025 00:00:00 +0000</pubDate>
        <link>https://kirsten-1.github.io/2025/11/17/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9905/</link>
        <guid isPermaLink="true">https://kirsten-1.github.io/2025/11/17/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9905/</guid>
        
        <category>AI思想启蒙</category>
        
        
      </item>
    
      <item>
        <title>【redis入门与实操-01】从磁盘瓶颈到Redis内存王者：缓存体系全解析</title>
        <description>&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG&quot;&gt;
&lt;/script&gt;

&lt;p&gt;redis学习的整个体系&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251109214841246.png&quot; alt=&quot;image-20251109214841246&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1文件读取与底层存储瓶颈&quot;&gt;1.文件读取与底层存储瓶颈&lt;/h1&gt;

&lt;p&gt;数据存储在文件中时，例如&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;data.txt&lt;/code&gt;，读取方式有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Linux平台下：grep, awk等命令行工具进行文本处理和搜索&lt;/li&gt;
  &lt;li&gt;用编程语言写一个程序读取文件再查找，比如java的IO流。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;补充：存储介质的关键性能指标&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;【1】数据存在磁盘中，对于磁盘有2个重要的指标：&lt;/p&gt;

  &lt;p&gt;1.寻址，ms级别&lt;/p&gt;

  &lt;p&gt;2.带宽，MB/s，GB/s，TB/s&lt;/p&gt;

  &lt;p&gt;【2】内存的重要指标：&lt;/p&gt;

  &lt;p&gt;1.寻址，ns(纳秒)级别，比磁盘快10万倍&lt;/p&gt;

  &lt;p&gt;2.带宽，很大&lt;/p&gt;

  &lt;p&gt;以上关键指标整理为下面的表格：&lt;/p&gt;

  &lt;table&gt;
    &lt;thead&gt;
      &lt;tr&gt;
        &lt;th&gt;&lt;strong&gt;介质&lt;/strong&gt;&lt;/th&gt;
        &lt;th&gt;&lt;strong&gt;指标&lt;/strong&gt;&lt;/th&gt;
        &lt;th&gt;&lt;strong&gt;性能级别&lt;/strong&gt;&lt;/th&gt;
        &lt;th&gt;&lt;strong&gt;相对速度&lt;/strong&gt;&lt;/th&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;&lt;strong&gt;磁盘 (Disk)&lt;/strong&gt;&lt;/td&gt;
        &lt;td&gt;寻址时间 (Access Latency)&lt;/td&gt;
        &lt;td&gt;&lt;strong&gt;毫秒 (ms)&lt;/strong&gt; 级别&lt;/td&gt;
        &lt;td&gt;慢&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt; &lt;/td&gt;
        &lt;td&gt;带宽 (Throughput)&lt;/td&gt;
        &lt;td&gt;&lt;strong&gt;MB/s, GB/s, TB/s&lt;/strong&gt;&lt;/td&gt;
        &lt;td&gt; &lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;&lt;strong&gt;内存 (RAM)&lt;/strong&gt;&lt;/td&gt;
        &lt;td&gt;寻址时间 (Access Latency)&lt;/td&gt;
        &lt;td&gt;&lt;strong&gt;纳秒 (ns)&lt;/strong&gt; 级别&lt;/td&gt;
        &lt;td&gt;&lt;strong&gt;比磁盘快 10 万倍&lt;/strong&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt; &lt;/td&gt;
        &lt;td&gt;带宽 (Throughput)&lt;/td&gt;
        &lt;td&gt;&lt;strong&gt;非常大&lt;/strong&gt;&lt;/td&gt;
        &lt;td&gt; &lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;

  &lt;p&gt;&lt;strong&gt;核心矛盾：&lt;/strong&gt; 磁盘是存储大量数据的理想选择，但其&lt;strong&gt;寻址时间太慢&lt;/strong&gt;（ms 级），是主要的性能瓶颈。&lt;/p&gt;

  &lt;p&gt;【3】I/O Buffer（ I/O 缓冲与磁盘格式化）&lt;/p&gt;

  &lt;p&gt;成本：磁盘有磁道和扇区。磁盘的最小物理存储单元是扇区 (一般 &lt;strong&gt;512B&lt;/strong&gt;)。如果读取单位过小，查找对应扇区（即索引）的成本（寻址时间）相对会变大。1扇区一般512B，1T会有很多512B。如果区域足够小，找哪个扇区（索引）的成本就会变大。&lt;/p&gt;

  &lt;p&gt;现代操作系统在格式化硬盘时，倾向于使用 &lt;strong&gt;4KB 对齐&lt;/strong&gt;，不再以512B为一次的 读写量。即，操作系统无论请求读取多少数据，&lt;strong&gt;最小&lt;/strong&gt;都会从磁盘中读取 &lt;strong&gt;4KB&lt;/strong&gt; 的数据块。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;如果文件越来越大，读取速度会变慢，因为频繁的磁盘 I/O（寻址和读取）会使&lt;strong&gt;硬盘&lt;/strong&gt;成为瓶颈，即 &lt;strong&gt;I/O 成为瓶颈&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;为了解决磁盘 I/O 成为瓶颈的问题，出现了数据库。&lt;/p&gt;

&lt;h1 id=&quot;2数据库的底层设计与优化&quot;&gt;2.数据库的底层设计与优化&lt;/h1&gt;

&lt;p&gt;【1】data page的出现：数据库引入 &lt;strong&gt;Data Page&lt;/strong&gt;（数据页）的概念，通常定义为 &lt;strong&gt;4KB 或其倍数&lt;/strong&gt;（如 MySQL InnoDB 的默认 Data Page 大小是 16KB）。最小4KB，与格式化磁盘的“4KB对齐”正好对应上了，即符合1次I/O。如果data page定义比4K小，比如1K、2K，则会浪费操作系统的读取。如果data page定义比4K大，那无所谓。即，将 Data Page 定义为 &lt;strong&gt;4KB&lt;/strong&gt; 恰好与操作系统最小读取单元的 &lt;strong&gt;4KB 对齐&lt;/strong&gt;机制相对应，从而确保&lt;strong&gt;一次 I/O 操作&lt;/strong&gt;就能读取一个完整的 Data Page，避免浪费。&lt;/p&gt;

&lt;p&gt;data page的出现，还是全量的IO（顺序或全表扫描），还是和之前速度类似，性能提升有限。更快的处理是：建索引，引入索引来加速查找，即建立对于data page索引的关系的表格。&lt;/p&gt;

&lt;p&gt;【2】data page的索引。随着数据增大，索引也会变多。建立索引，其实变相来说，也是一种数据。索引本身也是数据，通常也存储在磁盘中。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;关系型数据库建表，必须先给出schema，即给出表的每个列、每个列的类型（字节宽度，即一种约束）。先给出schema，从而固定了每条数据的宽度（&lt;strong&gt;约束&lt;/strong&gt;）。&lt;/p&gt;

  &lt;p&gt;存储时，会更倾向“行级存储”，即以行为单位进行存储，即使某些字段是空，也会占位。增删改差，不需要移动数据，只需要覆盖即可。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;数据库的存取机制是&lt;strong&gt;充分利用磁盘的大容量和内存的高速度&lt;/strong&gt;。数据和索引都存储在磁盘中，读取时，需要在内存中准备一颗&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B+&lt;/code&gt;树（一种高效的磁盘存取数据结构）。命中某个索引后，将 B+ 树的树干或叶子节点（即索引页）从磁盘&lt;strong&gt;加载到内存&lt;/strong&gt;。 通过内存中的索引，确定目标数据所在的 &lt;strong&gt;Data Page&lt;/strong&gt;，然后将这个 Data Page 从磁盘&lt;strong&gt;加载到内存&lt;/strong&gt;。在内存中的 Data Page 里找到最终的数据。&lt;/p&gt;

&lt;p&gt;这种设计就是为了&lt;strong&gt;减少磁盘 I/O 的流量和寻址次数&lt;/strong&gt;。B+ 树结构保证了无论是访问哪个 Data Page，寻址路径（树的高度）都是非常短且固定的，从而大大加快了遍历速度。&lt;/p&gt;

&lt;p&gt;以上，充分利用各自的能力，磁盘发挥存储大量数据的作用，内存发挥读取速度快的作用，利用B+树这个数据结构，就可以加快遍历数据的速度，数据又是分而治之的存储，所以，最终数据存取非常快。&lt;/p&gt;

&lt;p&gt;其实这样的设计，就是为了减少IO的流量。磁盘读取速度这么慢，尽量避免磁盘的IO流量与寻址。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;面试题&quot;&gt;面试题&lt;/h2&gt;

&lt;p&gt;【面试】：如果数据库存储的数据量变得很大，比如1T、2T，检索速度或者说检索性能一定会变低，对不对？&lt;/p&gt;

&lt;p&gt;答：不完全对，需要区分&lt;strong&gt;单次查询&lt;/strong&gt;和&lt;strong&gt;高并发&lt;/strong&gt;场景：&lt;/p&gt;

&lt;p&gt;如果表有索引，增删改会变慢，因为需要维护索引。索引可能会被修改。&lt;/p&gt;

&lt;p&gt;查询来说，1个或者少量查询依然很快，因为因为 B+ 树的高度增加非常缓慢（1T 数据可能树高仍然只有 3-4 层），单个查询需要的&lt;strong&gt;磁盘 I/O 次数变化不大&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;但如果并发大，此时真正的瓶颈是&lt;strong&gt;硬盘带宽&lt;/strong&gt;。在高并发情况下，系统可能需要&lt;strong&gt;同时加载多个 Data Page 和索引页到内存&lt;/strong&gt;。由于硬盘的&lt;strong&gt;带宽&lt;/strong&gt;是有限的，大量并发的 I/O 请求会互相等待，导致整体吞吐量下降。&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;3数据量大如何快速查询数据库-缓存的引入&quot;&gt;3.数据量大如何快速查询数据库-缓存的引入&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;数据在磁盘存储和内存存储之间，会存在“体积”（即占用空间）的差异&lt;/strong&gt;，&lt;/p&gt;

&lt;p&gt;举例说明：传统关系型数据库和像 SAP HANA 这样的内存数据库&lt;/p&gt;

&lt;p&gt;【1】在传统的基于磁盘的关系型数据库中，为了保证查询效率，数据和索引是分开存储且都需要占用空间的。详细来说，原始数据（例如 2TB）存储在磁盘上。数据库需要构建索引来加速查找 Data Page。&lt;strong&gt;索引本身也是数据&lt;/strong&gt;，它们需要占用额外的磁盘空间。磁盘是持久化、物理寻址的。你不能像在程序中那样，用一个小的内存地址（指针/引用）来指向一个大对象。如果数据要在索引中“出现”，就意味着&lt;strong&gt;索引需要存储足够的信息来定位原始数据&lt;/strong&gt;（例如，一个键值对，其中值可能是指向磁盘地址的物理指针或 Data Page ID）。如果一个数据项需要被多个索引引用，&lt;strong&gt;索引系统会为这个数据项建立多个索引条目&lt;/strong&gt;。这些索引条目加起来，使&lt;strong&gt;总存储体积膨胀&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;结论：&lt;/strong&gt; 磁盘上的 &lt;strong&gt;总存储体积 = 原始数据体积 + 索引体积&lt;/strong&gt;。因此，总存储量会大于原始数据量（例如，原始数据 2T，加上索引可能远超 2T）。&lt;/p&gt;

&lt;p&gt;【2】内存数据库（如 SAP HANA）利用内存的高速寻址能力，可以采用更高效、更紧凑的存储方式。（管理是统一的，冗余很少）&lt;/p&gt;

&lt;p&gt;在内存中，你可以真正使用&lt;strong&gt;指针（或引用）&lt;/strong&gt;的概念。一个大对象存储在内存堆中的某个位置，不同的数据结构（线程、索引）只需要一个很小的&lt;strong&gt;内存地址/引用&lt;/strong&gt;就可以指向它。不是说完全没有索引，而是指：&lt;strong&gt;内存数据库可以采用集成或优化后的数据结构&lt;/strong&gt;（例如，高度优化的列式存储结构、哈希表等），这些结构在内存中可以更高效地管理数据关系，而&lt;strong&gt;不需要像磁盘数据库那样在物理上存储一套完整的、冗余的、分离的索引结构&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;内存数据库通常内置了强大的数据&lt;strong&gt;压缩策略&lt;/strong&gt;（例如，基于字典编码、位图索引等）。由于数据始终在内存中，可以实时进行压缩和解压，大幅减少占用的空间。许多内存数据库（如 HANA）采用&lt;strong&gt;列式存储&lt;/strong&gt;，对同一列的数据进行优化存储，进一步提升压缩率。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;存储环境&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;为什么会“张出”（膨胀）？&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;为什么会“缩小”？&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;关键技术差异&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;磁盘存储&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;1. 必须存储&lt;strong&gt;冗余且物理分离的索引&lt;/strong&gt;（没有内存指针的概念）。2. 索引本身占用大量空间。&lt;/td&gt;
      &lt;td&gt;N/A&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;物理寻址&lt;/strong&gt;，I/O 瓶颈。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;内存存储 (HANA)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;N/A&lt;/td&gt;
      &lt;td&gt;1. &lt;strong&gt;无需存储传统意义上的冗余磁盘索引&lt;/strong&gt;。2. 可以使用&lt;strong&gt;内存指针/引用&lt;/strong&gt;进行高效引用。3. 采用&lt;strong&gt;高效的数据压缩优化策略&lt;/strong&gt;。&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;内存寻址&lt;/strong&gt;（ns 级），高压缩率。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;如果原始数据文件是 2T，传统数据库在磁盘上实际占用的空间（数据 + 索引）可能高达 3T 甚至更多。而当把&lt;strong&gt;原始数据&lt;/strong&gt;加载到 HANA 内存数据库中时，由于&lt;strong&gt;索引的存储更高效、没有磁盘I/O的物理约束、并且启用了压缩&lt;/strong&gt;，数据占用的内存空间反而会&lt;strong&gt;小于&lt;/strong&gt;原始数据体积，变成 &lt;strong&gt;1T 多一点&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;总结来说，数据在磁盘和内存的“体积不一样”，主要是因为：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;磁盘存储了庞大的、物理上冗余的索引结构。&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;内存存储可以利用指针/引用和高级压缩技术，极大地减少了冗余和数据本身的占用空间。&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;以上是2个极端，传统关系型数据库和内存数据库。可能企业买不起HANA这样的内存数据库（很大概率一套内存数据库下来，几个亿）。此时，折中的方案就是——【缓存】。&lt;/p&gt;

&lt;p&gt;即，内存级的用不起，只能用磁盘级的，磁盘级的速度又很慢，选择一个折中方案，用小一点的内存，把数据迁移出来。这就是缓存的技术。&lt;/p&gt;

&lt;p&gt;缓存的技术很多，比如memcached、redis。&lt;/p&gt;

&lt;p&gt;【冯诺伊曼体系结构】与【以太网、TCP/IP网络】这2套现代IT信息系统的基础设施，决定了redis等缓存技术的重要性。&lt;/p&gt;

\[\text{寄存器} &amp;gt; \text{L1/L2/L3 缓存} &amp;gt; \text{主内存} &amp;gt; \text{磁盘/SSD}\]

&lt;p&gt;计算机内部的&lt;strong&gt;天然性能鸿沟&lt;/strong&gt;（CPU 和内存/磁盘的速度差异）使得&lt;strong&gt;数据必须尽可能靠近 CPU&lt;/strong&gt;。系统级缓存（如 CPU 内部的 L1/L2）是第一层优化；而 Redis/Memcache 则是面向&lt;strong&gt;应用层&lt;/strong&gt;的缓存优化，目的是将数据从&lt;strong&gt;磁盘&lt;/strong&gt;这个最远的存储介质拉到&lt;strong&gt;内存&lt;/strong&gt;这个最近的存储介质。&lt;/p&gt;

&lt;p&gt;现代 IT 系统是&lt;strong&gt;分布式&lt;/strong&gt;的，数据和应用分散在网络中的不同服务器上。即使服务器内部的数据库很快，数据从数据库服务器通过 &lt;strong&gt;TCP/IP 网络&lt;/strong&gt;传输到应用服务器，仍然需要额外的&lt;strong&gt;网络延迟&lt;/strong&gt;（通常是毫秒 ms 级别）。当并发量增大时，大量的数据库连接和数据传输会消耗大量的&lt;strong&gt;网络带宽和服务器资源&lt;/strong&gt;。将缓存服务（如 Redis）部署在&lt;strong&gt;离应用服务器更近&lt;/strong&gt;的网络位置，甚至直接部署在应用服务器上，可以消除访问&lt;strong&gt;远程数据库&lt;/strong&gt;带来的网络延迟。绝大多数读请求可以直接命中缓存，避免&lt;strong&gt;流量直接涌向后端数据库&lt;/strong&gt;，从而减轻了数据库服务器、以及它们之间的&lt;strong&gt;网络 I/O 压力&lt;/strong&gt;。&lt;/p&gt;

&lt;h1 id=&quot;4db-engines网站&quot;&gt;4.DB-Engines网站&lt;/h1&gt;

&lt;p&gt;网址：https://db-engines.com/en/&lt;/p&gt;

&lt;p&gt;DB-Engines 网站是一个非常重要的资源，主要提供关于&lt;strong&gt;数据库管理系统（DBMS）&lt;/strong&gt;的排名、趋势和详细信息。涵盖几乎所有类型的数据库，包括关系型、NoSQL（键值、文档、图、时序等）、多值数据库等。DB-Engines 的排名是其最著名的产物。这个排名并非基于纯粹的性能测试或市场份额数据，而是基于一个综合性的计算模型，它试图衡量&lt;strong&gt;一个数据库系统在社区中的流行程度（popularity）&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;DB-Engines 的排名得分是基于以下四个公开可获取的指标综合计算得出的：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;搜索引擎结果数（Google Trends）：&lt;/strong&gt; 衡量包含 DBMS 名称的网页数量。这代表了该系统在网络上的&lt;strong&gt;讨论热度&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Google Trends 搜索兴趣：&lt;/strong&gt; 衡量用户在 Google 上搜索该 DBMS 名称的&lt;strong&gt;频率&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;技术讨论论坛提及数（Stack Overflow/DBA Stack Exchange）：&lt;/strong&gt; 衡量该 DBMS 在专业技术问答社区中&lt;strong&gt;被提及和讨论的活跃度&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;职位招聘数量：&lt;/strong&gt; 衡量全球招聘信息中提及该 DBMS 的&lt;strong&gt;数量&lt;/strong&gt;。这代表了该系统在&lt;strong&gt;商业应用和劳动力市场中的需求&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;下面是2025.11.09的截图&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251109205203072.png&quot; alt=&quot;image-20251109205203072&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251109205331728.png&quot; alt=&quot;image-20251109205331728&quot; /&gt;&lt;/p&gt;

&lt;p&gt;键值对数据库排名：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251109205526186.png&quot; alt=&quot;image-20251109205526186&quot; /&gt;&lt;/p&gt;

&lt;p&gt;网站对于数据库的指标罗列是非常全的，甚至权威到可以用来写标书。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251109205839026.png&quot; alt=&quot;image-20251109205839026&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;5redis概述&quot;&gt;5.Redis概述&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;可以简单认为服务器读取Redis比读取Mysql快100倍左右。&lt;/p&gt;

  &lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251111170952697.png&quot; alt=&quot;image-20251111170952697&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;https://db-engines.com/en/system/Redis&lt;/p&gt;

&lt;p&gt;官网：&lt;a href=&quot;https://redis.com/&quot;&gt;redis.com&lt;/a&gt;和&lt;a href=&quot;https://redis.io/&quot;&gt;redis.io&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;最新版本： 7.2.5, May 2024&lt;/p&gt;

&lt;p&gt;实现语言： C&lt;/p&gt;

&lt;p&gt;集群：Sharding&lt;/p&gt;

&lt;p&gt;数据一致性：最终一致性，Eventual Consistency。如果速度不关键，不一定要用redis。&lt;/p&gt;

&lt;p&gt;Redis（&lt;strong&gt;RE&lt;/strong&gt;mote &lt;strong&gt;DI&lt;/strong&gt;ctionary &lt;strong&gt;S&lt;/strong&gt;erver，远程字典服务器）是一种非常流行的开源、高性能的&lt;strong&gt;内存键值（Key-Value）存储系统&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;它常被用作&lt;strong&gt;应用程序缓存&lt;/strong&gt;、&lt;strong&gt;快速数据库&lt;/strong&gt;或&lt;strong&gt;消息代理&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;Redis 将所有数据存储在&lt;strong&gt;计算机主内存（RAM）&lt;/strong&gt;中，而不是传统的磁盘上。内存寻址速度远高于磁盘，因此 Redis 能够实现&lt;strong&gt;微秒（\(\mu s\)）级别的低延迟&lt;/strong&gt;读写操作，速度极快，解决了磁盘 I/O 带来的瓶颈。非常适合用作缓存系统（将热点数据从慢速数据库迁移出来）、会话存储（分布式Session）、排行榜等需要快速响应的场景。&lt;/p&gt;

&lt;h2 id=&quot;sql与nosql&quot;&gt;SQL与NoSQL&lt;/h2&gt;

&lt;p&gt;SQL (关系型数据库):如 MySQL、Oracle、SQL Server 等，其核心在于&lt;strong&gt;结构化(Structured)&lt;/strong&gt;和&lt;strong&gt;表结构&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;【1】结构化：数据以&lt;strong&gt;行 (Row)&lt;/strong&gt; 和 &lt;strong&gt;列 (Column)&lt;/strong&gt; 组成的&lt;strong&gt;二维表&lt;/strong&gt;形式存储。在存储数据之前，必须预先定义好严格的表结构。每一列都有固定的名称、数据类型和约束（比如主键、唯一性约束、非负约束等等）。面对高并发和海量数据时，垂直和水平扩展（分库分表）难度较大。修改表结构（如增加一列）通常需要较长时间，尤其是在数据量大时。&lt;/p&gt;

&lt;p&gt;NoSQL (非关系型数据库)：（Not Only SQL）数据库是为了解决关系型数据库在海量数据、高并发、灵活数据结构等方面的不足而诞生的。&lt;/p&gt;

&lt;p&gt;非结构化：数据模型灵活多样，不强制要求固定的表结构。&lt;/p&gt;

&lt;p&gt;NoSQL 常见的几种数据模型：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Key-Value 键值对模型 (如 Redis、Memcached)&lt;/li&gt;
  &lt;li&gt;Document 文档模型 (如 MongoDB、Couchbase)：数据以&lt;strong&gt;文档&lt;/strong&gt;（Document）形式存储，通常是 JSON、BSON 或 XML 格式。与面向对象的编程语言天然契合，数据结构灵活，易于存储复杂对象。&lt;/li&gt;
  &lt;li&gt;Graph 图形模型 (如 Neo4j)：数据以&lt;strong&gt;节点&lt;/strong&gt;（Nodes）和&lt;strong&gt;边&lt;/strong&gt;（Edges/Relationships）的形式存储。擅长处理实体之间复杂的关系和连接查询（例如社交网络关系、推荐系统）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;【2】从&lt;strong&gt;数据关联&lt;/strong&gt;的角度&lt;/p&gt;

&lt;p&gt;关系型数据库（如 MySQL, PostgreSQL, Oracle）的设计基石是&lt;strong&gt;关系代数&lt;/strong&gt;，其核心目标是高效、完整地存储和管理&lt;strong&gt;关联性强&lt;/strong&gt;的数据，并确保数据在多个表之间的&lt;strong&gt;一致性&lt;/strong&gt;。外键是 SQL 维护关联关系的核心机制。外键用于连接两个表，它指向另一个表的主键。数据库本身（而非应用层）会维护外键约束。例如，如果尝试删除一个被外键引用的用户，数据库会阻止该操作，或根据级联规则（Cascade）自动删除相关记录，从而&lt;strong&gt;强制保证数据的一致性和关联的有效性&lt;/strong&gt;。可以通过 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JOIN&lt;/code&gt; 语句，可以实时、高效地根据外键在多个表之间查询关联数据。数据高度规范化，无冗余，一致性高，支持复杂的跨表查询和事务。当需要查询一个实体的完整信息时（如“某个用户和他的所有订单”），必须执行 &lt;strong&gt;JOIN 操作&lt;/strong&gt;，这在大规模并发和海量数据下，会成为&lt;strong&gt;性能瓶颈&lt;/strong&gt;。扩展时，跨机器的 JOIN 非常困难。&lt;/p&gt;

&lt;p&gt;非关系型数据库（如 MongoDB 文档型、Cassandra 宽列型）的设计目标是&lt;strong&gt;高可用性&lt;/strong&gt;、&lt;strong&gt;水平扩展性&lt;/strong&gt;和&lt;strong&gt;快速读写&lt;/strong&gt;，通常以&lt;strong&gt;牺牲严格的关联和一致性&lt;/strong&gt;为代价。通常采用&lt;strong&gt;反规范化&lt;/strong&gt;，将原本属于不同表的数据&lt;strong&gt;冗余&lt;/strong&gt;地存储在同一个数据对象（如文档）中。大多数 NoSQL 数据库在底层&lt;strong&gt;没有外键&lt;/strong&gt;的概念，数据库本身不负责维护数据间的引用关系和完整性。如果应用需要维护关联，这个责任就完全落在了&lt;strong&gt;应用层&lt;/strong&gt;。应用代码必须确保当一个用户修改了姓名时，所有包含该冗余姓名的订单文档也需要被更新。如果被冗余存储的字段（如用户姓名）发生变化，需要执行&lt;strong&gt;多次写入&lt;/strong&gt;操作去更新所有包含该冗余信息的文档（即&lt;strong&gt;最终一致性&lt;/strong&gt;问题）。不支持复杂的 JOIN 操作，需要通过应用层逻辑或两次查询来实现关联查询。但是，每个文档（或 Key-Value）是独立的，非常容易分散到多台机器上（水平扩展）。单个文档的结构变化不影响其他文档。获取一个实体的大部分数据通常只需要&lt;strong&gt;一次查询&lt;/strong&gt;，消除了耗时的 JOIN 操作。&lt;/p&gt;

&lt;p&gt;【3】从&lt;strong&gt;数据库查询语句&lt;/strong&gt;的角度&lt;/p&gt;

&lt;p&gt;SQL 是一种&lt;strong&gt;高度标准化&lt;/strong&gt;、&lt;strong&gt;声明式（Declarative）&lt;/strong&gt;的语言。&lt;/p&gt;

&lt;p&gt;无论使用 MySQL、PostgreSQL 还是 SQL Server，核心的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt;、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INSERT&lt;/code&gt;、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UPDATE&lt;/code&gt;、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DELETE&lt;/code&gt; 语法都是通用的，开发者可以跨数据库快速迁移知识。比如：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c1&quot;&gt;-- 查询：从Users表中，找出年龄大于25，并按姓名排序的记录&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;用户&lt;strong&gt;声明&lt;/strong&gt;他们想要什么结果（&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT id, name&lt;/code&gt;），而不必告诉数据库&lt;strong&gt;如何&lt;/strong&gt;获取这个结果（数据库的查询优化器会自行决定最佳的执行路径）。&lt;/p&gt;

&lt;p&gt;Nosql语言&lt;strong&gt;不统一&lt;/strong&gt;，通常是针对特定数据模型设计的 API 或命令集，或是模仿 SQL 的查询语言。比如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;键值对 (Redis)&lt;/strong&gt;：主要是&lt;strong&gt;命令式&lt;/strong&gt;（Imperative），基于简单的命令（Commands）。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;GET&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;-- 命令式：精确指定要执行的动作&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;文档型 (MongoDB)&lt;/strong&gt;：使用基于 &lt;strong&gt;JSON 的查询语言&lt;/strong&gt;（MongoDB Query Language, MQL）。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MQL&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;示例：从&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;users&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;集合中查找&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;的文档&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;users&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;图数据库 (Neo4j)&lt;/strong&gt;：使用专门的语言如 &lt;strong&gt;Cypher&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Cypher&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;示例：查找节点&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;和节点&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;之间的关系&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;MATCH&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;User&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;Alice&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FRIENDS_WITH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RETURN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Search 搜索引擎型 (Elasticsearch)，用RESTful API进行查询&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;示例：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;elasticsearch GET http://localhost:9200/users/1&lt;/code&gt;。通过 HTTP API 的形式，使用 GET、POST 等动词和 URL 路径来操作数据，通常用于全文检索和复杂聚合分析。&lt;/p&gt;

&lt;p&gt;【4】从&lt;strong&gt;事务（Transaction）&lt;/strong&gt;的角度&lt;/p&gt;

&lt;p&gt;事务保证一组操作要么全部成功，要么全部失败。&lt;/p&gt;

&lt;p&gt;SQL 关系型数据库（如 MySQL、PostgreSQL）将 &lt;strong&gt;ACID 特性&lt;/strong&gt;作为其设计的基本要求。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;原子性 (Atomicity)&lt;/strong&gt;：事务中的所有操作要么全部完成，要么全部不完成。如果事务中任何一步失败，所有已完成的操作都将被回滚到事务开始前的状态。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;一致性 (Consistency)&lt;/strong&gt;：事务必须使数据库从一个有效状态转换到另一个有效状态。它确保了数据的完整性约束（如外键、唯一性约束）不会被破坏。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;隔离性 (Isolation)&lt;/strong&gt;：并发执行的事务之间互不干扰。每个事务都感觉自己是系统中唯一在运行的事务。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;持久性 (Durability)&lt;/strong&gt;：一旦事务被提交，它对数据库的改变就是永久性的，即使发生系统故障（如断电）也不会丢失。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;SQL 数据库通过复杂的锁定机制（如行锁、表锁）和日志系统（如 Redo Log, Undo Log）来严格保证 ACID。在金融、库存管理、订单处理等需要&lt;strong&gt;强一致性&lt;/strong&gt;的业务场景中不可替代。为了维护严格的隔离性和一致性，事务会引入锁的竞争和等待，在高并发环境下会&lt;strong&gt;牺牲一部分性能&lt;/strong&gt;和&lt;strong&gt;水平扩展性&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;NoSQL 数据库（如 Cassandra、MongoDB、Redis）的设计目标是&lt;strong&gt;高性能、高可用性和可扩展性（Scale Out）&lt;/strong&gt;，因此它们通常&lt;strong&gt;放宽了对强一致性（尤其是隔离性）的要求&lt;/strong&gt;，采用了 BASE 模型。&lt;/p&gt;

&lt;p&gt;A. BASE 原则&lt;/p&gt;

&lt;p&gt;BASE 是对 ACID 的反向总结，是分布式系统常用的设计原则：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;基本可用性 (Basically Available)&lt;/strong&gt;：系统保证在任何情况下都能对外提供服务，允许&lt;strong&gt;响应时间延长&lt;/strong&gt;或&lt;strong&gt;返回非最新数据&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;软状态 (Soft State)&lt;/strong&gt;：系统状态可以随着时间流逝而发生改变，不要求实时的一致性。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;最终一致性 (Eventually Consistent)&lt;/strong&gt;：系统中的数据复制需要时间，但在没有新的更新操作时，经过一段同步时间后，所有副本的数据最终会达到一致状态。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;B. NoSQL 中的事务与一致性&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Key-Value (Redis)&lt;/strong&gt;：
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;事务&lt;/strong&gt;：Redis 提供了有限的事务（使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MULTI&lt;/code&gt; 和 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXEC&lt;/code&gt; 命令），但它不具备 ACID 的&lt;strong&gt;回滚能力&lt;/strong&gt;（即原子性保障较弱，如果命令执行失败，已执行的命令不会回滚）。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;一致性&lt;/strong&gt;：通常是&lt;strong&gt;最终一致性&lt;/strong&gt;，但在单节点下可以保证操作的顺序性。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;文档型 (MongoDB)&lt;/strong&gt;：
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;单文档操作&lt;/strong&gt;：MongoDB 保证&lt;strong&gt;单个文档&lt;/strong&gt;的 CRUD 操作是原子性的。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;多文档事务&lt;/strong&gt;：较新的版本开始支持&lt;strong&gt;多文档 ACID 事务&lt;/strong&gt;，但实现机制复杂且性能开销大于 SQL，常用于解决跨文档操作的原子性问题，但并非其主要优势。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;一致性&lt;/strong&gt;：支持不同级别的&lt;strong&gt;读写关注（Read/Write Concern）&lt;/strong&gt;配置，允许用户在&lt;strong&gt;一致性&lt;/strong&gt;和&lt;strong&gt;性能/可用性&lt;/strong&gt;之间进行选择。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;宽列/图数据库 (Cassandra)&lt;/strong&gt;：
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;事务&lt;/strong&gt;：通常只保证&lt;strong&gt;行级别的操作原子性&lt;/strong&gt;。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;一致性&lt;/strong&gt;：默认是&lt;strong&gt;最终一致性&lt;/strong&gt;，为了实现高可用和水平扩展，牺牲了强一致性。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;通过放弃严格的 ACID 保证，减少了锁竞争和同步开销，极大地提高了系统的&lt;strong&gt;并发处理能力&lt;/strong&gt;和&lt;strong&gt;水平扩展性&lt;/strong&gt;。开发者必须在应用层处理数据可能存在的&lt;strong&gt;暂时不一致状态&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;redis的用途&quot;&gt;redis的用途&lt;/h2&gt;

&lt;p&gt;（1）缓存系统（将热点数据从慢速数据库迁移出来）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251111171507582.png&quot; alt=&quot;image-20251111171507582&quot; /&gt;&lt;/p&gt;

&lt;p&gt;（2）会话存储（分布式Session）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251111171746150.png&quot; alt=&quot;image-20251111171746150&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;在分布式多服务器环境下，由于用户会话（Session）被存储在单个服务器的本地，当后续请求被路由到其他服务器时，无法共享 Session 信息，导致用户被迫退出或登录失败。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;为了解决这个问题引入redis：将原本分散存储在 &lt;strong&gt;服务器A&lt;/strong&gt; 和 &lt;strong&gt;服务器B&lt;/strong&gt; &lt;strong&gt;本地&lt;/strong&gt;的 Session 数据，统一迁移到 &lt;strong&gt;Redis 集群&lt;/strong&gt;（一个&lt;strong&gt;独立&lt;/strong&gt;于应用服务器的高速、内存型数据存储）。&lt;/p&gt;

&lt;p&gt;用户登录请求到达 &lt;strong&gt;服务器A&lt;/strong&gt; 后，&lt;strong&gt;服务器A&lt;/strong&gt; 不再将 Session 存储在本地，而是将 Session ID 和对应的用户信息写入 &lt;strong&gt;Redis&lt;/strong&gt;。&lt;strong&gt;服务器A&lt;/strong&gt; 会将这个 Session ID (通常通过 Cookie 或 Token) 返回给用户浏览器。&lt;/p&gt;

&lt;p&gt;用户后续的请求到达 &lt;strong&gt;服务器B&lt;/strong&gt;。请求中携带着之前由服务器A发出的 &lt;strong&gt;Session ID&lt;/strong&gt;。&lt;strong&gt;服务器B&lt;/strong&gt; 接收到请求后，会使用这个 &lt;strong&gt;Session ID&lt;/strong&gt; 向 &lt;strong&gt;Redis&lt;/strong&gt; 发起查询。&lt;strong&gt;Redis&lt;/strong&gt; 快速返回对应的 Session 数据。&lt;strong&gt;服务器B&lt;/strong&gt; 成功验证用户身份，请求得以继续执行。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251111172703728.png&quot; alt=&quot;image-20251111172703728&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Redis 作为一个&lt;strong&gt;共享的、中央存储库&lt;/strong&gt;，确保了所有应用服务器都能访问到相同的 Session 数据。&lt;/p&gt;

&lt;p&gt;Redis 是一个&lt;strong&gt;内存数据库&lt;/strong&gt;，读写速度极快，这对于对性能要求高的 Session 操作至关重要。&lt;/p&gt;

&lt;p&gt;通过 Redis 集群和数据复制，可以避免因为单个应用服务器故障而丢失 Session 的风险。&lt;/p&gt;

&lt;p&gt;引入 Redis 后，应用服务器（A和B）自身不再需要维护用户状态，变得&lt;strong&gt;无状态&lt;/strong&gt;。这样它们可以轻松地水平扩展，增加更多的服务器（C、D、E…），而不会遇到图中的 Session 丢失问题。&lt;/p&gt;

&lt;p&gt;（3）分布式锁：可以利用 &lt;strong&gt;Redis&lt;/strong&gt; 来实现对共享资源的&lt;strong&gt;互斥访问&lt;/strong&gt;，这就是 &lt;strong&gt;分布式锁&lt;/strong&gt; 的基本概念。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251111173048618.png&quot; alt=&quot;image-20251111173048618&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在分布式系统中，当多个独立的服务器需要&lt;strong&gt;同时&lt;/strong&gt;修改或访问同一个共享资源（例如扣减库存、更新数据库记录）时，如果不加控制，就可能发生&lt;strong&gt;竞态条件&lt;/strong&gt;（Race Condition）和&lt;strong&gt;数据不一致&lt;/strong&gt;的问题。&lt;/p&gt;

&lt;p&gt;谁先在 Redis 中成功设置了代表“锁”的 Key，谁就获得了对共享资源的独占访问权（即“先拿先用”）。&lt;/p&gt;

&lt;p&gt;服务器A &lt;strong&gt;完成操作后&lt;/strong&gt;，必须向 Redis 发送请求（使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DEL&lt;/code&gt; 命令）将这个 Key &lt;strong&gt;删除&lt;/strong&gt;，从而释放锁。否则，其他服务器将永远无法获取锁。&lt;/p&gt;

&lt;p&gt;如果在服务器A持有锁期间发生崩溃，导致它无法释放锁，就会造成 &lt;strong&gt;死锁&lt;/strong&gt;。解决方法是，在设置锁 Key 时必须同时设置一个 &lt;strong&gt;过期时间（Expiry Time / TTL）&lt;/strong&gt;。即使服务器A崩溃，Redis 也会在一段时间后自动删除这个 Key，从而保证锁能够最终被释放。&lt;/p&gt;

&lt;p&gt;（4）限流&lt;/p&gt;

&lt;p&gt;（5）结合Lua脚本，实现多个操作的原子性，避免数据不一致性。&lt;/p&gt;

&lt;p&gt;当涉及到分布式锁的释放时，仅仅使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DEL&lt;/code&gt; 命令是不够安全的，因为存在一个&lt;strong&gt;时间差&lt;/strong&gt;（Time Gap）可能导致数据错误。Lua 脚本就是用来解决这个问题的。&lt;/p&gt;

&lt;p&gt;在分布式锁中，我们需要确保&lt;strong&gt;“检查锁的归属权”&lt;/strong&gt;和&lt;strong&gt;“删除锁 Key”&lt;/strong&gt;这两个操作是&lt;strong&gt;原子性&lt;/strong&gt;的，它们必须作为一个整体被执行。&lt;/p&gt;

&lt;p&gt;Redis 保证&lt;strong&gt;所有发送到服务器的 Lua 脚本都会被当作一个单一的、不可分割的原子操作来执行&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;比如下面的Lua脚本：&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;KEYS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;是锁的&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;例如:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mylock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ARGV&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;是请求锁时设置的&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;、&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;代表当前服务器的唯一标识值&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;例如:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;serverA_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;get&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;KEYS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ARGV&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;then&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;只有当前锁的值等于我设置的值时&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;才删除它&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;del&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;KEYS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;锁已过期或已被其他服务获取&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;不执行删除操作&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Redis &lt;strong&gt;一次性执行&lt;/strong&gt;整个 Lua 脚本，确保了“检查（&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GET&lt;/code&gt;）”和“删除（&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DEL&lt;/code&gt;）”这两个关键步骤不会被其他任何操作打断。&lt;/p&gt;

&lt;p&gt;服务器 A 只能删除它自己设置的锁。如果锁在 A 的操作期间过期了，那么锁的值已经被服务器 B 修改（或刷新），A 的脚本会发现 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;redis.call(&quot;get&quot;, KEYS[1])&lt;/code&gt; 的值不再是 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARGV[1]&lt;/code&gt;（&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;serverA_id&lt;/code&gt;），从而&lt;strong&gt;安全地跳过删除操作&lt;/strong&gt;，避免了误删服务器 B 的锁。&lt;/p&gt;

&lt;h2 id=&quot;丰富的数据结构&quot;&gt;丰富的数据结构&lt;/h2&gt;

&lt;p&gt;与其他仅支持简单字符串的键值存储不同，Redis 支持丰富的数据结构，这使其功能更加强大和灵活：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251109213456651.png&quot; alt=&quot;image-20251109213456651&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;数据结构&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;描述&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;典型应用&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;String (字符串)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;最基本的数据类型，可以存储文本、数字或二进制数据。&lt;/td&gt;
      &lt;td&gt;缓存对象、计数器（如点赞数）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Hash (哈希)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;类似于字典或对象，在一个键下存储多个字段和值。&lt;/td&gt;
      &lt;td&gt;存储用户信息、对象数据&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;List (列表)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;有序的字符串列表，可以从头部或尾部添加/删除元素。&lt;/td&gt;
      &lt;td&gt;消息队列、最新动态列表&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Set (集合)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;无序的、不重复的字符串集合。&lt;/td&gt;
      &lt;td&gt;社交关系（共同好友）、标签系统&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Sorted Set (有序集合)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;集合中的每个成员都会关联一个分数（Score），成员按分数排序。&lt;/td&gt;
      &lt;td&gt;排行榜&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;尽管 Redis 是内存存储，但它提供了将数据持久化到磁盘的机制，以防止服务器宕机时数据丢失：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;RDB (Redis Database)：&lt;/strong&gt; 定期将内存中的数据&lt;strong&gt;快照&lt;/strong&gt;（Snapshot）写入磁盘。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;AOF (Append Only File)：&lt;/strong&gt; 记录所有对 Redis 数据的&lt;strong&gt;修改操作命令&lt;/strong&gt;，以日志形式追加到文件中。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此外，Redis 还支持：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;主从复制 (Replication)：&lt;/strong&gt; 将数据从主节点同步到多个从节点，用于读写分离和数据冗余。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sentinel (哨兵)：&lt;/strong&gt; 监控 Redis 实例的运行状态，并提供&lt;strong&gt;自动故障转移&lt;/strong&gt;能力，实现高可用。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cluster (集群)：&lt;/strong&gt; 自动在多个节点之间&lt;strong&gt;分片&lt;/strong&gt;（Sharding）数据集，提高性能和可扩展性。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;redis和memcached的区别&quot;&gt;redis和memcached的区别&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;特性&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Redis (REmote DIctionary Server)&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Memcached (Memory Cache Daemon)&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;数据结构&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;丰富多样：&lt;/strong&gt; 支持 String、Hash、List、Set、Sorted Set 等。&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;单一简单：&lt;/strong&gt; 仅支持最简单的 &lt;strong&gt;String&lt;/strong&gt;（键值对）。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;持久化&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;支持：&lt;/strong&gt; 提供 RDB（快照）和 AOF（日志）两种方式，可将数据从内存同步到磁盘。&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;不支持：&lt;/strong&gt; 所有数据完全存储在内存中，服务重启或宕机，数据会丢失。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;内存管理&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;采用更灵活的内存管理机制（基于包装的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;malloc/free&lt;/code&gt;），能支持复杂的结构。&lt;/td&gt;
      &lt;td&gt;采用&lt;strong&gt;Slab Allocation&lt;/strong&gt;（内存块分配），对内存利用率更高，但结构单一。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;复制/高可用&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;支持：&lt;/strong&gt; 提供主从复制（Replication）和 Sentinel（哨兵）机制。&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;不支持：&lt;/strong&gt; 仅能通过客户端或外部工具实现分布式。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;事务性&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;支持：&lt;/strong&gt; 通过 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MULTI&lt;/code&gt;/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXEC&lt;/code&gt; 命令实现简单的事务原子性。&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;不支持&lt;/strong&gt;。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;CPU 模型&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;单线程模型&lt;/strong&gt;：保证了操作的原子性，避免了上下文切换开销。&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;多线程模型&lt;/strong&gt;：可以利用多核 CPU 处理网络 I/O。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;使用场景&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;通用性强：&lt;/strong&gt; 缓存、队列、排行榜、计数器、实时应用。&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;纯粹缓存：&lt;/strong&gt; 简单键值存储和读取。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Redis 在&lt;strong&gt;处理 JSON 或复杂数据&lt;/strong&gt;时，其设计更具优势：&lt;/p&gt;

&lt;p&gt;Memcached 只支持 String 类型。当你在 Memcached 中存储一个 JSON 对象时，它必须先被&lt;strong&gt;序列化&lt;/strong&gt;（例如，使用 JSON.stringify 转换为字符串），然后整个字符串作为一个 Value 存储。必须读取整个 JSON 字符串，然后在应用端进行&lt;strong&gt;反序列化&lt;/strong&gt;（例如，JSON.parse）才能操作其中的字段。如果只想修改 JSON 对象中的一个字段（例如用户的邮箱），必须将整个 JSON 字符串取出 \(\rightarrow\) 反序列化 \(\rightarrow\) 修改字段 \(\rightarrow\)  重新序列化  \(\rightarrow\)存回缓存。这个过程涉及多次&lt;strong&gt;网络 I/O 和 CPU 密集型操作&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;Redis 提供了 &lt;strong&gt;Hash（哈希）&lt;/strong&gt;数据类型，非常适合存储对象（如 JSON）。当存储一个 JSON 对象时，可以将其转换为 Redis Hash：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;键（Key）对应 JSON 对象。&lt;/li&gt;
  &lt;li&gt;Hash 的字段（Field）对应 JSON 对象的属性。&lt;/li&gt;
  &lt;li&gt;Hash 的值（Value）对应 JSON 属性的值。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可以使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HGET&lt;/code&gt; 命令&lt;strong&gt;只获取对象中的某个字段&lt;/strong&gt;，无需读取整个对象并反序列化。可以使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HSET&lt;/code&gt; 命令&lt;strong&gt;只修改对象中的某个字段&lt;/strong&gt;，无需取出整个对象，&lt;strong&gt;极大地减少了网络流量和应用端的 CPU 开销&lt;/strong&gt;。此外，Redis 还有专门的 &lt;strong&gt;RedisJSON 模块&lt;/strong&gt;，可以直接存储和操作 JSON 数据—-【计算向数据移动】&lt;/p&gt;

&lt;h2 id=&quot;单线程&quot;&gt;单线程&lt;/h2&gt;

&lt;p&gt;【注意】redis6 引入了多线程。&lt;/p&gt;

&lt;p&gt;单线程，每个命令都具备原子性。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【1】单线程设计原因：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Redis 的操作是基于内存的，其大多数操作的性能瓶颈主要不是 CPU 导致的&lt;/li&gt;
  &lt;li&gt;使用单线程模型，代码简便的同时也减少了线程上下文切换带来的性能开销&lt;/li&gt;
  &lt;li&gt;Redis 在单线程的情况下，使用&lt;strong&gt;I/O多路复用模型&lt;/strong&gt;就可以提高 Redis 的 I/O 利用率了&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;注：所说的 Redis 单线程，主要指的是 Redis 网络 I/O 和键值对读写这些操作是由一个线程完成的。(持久化、集群等机制其实是有后台线程执行的)
不过 Redis 并不是一直都单线程的，在 4.0 之后就开始引入了多线程指令，6.0 之后便正式引入了多线程的机制，不过 这里的多线程其只是针对网络请求过程使用多线程，其对于数据读写命令的处理依旧是单线程的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【2】6.0 版本引入多线程的原因&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;随着数据规模的增长、请求量的增多，Redis 的执行瓶颈主要在于网络 I/O。引入多线程处理可以提高网络 I/O处理速度。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;为什么 Redis 前期不使用多线程的方式，等到 6.0 却又引入呢？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;主要是因为对 Redis 的性能有了更高的要求，因为随着业务愈加复杂，公司需要的 QPS 就越高了，为了提升 QPS，最直接的做法就是搭建 Redis 的集群，即提高 Redis 的机器数，但是这种做法的资源消耗是巨大的。&lt;/p&gt;

&lt;p&gt;而 Redis 单线程执行命令的性能瓶颈在网络 I/O，虽然它采用了多路复用技术，但 I/O 多路复用模型本质还是同步 I/O。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251111235237458.png&quot; alt=&quot;image-20251111235237458&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从上面这个图中可以看到，I/O多路复用在处理网络请求的时候，其调用 select(或是 epoll 等)后，如果来数据了，那么将数据从内核拷贝到用户空间这一步是同步的,即用户线程需要等待数据拷贝完成 (在 redis 场景就是无法处理命令了),如果并发量很高的话，这个过程可能会成为瓶颈。
综上所示，多路复用+单线程的设计并不能很好地解决网络I/O瓶颈的问题，这个时候就可以考虑利用 CPU的多核优势，即利用多线程处理网络请求的方式来提高效率，然后对于读写命令，Redis 依旧采用单线程命令。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【3】Redis 引入多线程之后，有没有带来什么线程安全问题呢？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;没有，因为 Redis 6.0 只有针对网络请求模块采用的是多线程，对于读写命令部分还是采用单线程，所以所谓的线程安全问题就不存在了。
Redis 6.0 的多线程默认是禁用的，只使用主线程，因为大部分公司并发量实际上还是用不上这个。&lt;/p&gt;

&lt;p&gt;如果要开启，需要配置 io-threads-do-reads 参数为 yes 。开启多线程后，还需要设置线程数，否则是不生效的。同样需要修改 redis 配置文件 redis.conf: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;io-threads&lt;/code&gt;。官网建议4核的机器建议设置为2或3个线程，8核的建议设置为6个线程&lt;/p&gt;

&lt;h2 id=&quot;redis为什么这么快&quot;&gt;redis为什么这么快&lt;/h2&gt;

&lt;p&gt;【基于内存、单线程事件驱动模型+IO多路复用、编码】&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;（最重要）Redis 完全基于内存存储，相比于磁盘IO，不论是寻址，还是带宽，内存都很快。提供快速的读写速度，相比于传统的磁盘数据库，内存访问速度快得多。&lt;strong&gt;磁盘中&lt;/strong&gt;寻址ms/微妙级别，带宽MB/s，GB/s；&lt;strong&gt;内存&lt;/strong&gt;寻址ns(纳秒)级别，比磁盘快10万倍，带宽很大。&lt;/li&gt;
  &lt;li&gt;Redis 使用单线程事件驱动模型结合 I/O 多路复用（如 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Epoll&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Select&lt;/code&gt;/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Poll&lt;/code&gt;），避免了多线程上下文切换和竞争条件，提高了并发处理效率。单线程模型&lt;strong&gt;避免了多线程之间的上下文切换开销&lt;/strong&gt;，以及因锁竞争导致的性能损耗。I/O 多路复用使得单个线程可以在高并发场景下，&lt;strong&gt;同时监听大量的网络连接&lt;/strong&gt;，在等待I/O的过程中不被阻塞，从而在&lt;strong&gt;网络 I/O 密集型&lt;/strong&gt;场景下实现了高效的并发处理。(但是，是同步IO)&lt;/li&gt;
  &lt;li&gt;Redis 提供多种高效的数据结构 (如字符串、哈希、列表、集合等),这些结构经过优化，能够快速完成各种操作Redis 内部提供了多种&lt;strong&gt;经过高度优化的底层数据结构。这些数据结构的设计目标就是为了保证&lt;/strong&gt;大多数操作的时间复杂度为 O(1) 或 O(log N)（例如，哈希表的查找是 O(1)，跳跃表的查找是 O(log N)），从而保证了操作效率。&lt;/li&gt;
  &lt;li&gt;redis源码基于C语言编写，其编写规范等等业界都很认可。C语言编译后能生成高效的机器码，且 Redis 的代码库质量高，工程实现精简且出色&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;6redis安装&quot;&gt;6.redis安装&lt;/h1&gt;

&lt;p&gt;环境：纯净centos7.5，镜像是CentOS-7.5-x86_64-DVD-1804.iso&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;CentOS&lt;/strong&gt; 是一种基于 Red Hat Enterprise Linux (RHEL) 的发行版，属于 &lt;strong&gt;RPM 系列&lt;/strong&gt;（使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.rpm&lt;/code&gt; 包文件格式）。&lt;/p&gt;

&lt;p&gt;CentOS/RHEL 使用 &lt;strong&gt;YUM&lt;/strong&gt; 或 &lt;strong&gt;DNF&lt;/strong&gt; 作为其主要的包管理器，它们依赖于 RPM 包进行安装、更新和管理。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;APT&lt;/strong&gt; (Advanced Packaging Tool) 是 Debian/Ubuntu 等 &lt;strong&gt;DEB 系列&lt;/strong&gt;发行版使用的包管理器。&lt;/p&gt;

&lt;p&gt;https://redis.io/docs/latest/operate/oss_and_stack/install/install-stack/&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251109222249229.png&quot; alt=&quot;image-20251109222249229&quot; /&gt;&lt;/p&gt;

&lt;p&gt;因为我用的是centos，所以安装细节参考：https://redis.io/docs/latest/operate/oss_and_stack/install/install-stack/rpm/&lt;/p&gt;

&lt;p&gt;如果是Debian或者ubuntu，参考：https://redis.io/docs/latest/operate/oss_and_stack/install/install-stack/apt/&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;方法1&quot;&gt;方法1:&lt;/h2&gt;

&lt;p&gt;在 CentOS 7.5 上安装 Redis，最推荐且最稳定的是使用 &lt;strong&gt;EPEL (Extra Packages for Enterprise Linux) 仓库&lt;/strong&gt; 或 &lt;strong&gt;从源代码编译安装&lt;/strong&gt;。下面推荐使用 EPEL 仓库安装。由于 Redis 经常包含在 EPEL 仓库中，这是最简单且最稳定的方式。&lt;/p&gt;

&lt;p&gt;首先，安装 EPEL 仓库配置，因为 Redis 包通常在其内：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;release&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;yum&lt;/code&gt; 命令从 EPEL 仓库安装 Redis：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;安装完成后，启动 Redis 服务并设置开机自启：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemctl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemctl&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;检查状态:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemctl&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;备注通过ssh连接centos:&lt;/p&gt;

  &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;ssh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;172&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;135&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;130&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;

  &lt;p&gt;然后输入密码。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;停止 Redis 服务并禁用开机自启：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;停止&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Redis&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;服务&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemctl&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;禁用&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Redis&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;开机自启&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemctl&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;disable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;yum remove&lt;/code&gt; 命令卸载 Redis 主程序包。为了确保卸载干净，最好同时使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;yum autoremove&lt;/code&gt; 来移除 Redis 安装时作为依赖项安装的软件包（例如 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jemalloc&lt;/code&gt;）。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;卸载&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Redis&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;软件包&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;remove&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt; 

&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;（可选，推荐）自动移除不再被任何软件包需要的依赖项&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;这一步会移除&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jemalloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x86_64&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;el7&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;autoremove&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;yum&lt;/code&gt; 卸载只会移除程序文件，但通常会保留配置文件、日志文件和持久化数据文件。需要手动删除这些残留文件以实现完全卸载。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; &lt;strong&gt;这一步会删除 Redis 数据。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果需要，可以清理 YUM 缓存。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clean&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;all&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;方法2多实例配置&quot;&gt;方法2:多实例配置&lt;/h2&gt;

&lt;p&gt;下面介绍另外一种方式安装：这种安装方式虽然比使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;yum&lt;/code&gt; 仓库复杂，但能确保安装到特定版本，并对安装路径有完全的控制权。&lt;/p&gt;

&lt;p&gt;阶段一：准备工作与下载&lt;/p&gt;

&lt;p&gt;确保系统安装了 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;wget&lt;/code&gt;，这是通过命令行从互联网下载文件的常用工具。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;yum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wget&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;切换到当前用户的主目录（例如 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/apple/&lt;/code&gt; 或 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/root/&lt;/code&gt;），作为后续操作的基准目录。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;创建一个名为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;soft&lt;/code&gt; 的目录，用于存放下载的 Redis 源码包，保持文件组织整洁。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soft&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soft&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;从 Redis 官网下载某个版本（比如 5.0.5等等） 版本的 Gzip 压缩包。&lt;/p&gt;

&lt;p&gt;现在最新版本是7.2.5&lt;/p&gt;

&lt;p&gt;下面这个地址的格式7.2.5可以用，5.0.5也可以。应该是通用的。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;wget&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;http&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;releases&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gz&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tar&lt;/code&gt; 命令解压下载的压缩包。解压后会得到一个名为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;redis-7.2.5&lt;/code&gt; 的目录。然后进入到 Redis 的源代码目录。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;tar&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xf&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gz&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;阅读&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;README.md&lt;/code&gt;。这是一个好习惯。查看 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;README.md&lt;/code&gt; 文件通常可以了解编译、配置和安装的最新、最准确的指示。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;README&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;md&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;或者&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vi&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;README&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;md&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;README.md内容在最后我复制出来了。&lt;/p&gt;

&lt;p&gt;阶段二：编译与安装&lt;/p&gt;

&lt;p&gt;运行 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;make&lt;/code&gt; 开始编译过程。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;make&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果系统没有安装 &lt;strong&gt;GCC (GNU Compiler Collection)&lt;/strong&gt;，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;make&lt;/code&gt; 命令会失败。CentOS 6.x 可能需要先安装 GCC，这是 C 语言程序的编译器。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;yum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gcc&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;没有报错就不需要安装&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果第一次 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;make&lt;/code&gt; 失败，需要运行 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;make distclean&lt;/code&gt; 来清除之前编译失败留下的所有中间文件和配置，确保第二次编译是全新的开始。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;make&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distclean&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;没有执行&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gcc&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;，那么这一步也不需要执行&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在安装 GCC 并清理后，再次运行 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;make&lt;/code&gt;。这次应该能成功编译出所有的可执行文件。&lt;/p&gt;

&lt;p&gt;编译成功后，所有的可执行文件（如 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;redis-server&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;redis-cli&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;redis-benchmark&lt;/code&gt; 等）会生成在源代码目录下的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;src/&lt;/code&gt; 目录中。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251110011001229.png&quot; alt=&quot;image-20251110011001229&quot; /&gt;&lt;/p&gt;

&lt;p&gt;运行 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;make install&lt;/code&gt;，并使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PREFIX&lt;/code&gt; 参数将编译好的程序安装到指定目录 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/opt/hilda/redis7&lt;/code&gt;。这是一种&lt;strong&gt;定制化安装&lt;/strong&gt;，使得 Redis 文件不会散落在系统目录中，便于管理和升级。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;make&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PREFIX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hilda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251110010859918.png&quot; alt=&quot;image-20251110010859918&quot; /&gt;&lt;/p&gt;

&lt;p&gt;阶段三：配置环境变量&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/profile&lt;/code&gt; 文件用于设置系统全局的环境变量。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;vi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;profile&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;设置一个变量指向 Redis 的安装根目录。然后需要&lt;strong&gt;将可执行文件路径添加到 PATH&lt;/strong&gt;， 这样就可以在任何目录下直接执行 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;redis-server&lt;/code&gt; 或 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;redis-cli&lt;/code&gt; 等命令，而无需输入完整的路径。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;REDIS_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hilda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;REDIS_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;重新加载 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;profile&lt;/code&gt; 文件，使环境变量立即在当前会话中生效。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;profile&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;阶段四：配置多实例与服务化&lt;/p&gt;

&lt;p&gt;进入工具目录。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;soft&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;运行 Redis 提供的安装脚本，用于&lt;strong&gt;快速配置和部署 Redis 实例作为系统服务&lt;/strong&gt;。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;install_server&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在5.0.5版本中，这个命令可以执行，但是7.2.5出现：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;172&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;install_server&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Welcome&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;service&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;installer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;This&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;script&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;will&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;you&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;easily&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;up&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;running&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;This&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systems&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seems&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Please&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;take&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;look&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;provided&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;service&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;files&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;directory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adapt&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;them&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sorry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;您好，这个提示信息是 &lt;strong&gt;Redis 5.x 版本的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;install_server.sh&lt;/code&gt; 脚本&lt;/strong&gt;在 &lt;strong&gt;CentOS 7.x&lt;/strong&gt;（或其他使用 &lt;strong&gt;systemd&lt;/strong&gt; 的现代 Linux 发行版）上运行时给出的&lt;strong&gt;明确拒绝信息&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;install_server.sh&lt;/code&gt; 脚本最初是为 &lt;strong&gt;CentOS 6.x&lt;/strong&gt; 或更早版本设计的，这些系统使用老式的 &lt;strong&gt;SysVinit&lt;/strong&gt; 或 &lt;strong&gt;Upstart&lt;/strong&gt; 作为服务初始化系统。该脚本的主要功能就是创建 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/init.d/&lt;/code&gt; 下的服务启动脚本。&lt;/p&gt;

&lt;p&gt;CentOS 7.x 及更高版本已经切换到 &lt;strong&gt;systemd&lt;/strong&gt; 作为其初始化系统。Systemd 使用 &lt;strong&gt;Unit Files&lt;/strong&gt;（单元文件，通常以 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.service&lt;/code&gt; 结尾）来管理服务，而不是传统的 SysVinit 脚本。&lt;/p&gt;

&lt;p&gt;Redis 5.x 提供的这个 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;install_server.sh&lt;/code&gt; 脚本&lt;strong&gt;无法自动生成或正确配置 systemd Unit File&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;因此，脚本检测到系统是 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;systemd&lt;/code&gt; 架构后，直接停止执行，并提示查看源码目录中提供的示例 Unit File（&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;example service unit files&lt;/code&gt;），并要求手动进行安装配置。&lt;/p&gt;

&lt;p&gt;要在 CentOS 7.5 上启动和管理 Redis，需要手动创建和配置一个 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;redis.service&lt;/code&gt; 文件，并将其放置在 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/systemd/system/&lt;/code&gt; 目录下。&lt;/p&gt;

&lt;p&gt;下面将使用 Redis 源码包中提供的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;systemd-redis_server.service&lt;/code&gt; 模板来创建并启动 Redis 服务。&lt;/p&gt;

&lt;p&gt;一个物理机可以启动多个 Redis 实例。Redis 官方考虑到多实例部署的常见需求，在 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;utils&lt;/code&gt; 目录下提供了更高级的解决方案：&lt;strong&gt;Systemd 模板服务&lt;/strong&gt;。使用 Systemd 的模板服务 (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;systemd-redis_multiple_servers@.service&lt;/code&gt;) 是最优雅和推荐的方式，因为它允许您通过一个配置文件和一套命令，管理多个不同端口的 Redis 实例。redis通过端口号区分不同的redis实例。下面通过部署 Redis 7.2.5 多实例 (6379 &amp;amp; 6380)2个实例为例，说明。&lt;/p&gt;

&lt;p&gt;将使用以下路径：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Redis 可执行文件路径：&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/opt/hilda/redis7/bin/&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;配置目录：&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/redis7/&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;数据目录基础：&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/var/lib/redis7/&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;日志目录：&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/var/log/redis7/&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;（1）准备目录和配置文件&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;创建配置、数据和日志目录&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;复制源码中的配置文件到标准配置目录&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;soft&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;创建额外的配置和数据目录：需要为每个实例准备一个独立的配置文件、数据目录和日志文件。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;复制源码中的配置文件作为&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;的基础&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;soft&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;复制源码中的配置文件作为&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6380&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;的基础&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;soft&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6380&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;创建&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6380&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;实例的数据目录&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6380&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;（2）修改 Redis 配置文件:&lt;/p&gt;

&lt;p&gt;必须编辑 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/redis7/6379.conf&lt;/code&gt; 文件，将其配置为适合 Systemd 启动的方式：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;vi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;关闭守护进程模式：&lt;/strong&gt; 必须由 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;systemd&lt;/code&gt; 负责进程管理。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;daemonize&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;no&lt;/span&gt; 
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;设置 PID 文件路径：&lt;/strong&gt; 供 systemd 监控进程。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;pidfile&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis_6379&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pid&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;设置日志文件路径：&lt;/strong&gt; 确保日志输出到正确位置。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;logfile&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;/var/log/redis7/redis_6379.log&quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;设置持久化数据目录：&lt;/strong&gt; 确保 RDB/AOF 文件存放在这里。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;dir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/var/log/redis7/redis_6380.log&lt;/code&gt;也是类似的配置,注意端口要修改为6380&lt;/p&gt;

&lt;p&gt;（3）安装和配置 Systemd Unit File&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;复制官方模板到 Systemd 目录：&lt;/strong&gt;将模板文件复制到 Systemd 目录，&lt;strong&gt;保持文件名的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;@&lt;/code&gt; 符号&lt;/strong&gt;：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;soft&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;systemd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis_multiple_servers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;service&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;systemd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;system&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;service&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;注意：将其简化命名为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;redis@.service&lt;/code&gt;，这样后续命令会更简洁。&lt;/p&gt;

&lt;p&gt;编辑模板文件，使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%i&lt;/code&gt; (实例名，即端口号) 来引用配置和路径：&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;systemd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;system&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;service&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[Service]&lt;/code&gt; 部分，根据路径 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/opt/hilda/redis7&lt;/code&gt; 和配置命名规则 (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;redis-%i.conf&lt;/code&gt;) 进行修改：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Service&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;其他行保持不变&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ExecStart&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;：启动时加载&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;或&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6380&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;在运行时会被替换为&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;或&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6380&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ExecStart&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hilda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ExecStop&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;：关闭时连接对应端口的实例&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ExecStop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hilda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cli&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shutdown&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PIDFile&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;：指向&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pid&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;或&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6380&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pid&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;PIDFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pid&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;确保与配置文件中的&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pidfile&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;设置保持一致&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;Group&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;其他行保持不变&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;（4）修改&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/systemd/system/redis@.service&lt;/code&gt;中的如下内容：&lt;/p&gt;

&lt;p&gt;将 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[Unit]&lt;/code&gt; 部分的路径修改为实际创建的配置文件路径：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Unit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Description&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Redis&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;structure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Documentation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;https&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;documentation&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;原文件：&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AssertPathExists&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis_server_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;修复：&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AssertPathExists&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;确保断言指向&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;或&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6380&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;将 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[Service]&lt;/code&gt; 部分的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Type=notify&lt;/code&gt; 改为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Type=simple&lt;/code&gt;，以确保兼容性。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Service&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ExecStart&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hilda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ExecStop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hilda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cli&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shutdown&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;PIDFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pid&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;Group&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;LimitNOFILE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10032&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;NoNewPrivileges&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yes&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;原文件：&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;Type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;notify&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;修复：&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;Type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;simple&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TimeoutStartSec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;infinity&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TimeoutStopSec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;infinity&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;UMask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0077&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;（5）启动和验证多实例&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;重载&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemd&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;配置&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemctl&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;daemon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reload&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;启动&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;实例&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemctl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;启动&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6380&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;实例&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemctl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6380&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;检查两个实例的状态&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemctl&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemctl&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6380&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;设置开机自启（可选）&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemctl&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemctl&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6380&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;禁用&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;实例的开机自启&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;可选&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemctl&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;disable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;禁用&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6380&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;实例的开机自启（可选）&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemctl&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;disable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6380&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251110233606225.png&quot; alt=&quot;image-20251110233606225&quot; /&gt;&lt;/p&gt;

&lt;p&gt;两个 Redis 实例（6379 和 6380）都&lt;strong&gt;成功启动并正在运行&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251110233710625.png&quot; alt=&quot;image-20251110233710625&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果要关闭实例：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemctl&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;systemctl&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6380&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;配置修改总结便于查阅&quot;&gt;配置修改总结(便于查阅)&lt;/h2&gt;

&lt;p&gt;1.bind绑定监听的IP地址。默认配置是 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bind 127.0.0.1&lt;/code&gt;，这意味着 Redis 实例&lt;strong&gt;只能&lt;/strong&gt;接受来自本机（&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;localhost&lt;/code&gt;）的连接访问。将 Redis 监听的IP地址设置为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0.0.0.0&lt;/code&gt;，表示 Redis 将&lt;strong&gt;监听所有可用的网络接口&lt;/strong&gt;。这意味着它可以接受来自&lt;strong&gt;任意 IP 地址&lt;/strong&gt;的外部访问。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;bind&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;生产环境不要设置为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0.0.0.0&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;在生产环境中，如果设置 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bind 0.0.0.0&lt;/code&gt;，通常需要同时配置防火墙或 ACL (访问控制列表) 以及密码保护，以避免未经授权的外部访问。&lt;/p&gt;

&lt;p&gt;2.守护进程模式。默认通常是 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;daemonize no&lt;/code&gt;。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;daemonize&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yes&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;配置 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;yes&lt;/code&gt; 的作用：&lt;/strong&gt; 将 Redis 设置为&lt;strong&gt;守护进程 (Daemon)&lt;/strong&gt; 模式运行。这意味着 Redis 服务器将&lt;strong&gt;在后台运行&lt;/strong&gt;，脱离当前的终端会话。当终端关闭后，Redis 进程仍然会继续运行，适合作为服务长期运行。&lt;/p&gt;

&lt;p&gt;3.&lt;strong&gt;设置访问密码&lt;/strong&gt;。默认是注释掉的（相当于没有密码）。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;requirepass&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;123321&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;任何客户端在连接到 Redis 实例后，&lt;strong&gt;必须&lt;/strong&gt;使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AUTH&lt;/code&gt; 命令并提供正确的密码（这里是 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;123321&lt;/code&gt;）才能执行数据操作，提高安全性。&lt;/p&gt;

&lt;p&gt;4.&lt;strong&gt;设置 Redis 服务器监听的TCP端口号&lt;/strong&gt;。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;port&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Redis 服务器将监听 6379端口等待客户端连接。6379是 Redis 官方默认的端口号。&lt;/p&gt;

&lt;p&gt;5.&lt;strong&gt;设置 Redis 的工作目录&lt;/strong&gt;。默认情况下，通常是运行 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;redis-server&lt;/code&gt; 命令时的当前目录。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;dir&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;将工作目录设置为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.&lt;/code&gt;，即&lt;strong&gt;当前目录&lt;/strong&gt;（Redis 服务器启动时所在的目录）。所有需要保存在磁盘上的文件，如&lt;strong&gt;持久化文件&lt;/strong&gt; (RDB 快照、AOF 文件) 和&lt;strong&gt;日志文件&lt;/strong&gt;（如果指定了相对路径），都会存储在这个目录下。&lt;/p&gt;

&lt;p&gt;6.&lt;strong&gt;设置可用的数据库数量&lt;/strong&gt;。默认是 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;databases 16&lt;/code&gt;，即16个数据库，编号从 0到 15。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;databases&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;当前配置 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1&lt;/code&gt; 的作用：&lt;/strong&gt; 将 Redis 实例中可供使用的数据库数量设置为1 个。此时，客户端只能使用编号为0的数据库。&lt;/p&gt;

&lt;p&gt;7.&lt;strong&gt;设置 Redis 能够使用的最大内存限制&lt;/strong&gt;。默认是没有限制的（通常是注释掉的）。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;maxmemory&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mb&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;配置 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;512mb&lt;/code&gt; 的作用：&lt;/strong&gt; 限制 Redis 实例可使用的内存总量为512兆字节。当内存使用量达到这个限制时，Redis 会根据配置的&lt;strong&gt;内存淘汰策略&lt;/strong&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;maxmemory-policy&lt;/code&gt;) 移除数据，以确保不超过限制。&lt;/p&gt;

&lt;p&gt;8.&lt;strong&gt;设置日志文件的路径和名称&lt;/strong&gt;。默认是空字符串 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;&quot;&lt;/code&gt;，表示不记录日志到文件（日志可能只输出到标准输出/终端）。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;logfile&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;redis.log&quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;7redis知识点罗列不全&quot;&gt;7.redis知识点罗列(不全)&lt;/h1&gt;

&lt;h2 id=&quot;redis缓存穿透&quot;&gt;redis缓存穿透&lt;/h2&gt;

&lt;p&gt;缓存穿透指的是&lt;strong&gt;查询一个根本不存在的数据&lt;/strong&gt;，导致请求直接穿过缓存（Redis），到达持久层存储（通常是数据库，比如mysql）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251111174658486.png&quot; alt=&quot;image-20251111174658486&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当这种请求量很大时，每次查询都会落到数据库上，就像缓存“失效”了一样，给数据库带来巨大的压力，甚至可能导致数据库宕机。&lt;/p&gt;

&lt;p&gt;解决缓存穿透主要有两种主流且高效的方法：&lt;strong&gt;缓存空值/短期默认值&lt;/strong&gt; 和 &lt;strong&gt;布隆过滤器 (Bloom Filter)&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;（1）缓存空值/短期默认值：当查询请求发现 Key 在缓存中和数据库中都不存在时，我们仍然将这个 &lt;strong&gt;空结果&lt;/strong&gt;（例如：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;null&lt;/code&gt; 或一个特定的默认值如 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-1&lt;/code&gt;）写入 Redis 缓存。并且这个写入的空值设置一个&lt;strong&gt;较短的过期时间&lt;/strong&gt;（例如 60 秒）。后续对该 Key 的查询会命中 Redis 中的空值，直接返回，避免了对数据库的再次查询。&lt;/p&gt;

&lt;p&gt;这么做缺点是：浪费了 Redis 内存空间来存储这些空 Key，并且需要设置合理的过期时间（防止数据在短期内被写入数据库后，仍然被缓存的空值阻塞）。&lt;/p&gt;

&lt;p&gt;（2）布隆过滤器 (Bloom Filter)/布谷鸟过滤器（加强版-布隆过滤器）：布隆过滤器是一个&lt;strong&gt;概率型&lt;/strong&gt;数据结构。它可以在应用服务器和 Redis/数据库之间建立一个快速的“黑名单”或“白名单”。它能高效地判断一个 Key &lt;strong&gt;一定不存在&lt;/strong&gt;，但不能保证 Key &lt;strong&gt;一定存在&lt;/strong&gt;（存在极低的误判率，即“误报”）。&lt;/p&gt;

&lt;p&gt;具体做法：将数据库中&lt;strong&gt;所有实际存在的 Key&lt;/strong&gt; 的哈希值预先加载到布隆过滤器中。用户发起查询请求时，&lt;strong&gt;先通过布隆过滤器进行检查&lt;/strong&gt;。如果布隆过滤器判断 Key &lt;strong&gt;不存在&lt;/strong&gt;（即“黑名单”），则直接拒绝该请求，甚至不进行 Redis 查询。如果布隆过滤器判断 Key &lt;strong&gt;可能存在&lt;/strong&gt;，请求才继续查 Redis 和数据库。&lt;/p&gt;

&lt;p&gt;优点：占用的内存空间极小，效率极高，可以完全拦截对数据库的无效请求，是防御恶意穿透的利器。&lt;/p&gt;

&lt;p&gt;缺点：存在误判率；当数据库数据发生变化时，布隆过滤器需要同步更新。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;对于一般的业务场景，&lt;strong&gt;缓存空值&lt;/strong&gt;已经足够有效。对于有高并发或恶意攻击风险的核心业务，则推荐使用 &lt;strong&gt;布隆过滤器&lt;/strong&gt; 进行更全面的保护。&lt;/p&gt;

&lt;h2 id=&quot;redis缓存击穿-cache-breakdown&quot;&gt;redis缓存击穿 (Cache Breakdown)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;缓存击穿&lt;/strong&gt;指的是 Redis 中某个 &lt;strong&gt;热点 Key&lt;/strong&gt; 突然 &lt;strong&gt;过期&lt;/strong&gt;（或被删除）的瞬间，大量针对该 Key 的并发请求，在 Redis 中查询未命中，&lt;strong&gt;瞬间全部涌向数据库&lt;/strong&gt;，对数据库造成巨大的压力。&lt;/p&gt;

&lt;p&gt;“热点 Key”是指那些访问频率极高、并发量巨大的 Key。例如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;电商平台秒杀商品的库存信息。&lt;/li&gt;
  &lt;li&gt;某个新闻网站头条文章的访问计数。&lt;/li&gt;
  &lt;li&gt;高流量明星或主播的个人主页数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;第一个成功查询数据库并完成计算的请求，会将新数据写回 Redis，后续请求恢复正常。但在回写完成之前，数据库已经承受了短时的高峰压力。&lt;/p&gt;

&lt;p&gt;解决缓存击穿的核心思想是：&lt;strong&gt;阻止大量请求同时去查询数据库，或者延长热点 Key 的生命周期。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;（1）互斥锁（Mutex Lock / 分布式锁）—最常用、最有效&lt;/p&gt;

&lt;p&gt;只允许&lt;strong&gt;第一个&lt;/strong&gt;请求去查询数据库和回写缓存，其他请求必须等待。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;流程&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;请求 A 发现 Redis 未命中。&lt;/li&gt;
  &lt;li&gt;请求 A 立即尝试获取一个&lt;strong&gt;针对该 Key 的分布式锁&lt;/strong&gt;（例如，使用上文提到的 Redis Lua 脚本实现的锁）。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;请求 A&lt;/strong&gt; 成功获取锁，然后去查询数据库、回写缓存，最后释放锁。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;请求 B, C, D…&lt;/strong&gt; 尝试获取锁，但失败了。它们要么在循环中等待锁（Spinning），要么等待一段时间后重试，或者直接返回默认值。&lt;/li&gt;
  &lt;li&gt;当请求 A 释放锁后，等待中的请求 B 抢到锁，它发现缓存已经被 A 更新了，于是直接从 Redis 中取出数据返回，然后释放锁。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;：保证了数据库在同一时刻只会被一个请求访问，极大地保护了数据库。&lt;/p&gt;

&lt;p&gt;（2）“永不过期”策略（逻辑过期）&lt;/p&gt;

&lt;p&gt;让热点 Key 在 Redis 中&lt;strong&gt;永远不设置物理过期时间&lt;/strong&gt;（即 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TTL&lt;/code&gt; 永不过期），但在 Key 的 Value 中&lt;strong&gt;逻辑上&lt;/strong&gt;存储一个过期时间字段。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;流程&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;系统访问 Key 时，先从 Redis 中取出 Value。&lt;/li&gt;
  &lt;li&gt;检查 Value 中存储的&lt;strong&gt;逻辑过期时间&lt;/strong&gt;是否已经到达。&lt;/li&gt;
  &lt;li&gt;如果逻辑时间&lt;strong&gt;未过期&lt;/strong&gt;，则直接返回数据。&lt;/li&gt;
  &lt;li&gt;如果逻辑时间&lt;strong&gt;已过期&lt;/strong&gt;，则启动一个&lt;strong&gt;后台线程&lt;/strong&gt;去异步地执行数据库查询和缓存重建工作。&lt;strong&gt;同时，主线程仍向用户返回旧数据&lt;/strong&gt;（可以接受短暂的旧数据），避免阻塞用户请求。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;：用户永远不会感知到 Key 过期导致的延迟；数据库重建操作被放在后台异步执行，不影响前端高并发的实时响应。&lt;/p&gt;

&lt;p&gt;（3）设置合理的预热和过期时间&lt;/p&gt;

&lt;p&gt;对于已知的高频 Key，通过系统预热和统一设置过期时间，&lt;strong&gt;错开&lt;/strong&gt;它们的过期时间点，避免它们在同一时间大量过期。&lt;/p&gt;

&lt;h2 id=&quot;redis缓存雪崩cache-avalanche&quot;&gt;redis缓存雪崩（Cache Avalanche）&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;缓存雪崩&lt;/strong&gt;指的是在&lt;strong&gt;短时间内&lt;/strong&gt;，Redis 缓存中&lt;strong&gt;大量 Key 集中失效&lt;/strong&gt;（过期或被清除），导致这些 Key 的所有并发请求都&lt;strong&gt;瞬间穿透&lt;/strong&gt;到数据库（持久层）。&lt;/p&gt;

&lt;p&gt;这就像雪山顶部的积雪集中崩塌一样，巨大的洪峰流量在极短的时间内冲击数据库，可能导致数据库压力过大而崩溃。&lt;/p&gt;

&lt;p&gt;缓存雪崩通常由以下两种情况引发：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;大规模 Key 集中过期&lt;/strong&gt;：系统在短时间内将大量 Key 设置了&lt;strong&gt;相同的过期时间&lt;/strong&gt;。当到达这个时间点时，所有这些 Key 集体失效。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Redis 服务宕机&lt;/strong&gt;：Redis 集群发生故障或宕机，导致整个缓存服务不可用。所有请求都无法命中缓存，直接流向数据库。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;缓存雪崩的流程&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;集中过期&lt;/strong&gt;：大量非热点 Key 或大量 Key 同时过期。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;全部穿透&lt;/strong&gt;：用户请求访问这些失效的 Key，导致 Redis 未命中。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;流量洪峰&lt;/strong&gt;：所有请求几乎同时去查询数据库，形成流量洪峰。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;数据库崩溃&lt;/strong&gt;：数据库在高并发查询下，连接池耗尽，最终崩溃。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;系统瘫痪&lt;/strong&gt;：数据库崩溃后，应用服务无法正常工作，导致整个系统瘫痪。&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;解决缓存雪崩的关键在于&lt;strong&gt;分散失效时间&lt;/strong&gt;和提高&lt;strong&gt;缓存系统的可用性&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;（1）分散 Key 的过期时间（避免集中失效）&lt;/p&gt;

&lt;p&gt;在设置 Key 的过期时间时，不要使用固定的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TTL&lt;/code&gt;（Time To Live）。可以给基础过期时间上&lt;strong&gt;增加一个随机值&lt;/strong&gt;。&lt;/p&gt;

\[\text{Expire\_Time} = \text{Base\_Time} + \text{Random}(\text{0}, \text{N})\]

&lt;p&gt;（2）提高缓存系统的可用性（防止缓存宕机）&lt;/p&gt;

&lt;p&gt;使用 Redis Sentinel（哨兵）或 Redis Cluster（集群）来部署服务，确保即使部分节点故障，整个缓存系统依然可以提供服务，避免单点故障。&lt;/p&gt;

&lt;p&gt;（3）增加多级缓存或使用本地缓存（减轻Redis压力）&lt;/p&gt;

&lt;p&gt;在应用服务器内部引入如 Guava Cache 等本地缓存，存储一些访问极高的数据。当 Redis 宕机时，请求可以先走本地缓存，起到一层缓冲作用。&lt;/p&gt;

&lt;p&gt;（4）熔断降级与限流（保护数据库）&lt;/p&gt;

&lt;p&gt;这是在雪崩发生时，对数据库的最终保护措施。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;限流&lt;/strong&gt;：当检测到 Redis 不可用或大量 Key 失效时，应用层可以启动&lt;strong&gt;限流&lt;/strong&gt;机制，限制每秒钟允许访问数据库的请求数量。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;熔断降级&lt;/strong&gt;：对于非核心业务（如评论、推荐等），当数据库压力过大时，可以对这些请求进行&lt;strong&gt;熔断&lt;/strong&gt;，直接返回一个默认值、友好提示或错误信息，阻止它们访问数据库。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;数据预热&lt;/strong&gt;：提前将热门数据加载到缓存中，并监控其 TTL，在 Key 即将过期前，通过后台任务&lt;strong&gt;提前更新&lt;/strong&gt;缓存。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;缓存雪崩是一个系统级的风险，需要通过&lt;strong&gt;分散过期时间&lt;/strong&gt;（预防）和&lt;strong&gt;部署高可用集群&lt;/strong&gt;（增强）以及&lt;strong&gt;熔断限流&lt;/strong&gt;（容灾）三方面结合来解决。&lt;/p&gt;

&lt;h2 id=&quot;数据不一致&quot;&gt;数据不一致&lt;/h2&gt;

&lt;h2 id=&quot;查询redis阻塞&quot;&gt;查询redis阻塞&lt;/h2&gt;

&lt;h2 id=&quot;内存爆满&quot;&gt;内存爆满&lt;/h2&gt;

&lt;h2 id=&quot;多级缓存&quot;&gt;多级缓存&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;服务器本地缓存&lt;/li&gt;
  &lt;li&gt;redis多级缓存&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;缓存预热&quot;&gt;缓存预热&lt;/h2&gt;

&lt;p&gt;比如大促期间，提前把热门商品数据加载到redis，避免活动开始时，大量请求打到数据库&lt;/p&gt;

&lt;h2 id=&quot;防止数据丢失&quot;&gt;防止数据丢失&lt;/h2&gt;

&lt;p&gt;尽管 Redis 是内存存储，但它提供了将数据持久化到磁盘的机制，以防止服务器宕机时数据丢失：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;RDB (Redis Database)：&lt;/strong&gt; 定期将内存中的数据&lt;strong&gt;快照&lt;/strong&gt;（Snapshot）写入磁盘。恢复快，但是可能丢失最新数据。RDB 是通过生成某一时刻的数据快照来实现持久化的，可以在特定时间间隔内保存数据的快照。适合灾难恢复和备份，能生成紧凑的二进制文件，但可能会在崩溃时丢失最后一次快照之后的数据。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;AOF (Append Only File)：&lt;/strong&gt; （&lt;strong&gt;每个写操作追加到日志文件中实现持久化&lt;/strong&gt;）记录所有对 Redis 数据的&lt;strong&gt;修改操作命令&lt;/strong&gt;（写操作记录），以日志形式追加到文件中。数据更安全，恢复较慢。数据恢复更为精确，但文件体积较大，重写时可能会消耗更多资源。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Redis 4.0 新增了 RDB 和 AOF 的混合持久化机制。&lt;/p&gt;

&lt;h2 id=&quot;redis服务器挂了怎么办&quot;&gt;redis服务器挂了怎么办&lt;/h2&gt;

&lt;h3 id=&quot;主从集群&quot;&gt;主从集群&lt;/h3&gt;

&lt;p&gt;主节点挂了，从节点扛住。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251111204813287.png&quot; alt=&quot;image-20251111204813287&quot; style=&quot;zoom:50%;&quot; /&gt;
如果主节点挂了，从节点升级策略：哨兵机制。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Redis Sentinel&lt;/strong&gt; 是一个&lt;strong&gt;分布式系统&lt;/strong&gt;，它用于对 Redis 主从结构中的各个节点进行&lt;strong&gt;监控、通知、自动故障转移（Failover）&lt;/strong&gt;等功能。它的核心目标就是解决 Redis 主节点的单点故障问题。&lt;/p&gt;

&lt;p&gt;一个 Redis 哨兵系统通常由一组独立的 &lt;strong&gt;Sentinel 进程&lt;/strong&gt;组成。&lt;strong&gt;Sentinel 进程&lt;/strong&gt;运行在独立的服务器上，彼此之间互相通信（构成一个哨兵集群），并持续监控所有的 Redis 主节点和从节点。&lt;/p&gt;

&lt;p&gt;哨兵机制的工作流程可以分为以下几个关键阶段：&lt;/p&gt;

&lt;h4 id=&quot;阶段一监控-monitoring&quot;&gt;阶段一：监控 (Monitoring)&lt;/h4&gt;

&lt;p&gt;所有哨兵进程会持续不断地检查主节点和从节点是否正常运行。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;发送心跳&lt;/strong&gt;：每个 Sentinel 进程会每秒向所有 Redis 实例发送一个 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PING&lt;/code&gt; 命令。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;阶段二主观下线-subjectively-down-sdown&quot;&gt;阶段二：主观下线 (Subjectively Down, SDown)&lt;/h4&gt;

&lt;p&gt;当一个 Sentinel 进程发现某个主节点在设定的时间（称为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;down-after-milliseconds&lt;/code&gt;）内没有响应其 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PING&lt;/code&gt; 命令，该 Sentinel 就会认为这个主节点&lt;strong&gt;主观下线&lt;/strong&gt;（SDown）。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：SDown 是单个 Sentinel 节点的判断，具有主观性。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;阶段三客观下线-objectively-down-odown&quot;&gt;阶段三：客观下线 (Objectively Down, ODown)&lt;/h4&gt;

&lt;p&gt;为了避免单个 Sentinel 的误判，需要多个 Sentinel 达成一致意见。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;协商&lt;/strong&gt;：当一个 Sentinel 认为主节点 SDown 后，它会询问其他 Sentinel 进程是否也认为该主节点已经下线。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;法定人数 (Quorum)&lt;/strong&gt;/&lt;strong&gt;分布式投票&lt;/strong&gt;（Quorum 机制）：如果达到&lt;strong&gt;足够数量&lt;/strong&gt;（即配置的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quorum&lt;/code&gt; 值）的 Sentinel 进程都同意该主节点已下线，那么这个主节点的状态就会被标记为&lt;strong&gt;客观下线&lt;/strong&gt;（ODown）。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：ODown 标志着多数 Sentinel 已经确认主节点故障，需要启动故障转移流程。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;阶段四故障转移-failover---从节点升级策略&quot;&gt;阶段四：故障转移 (Failover) - 从节点升级策略&lt;/h4&gt;

&lt;p&gt;一旦主节点被确认为 ODown，哨兵集群就会开始执行自动故障转移，即选择一个健康的从节点升级为新的主节点。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;选举 Leader&lt;/strong&gt;：在启动故障转移前，哨兵集群会通过 Raft 协议的 Leader 选举过程，在所有的 Sentinel 进程中选举出一个 &lt;strong&gt;Sentinel Leader&lt;/strong&gt;，由它来主导并执行故障转移操作，以保证操作的唯一性。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;选择最佳从节点 (Promotion)&lt;/strong&gt;：Sentinel Leader 会从所有健康的从节点中，根据以下规则&lt;strong&gt;择优选择&lt;/strong&gt;一个从节点进行升级：
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;排除不合格节点&lt;/strong&gt;：过滤掉处于断线或下线状态的从节点。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;选择优先级高者&lt;/strong&gt;：根据配置文件中 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;slave-priority&lt;/code&gt;（或 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replica-priority&lt;/code&gt;）最高的从节点。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;选择复制偏移量最大者&lt;/strong&gt;：如果优先级相同，则选择&lt;strong&gt;复制偏移量（Replication Offset）&lt;/strong&gt;最大的从节点。复制偏移量越大，代表该从节点与原主节点的数据同步得越完整、越少丢失。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;选择运行 ID 最小者&lt;/strong&gt;：如果偏移量也相同，则选择运行 ID 最小的从节点。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;执行升级&lt;/strong&gt;：
    &lt;ul&gt;
      &lt;li&gt;Sentinel Leader 向被选中的从节点发送 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SLAVEOF NO ONE&lt;/code&gt; 命令，使其&lt;strong&gt;脱离从属关系&lt;/strong&gt;，升级为&lt;strong&gt;新的主节点&lt;/strong&gt;。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;配置其他从节点&lt;/strong&gt;：
    &lt;ul&gt;
      &lt;li&gt;Sentinel Leader 向剩余的从节点发送 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SLAVEOF &amp;lt;新的主节点IP&amp;gt; &amp;lt;端口&amp;gt;&lt;/code&gt; 命令，让它们&lt;strong&gt;复制新的主节点&lt;/strong&gt;。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;处理原主节点&lt;/strong&gt;：
    &lt;ul&gt;
      &lt;li&gt;当原主节点（已下线）重新上线后，Sentinel 也会向它发送 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SLAVEOF &amp;lt;新的主节点IP&amp;gt; &amp;lt;端口&amp;gt;&lt;/code&gt; 命令，使其降级为新主节点的&lt;strong&gt;从节点&lt;/strong&gt;。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;redis淘汰策略过期算法&quot;&gt;(redis淘汰策略/过期算法)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;maxmemory：Redis 配置文件（&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;redis.conf&lt;/code&gt;）中的一个关键参数，用于设置 Redis 实例能够使用的&lt;strong&gt;最大内存容量&lt;/strong&gt;。一旦 Redis 使用的内存量达到 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;maxmemory&lt;/code&gt; 设定的限制，并且有新的写入操作（如 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SET&lt;/code&gt;、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INCR&lt;/code&gt; 等）发生时，Redis 就会触发相应的&lt;strong&gt;数据淘汰策略&lt;/strong&gt;。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;maxmemory&lt;/code&gt; 限制的是&lt;strong&gt;数据存储&lt;/strong&gt;占用的内存，并不包括 RDB/AOF 持久化所需的内存、客户端连接缓冲区等。&lt;/li&gt;
  &lt;li&gt;No eviction:不淘汰任何 Key。当内存达到限制，且有新的写入操作时，&lt;strong&gt;直接返回错误&lt;/strong&gt;（如 OOM - Out of Memory 错误），拒绝写入。适用场景：数据库或关键配置存储等，不允许丢失任何数据的场景。&lt;/li&gt;
  &lt;li&gt;volatile-lru&lt;/li&gt;
  &lt;li&gt;volatile-ttl&lt;/li&gt;
  &lt;li&gt;volatile-random&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这些策略&lt;strong&gt;只考虑&lt;/strong&gt;删除那些&lt;strong&gt;设置了过期时间&lt;/strong&gt;（即设置了 TTL）的 Key。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;策略名称&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;淘汰描述&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;适用场景&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;volatile-lru&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;（Least Recently Used）&lt;/strong&gt;：淘汰&lt;strong&gt;设置了过期时间&lt;/strong&gt;的 Key 中，最近最少使用的 Key。&lt;/td&gt;
      &lt;td&gt;当你需要保留那些“永不过期”的 Key（如配置信息、Session ID），而只对缓存数据进行淘汰时使用。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;volatile-ttl&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;（Time To Live）&lt;/strong&gt;：淘汰&lt;strong&gt;设置了过期时间&lt;/strong&gt;的 Key 中，剩余&lt;strong&gt;生存时间（TTL）最短&lt;/strong&gt;的 Key。&lt;/td&gt;
      &lt;td&gt;倾向于让即将到期的 Key 先被淘汰。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;volatile-random&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;（Random）&lt;/strong&gt;：随机地淘汰&lt;strong&gt;设置了过期时间&lt;/strong&gt;的 Key 中的一部分 Key。&lt;/td&gt;
      &lt;td&gt;与 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;allkeys-random&lt;/code&gt; 类似，但仅针对设置了 TTL 的键。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;allkeys-lru&lt;/li&gt;
  &lt;li&gt;allkeys-random&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这些策略会考虑删除 &lt;strong&gt;Redis 实例中的所有 Key&lt;/strong&gt;。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;策略名称&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;淘汰描述&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;适用场景&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;allkeys-lru&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;（Least Recently Used）&lt;/strong&gt;：淘汰&lt;strong&gt;所有键&lt;/strong&gt;中，最近最少使用（最久没有被访问）的 Key。&lt;/td&gt;
      &lt;td&gt;默认推荐的通用策略，适用于将 Redis 作为纯缓存使用，且所有 Key 的重要性大致相等。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;allkeys-random&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;（Random）&lt;/strong&gt;：随机地淘汰&lt;strong&gt;所有 Key&lt;/strong&gt; 中的一部分 Key。&lt;/td&gt;
      &lt;td&gt;内存占用均匀，但对 Key 的访问模式没有明显倾向时使用。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;LRU 算法：传统的 LRU 算法需要维护一个有序链表，每次访问 Key 时都需要移动链表节点。这能实现精确淘汰最久未使用的 Key。&lt;/li&gt;
  &lt;li&gt;近似 LRU 算法：Redis 并没有使用精确的 LRU，而是采用了&lt;strong&gt;近似 LRU 算法&lt;/strong&gt;。Redis 维护一个随机采样的 Key 集合（例如，默认采样 5 个 Key）。每次需要淘汰 Key 时，它随机从数据库中取出这个小集合的 Key。然后，它从这个小样本中找出最近最少使用的那个 Key 并将其淘汰。这种近似算法在性能和淘汰准确性之间取得了极佳的平衡。通过调整采样数量，可以在性能和准确性之间进行权衡。在实际应用中，它的效果与精确 LRU 非常接近，但效率高得多。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当 Redis 内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交换(swap)。交换会让 Redis 的性能急剧下降，对于访问量比较频繁的 Redis 来说，这样龟速的存取效率基本上等于不可用。&lt;/p&gt;

&lt;h2 id=&quot;数据量太大单台redis存不下&quot;&gt;数据量太大，单台redis存不下&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Redis Cluster (集群)&lt;/strong&gt;：将数据分散存储在多台 Redis 实例上，每台实例只存储总数据量的一部分。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;客户端分片&lt;/strong&gt;：在客户端通过特定的【哈希算法】将数据分散到不同的 Redis 实例中。&lt;/p&gt;

&lt;h2 id=&quot;其他注意点&quot;&gt;其他注意点&lt;/h2&gt;

&lt;p&gt;（1）合理设计缓存键名&lt;/p&gt;

&lt;p&gt;使用有意义的前缀,比如
user:1001:profile、
article:2023:hot,这样便于管理和避免冲突。&lt;/p&gt;

&lt;p&gt;（2）设置合适的过期时间&lt;/p&gt;

&lt;p&gt;根据数据特点设置,热门数据可以长一些(1小时)&lt;/p&gt;

&lt;p&gt;普通数据短一些(10分钟),还要加上随机值，避免同时过期。&lt;/p&gt;

&lt;p&gt;（3）选择正确的数据结构&lt;/p&gt;

&lt;p&gt;不要什么都用 String, 存对象用 Hash, 存列表用 List, 存排行榜用 SortedSet。&lt;/p&gt;

&lt;h1 id=&quot;附录redis源码方式安装的readme文件&quot;&gt;附录：redis源码方式安装的readme文件&lt;/h1&gt;

&lt;div class=&quot;language-markdown highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418
419
420
421
422
423
424
425
426
427
428
429
430
431
432
433
434
435
436
437
438
439
440
441
442
443
444
445
446
447
448
449
450
451
452
453
454
455
456
457
458
459
460
461
462
463
464
465
466
467
468
469
470
471
472
473
474
475
476
477
478
479
480
481
482
483
484
485
486
487
488
489
490
491
492
493
494
495
496
497
498
499
500
501
502
503
504
505
506
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;This README is just a fast &lt;span class=&quot;ge&quot;&gt;*quick start*&lt;/span&gt; document. You can find more detailed documentation at &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;redis.io&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;sx&quot;&gt;https://redis.io&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;.

&lt;span class=&quot;gh&quot;&gt;What is Redis?
--------------
&lt;/span&gt;
Redis is often referred to as a &lt;span class=&quot;ge&quot;&gt;*data structures*&lt;/span&gt; server. What this means is that Redis provides access to mutable data structures via a set of commands, which are sent using a &lt;span class=&quot;ge&quot;&gt;*server-client*&lt;/span&gt; model with TCP sockets and a simple protocol. So different processes can query and modify the same data structures in a shared way.

Data structures implemented into Redis have a few special properties:
&lt;span class=&quot;p&quot;&gt;
*&lt;/span&gt; Redis cares to store them on disk, even if they are always served and modified into the server memory. This means that Redis is fast, but that it is also non-volatile.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; The implementation of data structures emphasizes memory efficiency, so data structures inside Redis will likely use less memory compared to the same data structure modelled using a high-level programming language.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; Redis offers a number of features that are natural to find in a database, like replication, tunable levels of durability, clustering, and high availability.

Another good example is to think of Redis as a more complex version of memcached, where the operations are not just SETs and GETs, but operations that work with complex data types like Lists, Sets, ordered data structures, and so forth.

If you want to know more, this is a list of selected starting points:
&lt;span class=&quot;p&quot;&gt;
*&lt;/span&gt; Introduction to Redis data types. https://redis.io/topics/data-types-intro
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; Try Redis directly inside your browser. https://try.redis.io
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; The full list of Redis commands. https://redis.io/commands
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; There is much more inside the official Redis documentation. https://redis.io/documentation

&lt;span class=&quot;gh&quot;&gt;Building Redis
--------------
&lt;/span&gt;
Redis can be compiled and used on Linux, OSX, OpenBSD, NetBSD, FreeBSD.
We support big endian and little endian architectures, and both 32 bit
and 64 bit systems.

It may compile on Solaris derived systems (for instance SmartOS) but our
support for this platform is &lt;span class=&quot;ge&quot;&gt;*best effort*&lt;/span&gt; and Redis is not guaranteed to
work as well as in Linux, OSX, and &lt;span class=&quot;se&quot;&gt;\*&lt;/span&gt;BSD.

It is as simple as:&lt;span class=&quot;sb&quot;&gt;

    % make

&lt;/span&gt;To build with TLS support, you&apos;ll need OpenSSL development libraries (e.g.
libssl-dev on Debian/Ubuntu) and run:&lt;span class=&quot;sb&quot;&gt;

    % make BUILD_TLS=yes

&lt;/span&gt;To build with systemd support, you&apos;ll need systemd development libraries (such
as libsystemd-dev on Debian/Ubuntu or systemd-devel on CentOS) and run:&lt;span class=&quot;sb&quot;&gt;

    % make USE_SYSTEMD=yes

&lt;/span&gt;To append a suffix to Redis program names, use:&lt;span class=&quot;sb&quot;&gt;

    % make PROG_SUFFIX=&quot;-alt&quot;

&lt;/span&gt;You can build a 32 bit Redis binary using:&lt;span class=&quot;sb&quot;&gt;

    % make 32bit

&lt;/span&gt;After building Redis, it is a good idea to test it using:&lt;span class=&quot;sb&quot;&gt;

    % make test

&lt;/span&gt;If TLS is built, running the tests with TLS enabled (you will need &lt;span class=&quot;sb&quot;&gt;`tcl-tls`&lt;/span&gt;
installed):&lt;span class=&quot;sb&quot;&gt;

    % ./utils/gen-test-certs.sh
    % ./runtest --tls


&lt;/span&gt;&lt;span class=&quot;gh&quot;&gt;Fixing build problems with dependencies or cached build options
---------
&lt;/span&gt;
Redis has some dependencies which are included in the &lt;span class=&quot;sb&quot;&gt;`deps`&lt;/span&gt; directory.
&lt;span class=&quot;sb&quot;&gt;`make`&lt;/span&gt; does not automatically rebuild dependencies even if something in
the source code of dependencies changes.

When you update the source code with &lt;span class=&quot;sb&quot;&gt;`git pull`&lt;/span&gt; or when code inside the
dependencies tree is modified in any other way, make sure to use the following
command in order to really clean everything and rebuild from scratch:&lt;span class=&quot;sb&quot;&gt;

    % make distclean

&lt;/span&gt;This will clean: jemalloc, lua, hiredis, linenoise and other dependencies.

Also if you force certain build options like 32bit target, no C compiler
optimizations (for debugging purposes), and other similar build time options,
those options are cached indefinitely until you issue a &lt;span class=&quot;sb&quot;&gt;`make distclean`&lt;/span&gt;
command.

&lt;span class=&quot;gh&quot;&gt;Fixing problems building 32 bit binaries
---------
&lt;/span&gt;
If after building Redis with a 32 bit target you need to rebuild it
with a 64 bit target, or the other way around, you need to perform a
&lt;span class=&quot;sb&quot;&gt;`make distclean`&lt;/span&gt; in the root directory of the Redis distribution.

In case of build errors when trying to build a 32 bit binary of Redis, try
the following steps:
&lt;span class=&quot;p&quot;&gt;
*&lt;/span&gt; Install the package libc6-dev-i386 (also try g++-multilib).
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; Try using the following command line instead of &lt;span class=&quot;sb&quot;&gt;`make 32bit`&lt;/span&gt;:
  &lt;span class=&quot;sb&quot;&gt;`make CFLAGS=&quot;-m32 -march=native&quot; LDFLAGS=&quot;-m32&quot;`&lt;/span&gt;

&lt;span class=&quot;gh&quot;&gt;Allocator
---------
&lt;/span&gt;
Selecting a non-default memory allocator when building Redis is done by setting
the &lt;span class=&quot;sb&quot;&gt;`MALLOC`&lt;/span&gt; environment variable. Redis is compiled and linked against libc
malloc by default, with the exception of jemalloc being the default on Linux
systems. This default was picked because jemalloc has proven to have fewer
fragmentation problems than libc malloc.

To force compiling against libc malloc, use:&lt;span class=&quot;sb&quot;&gt;

    % make MALLOC=libc

&lt;/span&gt;To compile against jemalloc on Mac OS X systems, use:&lt;span class=&quot;sb&quot;&gt;

    % make MALLOC=jemalloc

&lt;/span&gt;&lt;span class=&quot;gh&quot;&gt;Monotonic clock
---------------
&lt;/span&gt;
By default, Redis will build using the POSIX clock_gettime function as the
monotonic clock source.  On most modern systems, the internal processor clock
can be used to improve performance.  Cautions can be found here:
    http://oliveryang.net/2015/09/pitfalls-of-TSC-usage/

To build with support for the processor&apos;s internal instruction clock, use:&lt;span class=&quot;sb&quot;&gt;

    % make CFLAGS=&quot;-DUSE_PROCESSOR_CLOCK&quot;

&lt;/span&gt;&lt;span class=&quot;gh&quot;&gt;Verbose build
-------------
&lt;/span&gt;
Redis will build with a user-friendly colorized output by default.
If you want to see a more verbose output, use the following:&lt;span class=&quot;sb&quot;&gt;

    % make V=1

&lt;/span&gt;&lt;span class=&quot;gh&quot;&gt;Running Redis
-------------
&lt;/span&gt;
To run Redis with the default configuration, just type:&lt;span class=&quot;sb&quot;&gt;

    % cd src
    % ./redis-server

&lt;/span&gt;If you want to provide your redis.conf, you have to run it using an additional
parameter (the path of the configuration file):&lt;span class=&quot;sb&quot;&gt;

    % cd src
    % ./redis-server /path/to/redis.conf

&lt;/span&gt;It is possible to alter the Redis configuration by passing parameters directly
as options using the command line. Examples:&lt;span class=&quot;sb&quot;&gt;

    % ./redis-server --port 9999 --replicaof 127.0.0.1 6379
    % ./redis-server /etc/redis/6379.conf --loglevel debug

&lt;/span&gt;All the options in redis.conf are also supported as options using the command
line, with exactly the same name.

&lt;span class=&quot;gh&quot;&gt;Running Redis with TLS:
------------------
&lt;/span&gt;
Please consult the &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;TLS.md&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;sx&quot;&gt;TLS.md&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; file for more information on
how to use Redis with TLS.

&lt;span class=&quot;gh&quot;&gt;Playing with Redis
------------------
&lt;/span&gt;
You can use redis-cli to play with Redis. Start a redis-server instance,
then in another terminal try the following:&lt;span class=&quot;sb&quot;&gt;

    % cd src
    % ./redis-cli
    redis&amp;gt; ping
    PONG
    redis&amp;gt; set foo bar
    OK
    redis&amp;gt; get foo
    &quot;bar&quot;
    redis&amp;gt; incr mycounter
    (integer) 1
    redis&amp;gt; incr mycounter
    (integer) 2
    redis&amp;gt;

&lt;/span&gt;You can find the list of all the available commands at https://redis.io/commands.

&lt;span class=&quot;gh&quot;&gt;Installing Redis
-----------------
&lt;/span&gt;
In order to install Redis binaries into /usr/local/bin, just use:&lt;span class=&quot;sb&quot;&gt;

    % make install

&lt;/span&gt;You can use &lt;span class=&quot;sb&quot;&gt;`make PREFIX=/some/other/directory install`&lt;/span&gt; if you wish to use a
different destination.

&lt;span class=&quot;sb&quot;&gt;`make install`&lt;/span&gt; will just install binaries in your system, but will not configure
init scripts and configuration files in the appropriate place. This is not
needed if you just want to play a bit with Redis, but if you are installing
it the proper way for a production system, we have a script that does this
for Ubuntu and Debian systems:&lt;span class=&quot;sb&quot;&gt;

    % cd utils
    % ./install_server.sh

&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;_Note_&lt;/span&gt;: &lt;span class=&quot;sb&quot;&gt;`install_server.sh`&lt;/span&gt; will not work on Mac OSX; it is built for Linux only.

The script will ask you a few questions and will setup everything you need
to run Redis properly as a background daemon that will start again on
system reboots.

You&apos;ll be able to stop and start Redis using the script named
&lt;span class=&quot;sb&quot;&gt;`/etc/init.d/redis_&amp;lt;portnumber&amp;gt;`&lt;/span&gt;, for instance &lt;span class=&quot;sb&quot;&gt;`/etc/init.d/redis_6379`&lt;/span&gt;.

&lt;span class=&quot;gh&quot;&gt;Code contributions
-----------------
&lt;/span&gt;
Note: By contributing code to the Redis project in any form, including sending
a pull request via Github, a code fragment or patch via private email or
public discussion groups, you agree to release your code under the terms
of the BSD license that you can find in the &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;COPYING&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; file included in the Redis
source distribution.

Please see the &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CONTRIBUTING.md&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; file in this source distribution for more
information. For security bugs and vulnerabilities, please see &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SECURITY.md&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;.

&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;sx&quot;&gt;https://github.com/redis/redis/blob/unstable/COPYING&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;sx&quot;&gt;https://github.com/redis/redis/blob/unstable/CONTRIBUTING.md&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;sx&quot;&gt;https://github.com/redis/redis/blob/unstable/SECURITY.md&lt;/span&gt;

&lt;span class=&quot;gu&quot;&gt;Redis internals
===
&lt;/span&gt;
If you are reading this README you are likely in front of a Github page
or you just untarred the Redis distribution tar ball. In both the cases
you are basically one step away from the source code, so here we explain
the Redis source code layout, what is in each file as a general idea, the
most important functions and structures inside the Redis server and so forth.
We keep all the discussion at a high level without digging into the details
since this document would be huge otherwise and our code base changes
continuously, but a general idea should be a good starting point to
understand more. Moreover most of the code is heavily commented and easy
to follow.

&lt;span class=&quot;gh&quot;&gt;Source code layout
---
&lt;/span&gt;
The Redis root directory just contains this README, the Makefile which
calls the real Makefile inside the &lt;span class=&quot;sb&quot;&gt;`src`&lt;/span&gt; directory and an example
configuration for Redis and Sentinel. You can find a few shell
scripts that are used in order to execute the Redis, Redis Cluster and
Redis Sentinel unit tests, which are implemented inside the &lt;span class=&quot;sb&quot;&gt;`tests`&lt;/span&gt;
directory.

Inside the root are the following important directories:
&lt;span class=&quot;p&quot;&gt;
*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`src`&lt;/span&gt;: contains the Redis implementation, written in C.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`tests`&lt;/span&gt;: contains the unit tests, implemented in Tcl.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`deps`&lt;/span&gt;: contains libraries Redis uses. Everything needed to compile Redis is inside this directory; your system just needs to provide &lt;span class=&quot;sb&quot;&gt;`libc`&lt;/span&gt;, a POSIX compatible interface and a C compiler. Notably &lt;span class=&quot;sb&quot;&gt;`deps`&lt;/span&gt; contains a copy of &lt;span class=&quot;sb&quot;&gt;`jemalloc`&lt;/span&gt;, which is the default allocator of Redis under Linux. Note that under &lt;span class=&quot;sb&quot;&gt;`deps`&lt;/span&gt; there are also things which started with the Redis project, but for which the main repository is not &lt;span class=&quot;sb&quot;&gt;`redis/redis`&lt;/span&gt;.

There are a few more directories but they are not very important for our goals
here. We&apos;ll focus mostly on &lt;span class=&quot;sb&quot;&gt;`src`&lt;/span&gt;, where the Redis implementation is contained,
exploring what there is inside each file. The order in which files are
exposed is the logical one to follow in order to disclose different layers
of complexity incrementally.

Note: lately Redis was refactored quite a bit. Function names and file
names have been changed, so you may find that this documentation reflects the
&lt;span class=&quot;sb&quot;&gt;`unstable`&lt;/span&gt; branch more closely. For instance, in Redis 3.0 the &lt;span class=&quot;sb&quot;&gt;`server.c`&lt;/span&gt;
and &lt;span class=&quot;sb&quot;&gt;`server.h`&lt;/span&gt; files were named &lt;span class=&quot;sb&quot;&gt;`redis.c`&lt;/span&gt; and &lt;span class=&quot;sb&quot;&gt;`redis.h`&lt;/span&gt;. However the overall
structure is the same. Keep in mind that all the new developments and pull
requests should be performed against the &lt;span class=&quot;sb&quot;&gt;`unstable`&lt;/span&gt; branch.

&lt;span class=&quot;gh&quot;&gt;server.h
---
&lt;/span&gt;
The simplest way to understand how a program works is to understand the
data structures it uses. So we&apos;ll start from the main header file of
Redis, which is &lt;span class=&quot;sb&quot;&gt;`server.h`&lt;/span&gt;.

All the server configuration and in general all the shared state is
defined in a global structure called &lt;span class=&quot;sb&quot;&gt;`server`&lt;/span&gt;, of type &lt;span class=&quot;sb&quot;&gt;`struct redisServer`&lt;/span&gt;.
A few important fields in this structure are:
&lt;span class=&quot;p&quot;&gt;
*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`server.db`&lt;/span&gt; is an array of Redis databases, where data is stored.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`server.commands`&lt;/span&gt; is the command table.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`server.clients`&lt;/span&gt; is a linked list of clients connected to the server.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`server.master`&lt;/span&gt; is a special client, the master, if the instance is a replica.

There are tons of other fields. Most fields are commented directly inside
the structure definition.

Another important Redis data structure is the one defining a client.
In the past it was called &lt;span class=&quot;sb&quot;&gt;`redisClient`&lt;/span&gt;, now just &lt;span class=&quot;sb&quot;&gt;`client`&lt;/span&gt;. The structure
has many fields, here we&apos;ll just show the main ones:
&lt;span class=&quot;p&quot;&gt;```&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;c
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;client&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sds&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;querybuf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;argc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;robj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;redisDb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// ... many other fields ...&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;buf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PROTO_REPLY_CHUNK_BYTES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;```&lt;/span&gt;
The client structure defines a &lt;span class=&quot;ge&quot;&gt;*connected client*&lt;/span&gt;:
&lt;span class=&quot;p&quot;&gt;
*&lt;/span&gt; The &lt;span class=&quot;sb&quot;&gt;`fd`&lt;/span&gt; field is the client socket file descriptor.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`argc`&lt;/span&gt; and &lt;span class=&quot;sb&quot;&gt;`argv`&lt;/span&gt; are populated with the command the client is executing, so that functions implementing a given Redis command can read the arguments.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`querybuf`&lt;/span&gt; accumulates the requests from the client, which are parsed by the Redis server according to the Redis protocol and executed by calling the implementations of the commands the client is executing.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`reply`&lt;/span&gt; and &lt;span class=&quot;sb&quot;&gt;`buf`&lt;/span&gt; are dynamic and static buffers that accumulate the replies the server sends to the client. These buffers are incrementally written to the socket as soon as the file descriptor is writable.

As you can see in the client structure above, arguments in a command
are described as &lt;span class=&quot;sb&quot;&gt;`robj`&lt;/span&gt; structures. The following is the full &lt;span class=&quot;sb&quot;&gt;`robj`&lt;/span&gt;
structure, which defines a &lt;span class=&quot;ge&quot;&gt;*Redis object*&lt;/span&gt;:

&lt;span class=&quot;p&quot;&gt;```&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;c
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redisObject&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lru&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LRU_BITS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;cm&quot;&gt;/* LRU time (relative to global lru_clock) or
                            * LFU data (least significant 8 bits frequency
                            * and most significant 16 bits access time). */&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;refcount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;```&lt;/span&gt;

Basically this structure can represent all the basic Redis data types like
strings, lists, sets, sorted sets and so forth. The interesting thing is that
it has a &lt;span class=&quot;sb&quot;&gt;`type`&lt;/span&gt; field, so that it is possible to know what type a given
object has, and a &lt;span class=&quot;sb&quot;&gt;`refcount`&lt;/span&gt;, so that the same object can be referenced
in multiple places without allocating it multiple times. Finally the &lt;span class=&quot;sb&quot;&gt;`ptr`&lt;/span&gt;
field points to the actual representation of the object, which might vary
even for the same type, depending on the &lt;span class=&quot;sb&quot;&gt;`encoding`&lt;/span&gt; used.

Redis objects are used extensively in the Redis internals, however in order
to avoid the overhead of indirect accesses, recently in many places
we just use plain dynamic strings not wrapped inside a Redis object.

&lt;span class=&quot;gh&quot;&gt;server.c
---
&lt;/span&gt;
This is the entry point of the Redis server, where the &lt;span class=&quot;sb&quot;&gt;`main()`&lt;/span&gt; function
is defined. The following are the most important steps in order to startup
the Redis server.
&lt;span class=&quot;p&quot;&gt;
*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`initServerConfig()`&lt;/span&gt; sets up the default values of the &lt;span class=&quot;sb&quot;&gt;`server`&lt;/span&gt; structure.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`initServer()`&lt;/span&gt; allocates the data structures needed to operate, setup the listening socket, and so forth.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`aeMain()`&lt;/span&gt; starts the event loop which listens for new connections.

There are two special functions called periodically by the event loop:
&lt;span class=&quot;p&quot;&gt;
1.&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`serverCron()`&lt;/span&gt; is called periodically (according to &lt;span class=&quot;sb&quot;&gt;`server.hz`&lt;/span&gt; frequency), and performs tasks that must be performed from time to time, like checking for timed out clients.
&lt;span class=&quot;p&quot;&gt;2.&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`beforeSleep()`&lt;/span&gt; is called every time the event loop fired, Redis served a few requests, and is returning back into the event loop.

Inside server.c you can find code that handles other vital things of the Redis server:
&lt;span class=&quot;p&quot;&gt;
*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`call()`&lt;/span&gt; is used in order to call a given command in the context of a given client.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`activeExpireCycle()`&lt;/span&gt; handles eviction of keys with a time to live set via the &lt;span class=&quot;sb&quot;&gt;`EXPIRE`&lt;/span&gt; command.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`performEvictions()`&lt;/span&gt; is called when a new write command should be performed but Redis is out of memory according to the &lt;span class=&quot;sb&quot;&gt;`maxmemory`&lt;/span&gt; directive.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; The global variable &lt;span class=&quot;sb&quot;&gt;`redisCommandTable`&lt;/span&gt; defines all the Redis commands, specifying the name of the command, the function implementing the command, the number of arguments required, and other properties of each command.

&lt;span class=&quot;gh&quot;&gt;commands.c
---
&lt;/span&gt;This file is auto generated by utils/generate-command-code.py, the content is based on the JSON files in the src/commands folder.
These are meant to be the single source of truth about the Redis commands, and all the metadata about them.
These JSON files are not meant to be used by anyone directly, instead that metadata can be obtained via the &lt;span class=&quot;sb&quot;&gt;`COMMAND`&lt;/span&gt; command.

&lt;span class=&quot;gh&quot;&gt;networking.c
---
&lt;/span&gt;
This file defines all the I/O functions with clients, masters and replicas
(which in Redis are just special clients):
&lt;span class=&quot;p&quot;&gt;
*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`createClient()`&lt;/span&gt; allocates and initializes a new client.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; The &lt;span class=&quot;sb&quot;&gt;`addReply*()`&lt;/span&gt; family of functions are used by command implementations in order to append data to the client structure, that will be transmitted to the client as a reply for a given command executed.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`writeToClient()`&lt;/span&gt; transmits the data pending in the output buffers to the client and is called by the &lt;span class=&quot;ge&quot;&gt;*writable event handler*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`sendReplyToClient()`&lt;/span&gt;.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`readQueryFromClient()`&lt;/span&gt; is the &lt;span class=&quot;ge&quot;&gt;*readable event handler*&lt;/span&gt; and accumulates data read from the client into the query buffer.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`processInputBuffer()`&lt;/span&gt; is the entry point in order to parse the client query buffer according to the Redis protocol. Once commands are ready to be processed, it calls &lt;span class=&quot;sb&quot;&gt;`processCommand()`&lt;/span&gt; which is defined inside &lt;span class=&quot;sb&quot;&gt;`server.c`&lt;/span&gt; in order to actually execute the command.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`freeClient()`&lt;/span&gt; deallocates, disconnects and removes a client.

&lt;span class=&quot;gh&quot;&gt;aof.c and rdb.c
---
&lt;/span&gt;
As you can guess from the names, these files implement the RDB and AOF
persistence for Redis. Redis uses a persistence model based on the &lt;span class=&quot;sb&quot;&gt;`fork()`&lt;/span&gt;
system call in order to create a process with the same (shared) memory
content of the main Redis process. This secondary process dumps the content
of the memory on disk. This is used by &lt;span class=&quot;sb&quot;&gt;`rdb.c`&lt;/span&gt; to create the snapshots
on disk and by &lt;span class=&quot;sb&quot;&gt;`aof.c`&lt;/span&gt; in order to perform the AOF rewrite when the
append only file gets too big.

The implementation inside &lt;span class=&quot;sb&quot;&gt;`aof.c`&lt;/span&gt; has additional functions in order to
implement an API that allows commands to append new commands into the AOF
file as clients execute them.

The &lt;span class=&quot;sb&quot;&gt;`call()`&lt;/span&gt; function defined inside &lt;span class=&quot;sb&quot;&gt;`server.c`&lt;/span&gt; is responsible for calling
the functions that in turn will write the commands into the AOF.

&lt;span class=&quot;gh&quot;&gt;db.c
---
&lt;/span&gt;
Certain Redis commands operate on specific data types; others are general.
Examples of generic commands are &lt;span class=&quot;sb&quot;&gt;`DEL`&lt;/span&gt; and &lt;span class=&quot;sb&quot;&gt;`EXPIRE`&lt;/span&gt;. They operate on keys
and not on their values specifically. All those generic commands are
defined inside &lt;span class=&quot;sb&quot;&gt;`db.c`&lt;/span&gt;.

Moreover &lt;span class=&quot;sb&quot;&gt;`db.c`&lt;/span&gt; implements an API in order to perform certain operations
on the Redis dataset without directly accessing the internal data structures.

The most important functions inside &lt;span class=&quot;sb&quot;&gt;`db.c`&lt;/span&gt; which are used in many command
implementations are the following:
&lt;span class=&quot;p&quot;&gt;
*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`lookupKeyRead()`&lt;/span&gt; and &lt;span class=&quot;sb&quot;&gt;`lookupKeyWrite()`&lt;/span&gt; are used in order to get a pointer to the value associated to a given key, or &lt;span class=&quot;sb&quot;&gt;`NULL`&lt;/span&gt; if the key does not exist.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`dbAdd()`&lt;/span&gt; and its higher level counterpart &lt;span class=&quot;sb&quot;&gt;`setKey()`&lt;/span&gt; create a new key in a Redis database.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`dbDelete()`&lt;/span&gt; removes a key and its associated value.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`emptyDb()`&lt;/span&gt; removes an entire single database or all the databases defined.

The rest of the file implements the generic commands exposed to the client.

&lt;span class=&quot;gh&quot;&gt;object.c
---
&lt;/span&gt;
The &lt;span class=&quot;sb&quot;&gt;`robj`&lt;/span&gt; structure defining Redis objects was already described. Inside
&lt;span class=&quot;sb&quot;&gt;`object.c`&lt;/span&gt; there are all the functions that operate with Redis objects at
a basic level, like functions to allocate new objects, handle the reference
counting and so forth. Notable functions inside this file:
&lt;span class=&quot;p&quot;&gt;
*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`incrRefCount()`&lt;/span&gt; and &lt;span class=&quot;sb&quot;&gt;`decrRefCount()`&lt;/span&gt; are used in order to increment or decrement an object reference count. When it drops to 0 the object is finally freed.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`createObject()`&lt;/span&gt; allocates a new object. There are also specialized functions to allocate string objects having a specific content, like &lt;span class=&quot;sb&quot;&gt;`createStringObjectFromLongLong()`&lt;/span&gt; and similar functions.

This file also implements the &lt;span class=&quot;sb&quot;&gt;`OBJECT`&lt;/span&gt; command.

&lt;span class=&quot;gh&quot;&gt;replication.c
---
&lt;/span&gt;
This is one of the most complex files inside Redis, it is recommended to
approach it only after getting a bit familiar with the rest of the code base.
In this file there is the implementation of both the master and replica role
of Redis.

One of the most important functions inside this file is &lt;span class=&quot;sb&quot;&gt;`replicationFeedSlaves()`&lt;/span&gt; that writes commands to the clients representing replica instances connected
to our master, so that the replicas can get the writes performed by the clients:
this way their data set will remain synchronized with the one in the master.

This file also implements both the &lt;span class=&quot;sb&quot;&gt;`SYNC`&lt;/span&gt; and &lt;span class=&quot;sb&quot;&gt;`PSYNC`&lt;/span&gt; commands that are
used in order to perform the first synchronization between masters and
replicas, or to continue the replication after a disconnection.

&lt;span class=&quot;gh&quot;&gt;Script
---
&lt;/span&gt;
The script unit is composed of 3 units:
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`script.c`&lt;/span&gt; - integration of scripts with Redis (commands execution, set replication/resp, ...)
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`script_lua.c`&lt;/span&gt; - responsible to execute Lua code, uses script.c to interact with Redis from within the Lua code.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`function_lua.c`&lt;/span&gt; - contains the Lua engine implementation, uses script_lua.c to execute the Lua code.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`functions.c`&lt;/span&gt; - contains Redis Functions implementation (FUNCTION command), uses functions_lua.c if the function it wants to invoke needs the Lua engine.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`eval.c`&lt;/span&gt; - contains the &lt;span class=&quot;sb&quot;&gt;`eval`&lt;/span&gt; implementation using &lt;span class=&quot;sb&quot;&gt;`script_lua.c`&lt;/span&gt; to invoke the Lua code.&lt;span class=&quot;sb&quot;&gt;


&lt;/span&gt;&lt;span class=&quot;gh&quot;&gt;Other C files
---
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;
*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`t_hash.c`&lt;/span&gt;, &lt;span class=&quot;sb&quot;&gt;`t_list.c`&lt;/span&gt;, &lt;span class=&quot;sb&quot;&gt;`t_set.c`&lt;/span&gt;, &lt;span class=&quot;sb&quot;&gt;`t_string.c`&lt;/span&gt;, &lt;span class=&quot;sb&quot;&gt;`t_zset.c`&lt;/span&gt; and &lt;span class=&quot;sb&quot;&gt;`t_stream.c`&lt;/span&gt; contains the implementation of the Redis data types. They implement both an API to access a given data type, and the client command implementations for these data types.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`ae.c`&lt;/span&gt; implements the Redis event loop, it&apos;s a self contained library which is simple to read and understand.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`sds.c`&lt;/span&gt; is the Redis string library, check https://github.com/antirez/sds for more information.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`anet.c`&lt;/span&gt; is a library to use POSIX networking in a simpler way compared to the raw interface exposed by the kernel.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`dict.c`&lt;/span&gt; is an implementation of a non-blocking hash table which rehashes incrementally.
&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`cluster.c`&lt;/span&gt; implements the Redis Cluster. Probably a good read only after being very familiar with the rest of the Redis code base. If you want to read &lt;span class=&quot;sb&quot;&gt;`cluster.c`&lt;/span&gt; make sure to read the &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Redis Cluster specification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;.

&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;sx&quot;&gt;https://redis.io/topics/cluster-spec&lt;/span&gt;

&lt;span class=&quot;gh&quot;&gt;Anatomy of a Redis command
---
&lt;/span&gt;
All the Redis commands are defined in the following way:

&lt;span class=&quot;p&quot;&gt;```&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;c
&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;foobarCommand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%s&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;cm&quot;&gt;/* Do something with the argument. */&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;addReply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;cm&quot;&gt;/* Reply something to the client. */&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;```&lt;/span&gt;

The command function is referenced by a JSON file, together with its metadata, see &lt;span class=&quot;sb&quot;&gt;`commands.c`&lt;/span&gt; described above for details.
The command flags are documented in the comment above the &lt;span class=&quot;sb&quot;&gt;`struct redisCommand`&lt;/span&gt; in &lt;span class=&quot;sb&quot;&gt;`server.h`&lt;/span&gt;.
For other details, please refer to the &lt;span class=&quot;sb&quot;&gt;`COMMAND`&lt;/span&gt; command. https://redis.io/commands/command/

After the command operates in some way, it returns a reply to the client,
usually using &lt;span class=&quot;sb&quot;&gt;`addReply()`&lt;/span&gt; or a similar function defined inside &lt;span class=&quot;sb&quot;&gt;`networking.c`&lt;/span&gt;.

There are tons of command implementations inside the Redis source code
that can serve as examples of actual commands implementations (e.g. pingCommand). Writing
a few toy commands can be a good exercise to get familiar with the code base.

There are also many other files not described here, but it is useless to
cover everything. We just want to help you with the first steps.
Eventually you&apos;ll find your way inside the Redis code base :-)

Enjoy!
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Wed, 12 Nov 2025 00:00:00 +0000</pubDate>
        <link>https://kirsten-1.github.io/2025/11/12/redis01%E5%85%A5%E9%97%A8%E4%BB%8E%E7%A3%81%E7%9B%98%E7%93%B6%E9%A2%88%E5%88%B0Redis%E5%86%85%E5%AD%98%E7%8E%8B%E8%80%85-%E7%BC%93%E5%AD%98%E4%BD%93%E7%B3%BB%E5%85%A8%E8%A7%A3%E6%9E%90/</link>
        <guid isPermaLink="true">https://kirsten-1.github.io/2025/11/12/redis01%E5%85%A5%E9%97%A8%E4%BB%8E%E7%A3%81%E7%9B%98%E7%93%B6%E9%A2%88%E5%88%B0Redis%E5%86%85%E5%AD%98%E7%8E%8B%E8%80%85-%E7%BC%93%E5%AD%98%E4%BD%93%E7%B3%BB%E5%85%A8%E8%A7%A3%E6%9E%90/</guid>
        
        <category>redis</category>
        
        
      </item>
    
      <item>
        <title>【AI思想启蒙04】线性回归3突破瓶颈，模型效果的提升 </title>
        <description>&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG&quot;&gt;
&lt;/script&gt;

&lt;p&gt;现实中，线性回归的问题往往是多元的。&lt;/p&gt;

&lt;h1 id=&quot;1多元回归模型基本描述&quot;&gt;1.多元回归模型基本描述&lt;/h1&gt;

&lt;p&gt;多元线性回归模型是处理具有多个特征（\(X\) 向量）的回归问题。&lt;/p&gt;

&lt;p&gt;模型是一个函数，将输入 \(X\) 映射到输出 \(Y\)。&lt;/p&gt;

&lt;p&gt;目标值 \(y\) 是由多个特征 \(x_i\) 及其对应的权重 \(w_i\) 的线性组合构成。&lt;/p&gt;

\[y = w_1 x_1 + w_2 x_2 + \cdots + w_n x_n + w_0\]

&lt;p&gt;上面的是标量形式，也可以写成向量形式/矩阵乘法形式，这是一种更规范、更紧凑的表达方式：&lt;/p&gt;

\[\hat{y} = \mathbf{W}^{\text{T}} \mathbf{X} + w_0\]

&lt;p&gt;其中，\(\mathbf{W} = \begin{pmatrix} w_1 \\ \vdots \\ w_n \end{pmatrix}\) 是权重向量。\(\mathbf{X} = \begin{pmatrix} x_1 \\ \vdots \\ x_n \end{pmatrix}\) 是特征向量。\(w_0\)（或 \(b\)）是偏置（截距）项。&lt;/p&gt;

&lt;p&gt;模型的目标是找到最优的权重 \(\mathbf{W}\) 和偏置 \(w_0\)，使得预测值 \(\hat{y}\) 与真实值 \(y\) 之间的误差最小。&lt;/p&gt;

&lt;p&gt;和一元的线性回归问题一样，衡量模型性能最常用的指标还是MSE（均方误差）：&lt;/p&gt;

\[\text{MSE} = \frac{1}{n}\sum_{i=1}^n (\hat{y}_i - y_i)^2\]

&lt;p&gt;为了将偏置项 \(w_0\) 融入矩阵乘法中，使其成为权重 \(\mathbf{W}\) 的一部分，我们需要对特征向量 \(\mathbf{X}\) 进行&lt;strong&gt;增广（Augmentation）&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;增广特征向量 \(\mathbf{X}\)：在原始特征向量 \(\mathbf{X}\) 的第一个位置（或最后一个位置）添加一个恒为1的元素。&lt;/p&gt;

\[\mathbf{X} = \begin{pmatrix} 1 \\ x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix}\]

&lt;p&gt;这个常数 $1$ 确保了 $w_0$ 在矩阵乘法中被保留。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;增广权重向量 \(\mathbf{W}\)：&lt;/strong&gt; 将偏置项 \(w_0\) 作为权重向量 \(\mathbf{W}\) 的第一个元素（对应于增广特征1）。&lt;/p&gt;

\[\mathbf{W} = \begin{pmatrix} w_0 \\ w_1 \\ w_2 \\ \vdots \\ w_n \end{pmatrix}\]

&lt;p&gt;通过这种增广，多元线性回归模型可以统一表达为一个简单的向量内积（矩阵乘法）：&lt;/p&gt;

\[\hat{y} = \mathbf{W}^{\text{T}} \mathbf{X}\]

&lt;p&gt;或&lt;/p&gt;

\[\hat{y} = \mathbf{X}^{\text{T}} \mathbf{W}\]

&lt;p&gt;这种简化表达是机器学习和深度学习中的&lt;strong&gt;标准做法&lt;/strong&gt;,简化所有数学推导（如梯度、正规方程）。同时简化了编程实现，而且MSE 损失函数仍然适用于这种简化形式：&lt;/p&gt;

\[\text{MSE} = \frac{1}{m}\sum_{i=1}^m (\mathbf{W}^{\text{T}} \mathbf{X}_i - y_i)^2\]

&lt;p&gt;这种简洁的表达方式使得复杂的多元线性回归模型在代数和编程上都变得高效和优雅。&lt;/p&gt;

&lt;h1 id=&quot;2多元回归-实战&quot;&gt;2.多元回归-实战&lt;/h1&gt;

&lt;p&gt;1.读取数据：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ast&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;load_data_from_list_format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    加载并解析您的特定格式（[[...], ...]）的数据文件。
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# 1. 使用 ast.literal_eval 安全地将字符串解析为 Python 列表
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;data_tuple&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;literal_eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
                
                &lt;span class=&quot;c1&quot;&gt;# 2. 解包：第一个元素是特征列表，第二个是目标值
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;X_row&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;y_value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                
                &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                
            &lt;span class=&quot;nf&quot;&gt;except &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;SyntaxError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Skipping line due to error: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; in line: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;
                
    &lt;span class=&quot;c1&quot;&gt;# 3. 转换为 NumPy 数组
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 示例调用
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;../boston/train_data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;load_data_from_list_format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Features (X_train) shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Targets (y_train) shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;First row of features:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;First target value:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027180907089.png&quot; alt=&quot;image-20251027180907089&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.使用多元线性回归模型对加载的全部数据进行训练，并打印出模型的参数（即截距和系数）。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c1&quot;&gt;# ----------------- 模型训练 -----------------
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;🚀 正在使用多元线性回归模型进行训练...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 1. 初始化模型
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LinearRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 2. 训练模型
# 注意：在实际应用中，您通常会划分训练集和测试集，但根据您的请求，我们使用全部数据进行训练。
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;✅ 模型训练完成。&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--- 模型参数 ---&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 3. 打印模型参数
# 截距 (Intercept)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;**截距 (Intercept, $&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;beta_0$):** &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept_&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 系数 (Coefficients)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;**特征系数 (Coefficients, $&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;beta_{1}$ 到 $&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;beta_{13}$):**&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 将系数打印成易于阅读的格式
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coefficients&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coef&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coefficients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 假设特征索引对应于第 1 到 第 13 个特征
&lt;/span&gt;    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - Feature &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (X&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 如果您想以 NumPy 数组形式查看所有系数
# print(f&quot;\n所有系数数组: \n{coefficients}&quot;)
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027181202802.png&quot; alt=&quot;image-20251027181202802&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注意，上面的13个变量没有进行标准化，只有在所有特征（自变量 \(X_i\)）都经过&lt;strong&gt;标准化（Standardization）&lt;/strong&gt;处理，即它们具有相同的尺度（例如，均值为 0，标准差为 1）时，参数（系数）的绝对值越大，才说明该变量对 \(Y\) 的影响越大。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在训练模型之前，对所有特征 \(X\) 进行标准化（StandardScaler），然后再次训练模型。&lt;/p&gt;

\[\text{标准化} (X&apos;) = \frac{X - \mu}{\sigma}\]
&lt;/blockquote&gt;

&lt;h1 id=&quot;3多项式回归&quot;&gt;3.多项式回归&lt;/h1&gt;

&lt;p&gt;使用线性回归的前提条件：数据尽量在一条直线上&lt;/p&gt;

&lt;p&gt;但是如果有下面这样的数据，如何拟合？&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;load_and_clean_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    从指定文件中读取数据，清理字符串格式，并返回 NumPy 数组。
    数据格式预期为：[[x], [y]]
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cleaned_data_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;line_number&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 用于跟踪行号
&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;line_number&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
                
                &lt;span class=&quot;c1&quot;&gt;# 1. 清理行首和行尾的空白字符
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;line_stripped&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
                
                &lt;span class=&quot;c1&quot;&gt;# 严格跳过空行或仅包含空白字符的行
&lt;/span&gt;                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line_stripped&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                    &lt;span class=&quot;c1&quot;&gt;# 如果需要调试，可以取消注释下面这行
&lt;/span&gt;                    &lt;span class=&quot;c1&quot;&gt;# print(f&quot;跳过文件中的空行或空白行 (行号: {line_number})&quot;)
&lt;/span&gt;                    &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;
                    
                &lt;span class=&quot;c1&quot;&gt;# 2. 移除所有方括号 &apos;[]&apos; 和空格，只留下数字和逗号
&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;# 示例: &quot;[[5.34...], [30.91...]]&quot; -&amp;gt; &quot;5.34...,30.91...&quot;
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;clean_value_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line_stripped&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                
                &lt;span class=&quot;c1&quot;&gt;# 3. 按逗号分隔，得到 X 和 y 的字符串
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;x_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clean_value_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                
                &lt;span class=&quot;c1&quot;&gt;# 4. 转换为浮点数并存储
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;cleaned_data_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
                
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;FileNotFoundError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;❌ 错误：未找到文件 &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_path&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;。请检查文件路径。&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ValueError&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;❌ 错误：数据格式不正确，无法转换为浮点数。请检查数据行 (行号: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line_number&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line_stripped&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;具体错误信息: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;❌ 发生未知错误: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 5. 转换为最终的 NumPy 数组
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;cleaned_data_np&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cleaned_data_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# 6. 分离特征 (X) 和目标值 (y)
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# X 必须是二维数组 (n, 1)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cleaned_data_np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cleaned_data_np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# y 是一维数组 (n,)
&lt;/span&gt;    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# ----------------- 修改后的使用示例 -----------------
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;train_paracurve_data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 建议使用 .txt 扩展名，以明确文件类型
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# **注意:** 请确保您的数据已保存到指定的文件中
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;load_and_clean_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--- ✅ 数据读取成功 ---&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;特征 X 的形状: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;目标 y 的形状: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;X 的前 5 个样本:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;y 的前 5 个样本:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;数据已清理并准备好进行模型训练（未分割数据集）。&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# **********************************************
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# 移除的分割代码原本在此处，现在直接对 X 和 y 进行操作
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# **********************************************
&lt;/span&gt;    
    &lt;span class=&quot;c1&quot;&gt;# 现在您可以直接使用整个 X 和 y 进行模型训练（例如，训练集就是整个数据集）
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# from sklearn.linear_model import LinearRegression
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# model = LinearRegression()
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# model.fit(X, y) # 直接使用所有数据进行训练
&lt;/span&gt;    
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;🎨 正在生成散点图...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# 绘制散点图
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# 绘制原始数据点 (散点图)
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# X 必须被展平为一维数组才能作为 x 轴输入
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;blue&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# 添加标题和标签
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;特征 X 与目标 Y 的数据散点图&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;特征 X 值&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;目标值 Y 值&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# 显示网格
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# 显示图形
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;✅ 散点图绘制完成。&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027182028140.png&quot; alt=&quot;image-20251027182028140&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以用下面的模型拟合：（因为通过观察猜测可以用抛物线拟合）&lt;/p&gt;

\[y = a x_1^2 + b x_1 + c\]

&lt;p&gt;这被称为 &lt;strong&gt;二次多项式回归 (Quadratic Polynomial Regression)&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sklearn&lt;/code&gt; 的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PolynomialFeatures&lt;/code&gt; 来生成 \(x^2\) 和 \(x\) 这两个特征，然后使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LinearRegression&lt;/code&gt; 进行拟合。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LinearRegression&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PolynomialFeatures&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r2_score&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 为保证绘图平滑，我们对 X 进行排序
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argsort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_sorted&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_sorted&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# -------------------------- 1. 特征工程：生成多项式特征 --------------------------
# 我们需要创建 X^2 和 X 这两个特征
# 公式: y = a*x^2 + b*x + c
# 这相当于一个线性模型: y = a*Z1 + b*Z2 + c，其中 Z1=x^2, Z2=x
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# degree=2 会生成 [1, x, x^2] (如果 include_bias=True)
# 我们设置为 include_bias=False，因为 LinearRegression 默认会添加截距 (c)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;poly&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PolynomialFeatures&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;degree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;include_bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_poly&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;poly&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# X_poly 现在有两列: [x, x^2] (注意：PolynomialFeatures 默认按幂次升序 [x^1, x^2])
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 为了对应您公式中的顺序 (x^2, x)，我们手动调整列的顺序（可选，但有助于参数对应）
# 确保 X_poly 的列顺序是 [x^2, x]
# 实际上，由于系数是自动拟合的，保持默认顺序 [x, x^2] 更简单。
# 我们保持默认顺序，并在解释系数时说明。
# 默认列顺序: X_poly = [x^1, x^2]
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# -------------------------- 2. 模型训练 --------------------------
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LinearRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_poly&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 3. 预测拟合曲线
# 用于绘图的预测值
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_poly&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# -------------------------- 4. 打印参数 --------------------------
# 系数顺序: model.coef_[0] 对应 x， model.coef_[1] 对应 x^2
# 截距: model.intercept_ 对应 c
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;coef_x2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;intercept_c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept_&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--- ✅ 模型训练完成 ---&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;拟合公式: y = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_x2&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; * x^2 + &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_x&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; * x + &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept_c&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--- 模型参数 ---&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;a (x^2 的系数): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_x2&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;b (x 的系数): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_x&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;c (截距): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept_c&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;拟合优度 R²: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;r2_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# -------------------------- 5. 绘图 --------------------------
# Matplotlib 绘图设置
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;font.sans-serif&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;SimHei&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;axes.unicode_minus&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 解决负号显示的问题
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 绘制原始数据点 (散点图)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;blue&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;原始数据点&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 绘制拟合曲线
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;red&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;拟合曲线: y = a*x² + b*x + c&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 添加标题和标签
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;二次多项式回归拟合&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;特征 X&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;目标值 Y&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 添加图例
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 显示网格
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 显示图形
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027182554921.png&quot; alt=&quot;image-20251027182554921&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;\(R^2\)​ (R-squared) ，也称为决定系数 (Coefficient of Determination)&lt;/strong&gt;,是用来衡量建立的回归模型对原始数据的拟合程度的一个指标。计算公式如下（非必要了解，但可帮助理解）：&lt;/p&gt;

\[R^2 = 1 - \frac{SS_{res}}{SS_{tot}}\]

&lt;ul&gt;
  &lt;li&gt;\(SS_{res}\)（Residual Sum of Squares）：残差平方和，即预测值与实际值之间差异的平方和。&lt;/li&gt;
  &lt;li&gt;\(SS_{tot}\)（Total Sum of Squares）：总平方和，即实际值与实际值平均值之间差异的平方和（代表了 $Y$ 的总变异）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;\(R^2\) 的取值范围通常在 0 到 1 之间。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;R^2 值&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;含义&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;\(R^2 \approx 1\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;模型能很好地解释数据的变异。这意味着模型对数据的拟合非常好，预测值与实际值非常接近。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;\(R^2 \approx 0\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;模型几乎不能解释数据的变异。这意味着模型的预测能力很弱，可能还不如直接使用 \(Y\) 的平均值来预测。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;\(R^2 &amp;lt; 0\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;这种情况很少见，但可能发生在拟合一个&lt;strong&gt;非线性模型&lt;/strong&gt;（如您刚才做的多项式回归）或使用&lt;strong&gt;不合适的模型&lt;/strong&gt;时。它意味着您的模型拟合效果比简单地使用 \(Y\) 的平均值进行预测还要差。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;p&gt;上面演示的是二次，三次甚至高次都是同理。&lt;/p&gt;

&lt;p&gt;根据泰勒公式，任意函数都可以表示成\(y = \beta_n x^n + \beta_{n-1} x^{n-1} + \dots + \beta_1 x + \beta_0\)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;根据 &lt;strong&gt;泰勒公式 (Taylor’s Formula)&lt;/strong&gt;，&lt;strong&gt;在一定条件下&lt;/strong&gt;，一个平滑（可导）的函数 \(f(x)\) 可以在某一点 \(x_0\) 附近用一个&lt;strong&gt;多项式&lt;/strong&gt;来近似表示：&lt;/p&gt;

\[f(x) \approx f(x_0) + f&apos;(x_0)(x-x_0) + \frac{f&apos;&apos;(x_0)}{2!}(x-x_0)^2 + \dots + \frac{f^{(n)}(x_0)}{n!}(x-x_0)^n\]

  &lt;p&gt;&lt;strong&gt;这正是多项式回归的理论基础！&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;多项式回归的本质就是利用线性模型来拟合特征的&lt;strong&gt;多项式组合&lt;/strong&gt;，从而&lt;strong&gt;利用泰勒多项式的能力去逼近数据集中存在的任何潜在的非线性关系&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;只需通过 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PolynomialFeatures(degree=n)&lt;/code&gt; 来生成 \(x\) 的 \(n\) 次方直到 1 次方的特征，然后将其输入到线性回归模型中进行拟合即可。&lt;/p&gt;

&lt;p&gt;次数越高，计算量&lt;strong&gt;不一定&lt;/strong&gt;是越来越大的（因为线性回归的计算复杂度主要取决于样本量 \(N\) 和特征数 \(P\)），&lt;strong&gt;但模型引入的风险是越来越高的。&lt;/strong&gt;理由如下：&lt;/p&gt;

&lt;p&gt;1.过拟合是最主要的问题。高次多项式能够&lt;strong&gt;完美&lt;/strong&gt;穿过所有训练数据点，但它学到的是数据中的&lt;strong&gt;噪声&lt;/strong&gt;和随机误差，而不是数据背后的真实规律。这会导致模型在&lt;strong&gt;新的、未见过的数据&lt;/strong&gt;上的泛化能力极差。&lt;/p&gt;

&lt;p&gt;2.共线性：当 \(x\) 的数值范围较大时，\(x^2, x^3, \dots, x^n\) 这些高次项之间的相关性会非常高，导致&lt;strong&gt;特征共线性&lt;/strong&gt;。这会使回归系数 \(\beta_i\) 的估计变得非常不稳定，微小的数据变动都可能导致系数的巨大变化。&lt;/p&gt;

&lt;p&gt;3.计算量。虽然对单变量而言计算量增加不显著，但对于&lt;strong&gt;多变量&lt;/strong&gt;（如 \(x_1, x_2\)）的高次模型，特征数量会呈指数级增长，此时计算时间和内存消耗会急剧增加。&lt;/p&gt;

&lt;p&gt;4.随着多项式次数的增加，模型的系数变得难以解释，降低了模型的可读性和实用性。&lt;/p&gt;

&lt;p&gt;因此，在实践中，我们通常选择一个&lt;strong&gt;较低的次数（如 2 次或 3 次）&lt;/strong&gt;，并在拟合度（\(R^2\)）和模型复杂度之间找到最佳的平衡点。&lt;/p&gt;

&lt;p&gt;另外，如果模型过拟合（在训练集上学习过多噪声），不一定在测试集上就一定好，所以次数一定不是越高越好。（虽然次数越高，模型对于训练集的拟合就越好）。这也是一种trade off&lt;/p&gt;

&lt;h1 id=&quot;4花式玩法-抗噪声&quot;&gt;4.花式玩法-抗噪声&lt;/h1&gt;

&lt;p&gt;考虑这样的问题，原来有数据\([X, y]\)，现在引入随机产生的数据\(X_2\)，就有了\([X_1, X_2, y]\)，请问最后多元线性回归拟合的\(\hat{y}=w_1X_1+w_2X_2+b\)中，\(w_2\)的取值是不是0？&lt;/p&gt;

&lt;p&gt;结论：\(w_2\) 的&lt;strong&gt;期望&lt;/strong&gt;值是0，但&lt;strong&gt;实际&lt;/strong&gt;值可能不为0&lt;/p&gt;

&lt;p&gt;\(X_2\) 是完全随机生成的（例如，来自 \(\mathcal{N}(0, 1)\) 或 \(\mathcal{U}(a, b)\) 分布）。\(X_2\) 与原始特征 \(X_1\) &lt;strong&gt;完全独立&lt;/strong&gt;，并且与目标变量 \(y\) &lt;strong&gt;完全独立&lt;/strong&gt;（即它们之间没有真实的线性关系）。&lt;/p&gt;

&lt;p&gt;在线性回归中，模型的系数 \(w_i\) 旨在最小化残差平方和（最小二乘法）。如果 \(X_2\) 与 \(y\) 之间没有真实关系，那么在&lt;strong&gt;无限大的样本集&lt;/strong&gt;上，最小化残差平方和的最佳解是设置 \(w_2\) 为 $0$，因为任何非零的 \(w_2\) 只会引入额外的、不可解释的误差。&lt;/p&gt;

\[E[w_2] = 0\]

&lt;p&gt;&lt;strong&gt;实际原因 (有限样本集和随机误差)：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在任何&lt;strong&gt;有限的实际数据集&lt;/strong&gt;上，即使 \(X_2\) 是纯随机的，它也会由于&lt;strong&gt;抽样误差（Sampling Error）和随机噪声&lt;/strong&gt;而出现以下情况：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;偶然相关性 (Spurious Correlation)：&lt;/strong&gt; 随机生成的 \(X_2\) 与目标变量 \(y\) 之间会存在微弱、偶然的非零相关性。最小二乘法会试图利用这种微弱的、随机的相关性来进一步稍微降低残差平方和。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;噪声吸收：&lt;/strong&gt; \(X_2\) 可能会“吸收”模型中未被 \(X_1\) 解释的&lt;strong&gt;随机噪声&lt;/strong&gt;部分。模型可能会将 \(w_2\) 设置为一个微小的非零值，以利用 \(X_2\) 的随机波动来微调拟合，使 \(\sum (y - \hat{y})^2\) 略微减小。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在实际运行代码时，您会发现拟合得到的 \(w_2\) 是一个&lt;strong&gt;接近于 0 的非零小数&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;下面是模拟的代码：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LinearRegression&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 1. 创建模拟数据 ---
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 设置随机种子以保证结果可重现
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_SAMPLES&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# 样本数量
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TRUE_W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;5.0&lt;/span&gt;       &lt;span class=&quot;c1&quot;&gt;# X1 的真实系数
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TRUE_B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;10.0&lt;/span&gt;       &lt;span class=&quot;c1&quot;&gt;# 真实截距
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 原始特征 X1 (与 y 有关)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_SAMPLES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; 

&lt;span class=&quot;c1&quot;&gt;# 目标变量 y (包含随机噪声)
# y = 5*X1 + 10 + 噪声
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE_W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE_B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N_SAMPLES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 2. 引入随机特征 X2 ---
# X2 是一个完全随机的特征，与 X1 和 y 均独立
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_SAMPLES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 3. 组合特征矩阵 ---
# 现在的特征矩阵 X 包含 X1 和 X2
# X.shape -&amp;gt; (1000, 2)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_combined&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;hstack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;原始特征 X1 形状: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;随机特征 X2 形状: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;组合特征 X 形状: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_combined&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 4. 训练多元线性回归模型 ---
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LinearRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_combined&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 5. 打印结果 ---
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1_fit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;w2_fit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b_fit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept_&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--- 模型拟合结果 ---&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;特征 X1 的真实系数 (w1): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TRUE_W1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;拟合得到的 X1 系数 (w1): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1_fit&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;随机特征 X2 的真实系数 (w2): 0.0000&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;拟合得到的 X2 系数 (w2): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2_fit&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;截距的真实值 (b): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TRUE_B&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;拟合得到的截距 (b): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_fit&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027204319656.png&quot; alt=&quot;image-20251027204319656&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面的例子可以说明&lt;strong&gt;线性回归具有抗噪声的能力。&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;5花式玩法-共线性&quot;&gt;5.花式玩法-共线性&lt;/h1&gt;

&lt;p&gt;假设我们从原始特征 \(x_1\) 构造了两个完全相同的特征 \(X_{1a} = x_1\)和 \(X_{1b} = x_1\)，并将它们代入模型：&lt;/p&gt;

\[y = w_{1a} X_{1a} + w_{1b} X_{1b} + w_0\]

&lt;p&gt;这种复制特征的操作创建了&lt;strong&gt;完美的共线性（Perfect Collinearity）&lt;/strong&gt;，即特征 \(X_{1a}\) 和 \(X_{1b}\) 之间的相关系数为1。&lt;/p&gt;

&lt;p&gt;线性回归模型（最小二乘法）的优化目标是找到最优的权重组合 \((w_{1a}, w_{1b})\)，使得残差平方和最小。&lt;/p&gt;

&lt;p&gt;假设原始的真实关系是 \(y = W_{\text{true}} x_1 + w_0\)。&lt;/p&gt;

&lt;p&gt;当引入 \(X_{1a}\) 和 \(X_{1b}\) 时，模型要拟合的是：&lt;/p&gt;

\[y = w_{1a} x_1 + w_{1b} x_1 + w_0 = (w_{1a} + w_{1b}) x_1 + w_0\]

&lt;p&gt;&lt;strong&gt;问题在于：&lt;/strong&gt; 只要保持系数之和 \((w_{1a} + w_{1b})\) 等于原始的真实系数 \(W_{\text{true}}\)，模型的预测结果 \(\hat{y}\) 就不会改变，残差平方和（RSS）也保持不变。&lt;/p&gt;

&lt;p&gt;因此，模型无法确定 \(w_{1a}\) 和 \(w_{1b}\) 的具体取值，只要满足：&lt;/p&gt;

\[w_{1a} + w_{1b} = W_{\text{true}}\]

&lt;p&gt;即，存在&lt;strong&gt;无穷多组&lt;/strong&gt;解，它们都能最小化 RSS。这使得系数矩阵在数学上是&lt;strong&gt;奇异&lt;/strong&gt;的（不可逆），导致最小二乘解变得不确定或不稳定。&lt;/p&gt;

&lt;p&gt;这种现象说明了线性回归的一个重要特性：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;线性回归对特征间的共线性高度敏感。当特征之间存在高度相关性时，模型的系数会被“摊派”，变得不稳定、难以解释，并且在不同数据集上运行时，系数的取值可能会发生剧烈变化。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;因此，在实际应用中，处理共线性是特征工程的一个重要环节，常用的解决方法包括：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;特征选择：&lt;/strong&gt; 删除重复或高度相关的特征（例如，在这个例子中删除 \(X_{1b}\)）。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;正则化：&lt;/strong&gt; 使用 &lt;strong&gt;岭回归 (Ridge Regression)&lt;/strong&gt; 或 &lt;strong&gt;Lasso 回归&lt;/strong&gt;，它们通过引入惩罚项来稳定和约束系数，减轻共线性的影响。&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;加噪声对于线性回归没有伤害，加相关性强的变量也不会带来帮助。&lt;/strong&gt;这是线性回归很重要的特点。&lt;/p&gt;

</description>
        <pubDate>Mon, 27 Oct 2025 00:00:00 +0000</pubDate>
        <link>https://kirsten-1.github.io/2025/10/27/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9904/</link>
        <guid isPermaLink="true">https://kirsten-1.github.io/2025/10/27/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9904/</guid>
        
        <category>AI思想启蒙</category>
        
        
      </item>
    
      <item>
        <title>【AI思想启蒙03】线性回归2从傻瓜到智能，梯度下降法学习法</title>
        <description>&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG&quot;&gt;
&lt;/script&gt;

&lt;h1 id=&quot;1代码实战线性回归&quot;&gt;1.代码实战：线性回归&lt;/h1&gt;

&lt;p&gt;1.导包与数据读取：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LinearRegression&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 分割数据集，分成训练集和测试集
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean_squared_error&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;# 计算MSE
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;load_and_clean_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    从指定文件中读取数据，清理字符串格式，并返回 NumPy 数组。
    数据格式预期为：[[x], [y]]
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cleaned_data_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;line_number&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 用于跟踪行号
&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;line_number&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
                
                &lt;span class=&quot;c1&quot;&gt;# 1. 清理行首和行尾的空白字符
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;line_stripped&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
                
                &lt;span class=&quot;c1&quot;&gt;# 严格跳过空行或仅包含空白字符的行
&lt;/span&gt;                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line_stripped&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                    &lt;span class=&quot;c1&quot;&gt;# 如果需要调试，可以取消注释下面这行
&lt;/span&gt;                    &lt;span class=&quot;c1&quot;&gt;# print(f&quot;跳过文件中的空行或空白行 (行号: {line_number})&quot;)
&lt;/span&gt;                    &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;
                    
                &lt;span class=&quot;c1&quot;&gt;# 2. 移除所有方括号 &apos;[]&apos; 和空格，只留下数字和逗号
&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;# 示例: &quot;[[5.34...], [30.91...]]&quot; -&amp;gt; &quot;5.34...,30.91...&quot;
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;clean_value_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line_stripped&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                
                &lt;span class=&quot;c1&quot;&gt;# 3. 按逗号分隔，得到 X 和 y 的字符串
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;x_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clean_value_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                
                &lt;span class=&quot;c1&quot;&gt;# 4. 转换为浮点数并存储
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;cleaned_data_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
                
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;FileNotFoundError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;❌ 错误：未找到文件 &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_path&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;。请检查文件路径。&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ValueError&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;❌ 错误：数据格式不正确，无法转换为浮点数。请检查数据行 (行号: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line_number&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line_stripped&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;具体错误信息: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;❌ 发生未知错误: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 5. 转换为最终的 NumPy 数组
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;cleaned_data_np&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cleaned_data_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# 6. 分离特征 (X) 和目标值 (y)
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# X 必须是二维数组 (n, 1)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cleaned_data_np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cleaned_data_np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# y 是一维数组 (n,)
&lt;/span&gt;    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# ----------------- 修改后的使用示例 -----------------
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 建议使用 .txt 扩展名，以明确文件类型
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# **注意:** 请确保您的数据已保存到指定的文件中
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;load_and_clean_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--- ✅ 数据读取成功 ---&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;特征 X 的形状: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;目标 y 的形状: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;X 的前 5 个样本:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;y 的前 5 个样本:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;数据已清理并准备好进行模型训练（未分割数据集）。&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# **********************************************
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# 移除的分割代码原本在此处，现在直接对 X 和 y 进行操作
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# **********************************************
&lt;/span&gt;    
    &lt;span class=&quot;c1&quot;&gt;# 现在您可以直接使用整个 X 和 y 进行模型训练（例如，训练集就是整个数据集）
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# from sklearn.linear_model import LinearRegression
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# model = LinearRegression()
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# model.fit(X, y) # 直接使用所有数据进行训练
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027135230250.png&quot; alt=&quot;image-20251027135230250&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.分割数据集，分为测试集和训练集，比例2:8&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 设置随机种子以确保结果可重现
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;训练集大小 (X_train): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;测试集大小 (X_test): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251027135243118.png&quot; alt=&quot;image-20251027135243118&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;3.模型训练：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LinearRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 打印模型参数 (截距和斜率)
# 对于一元线性回归： y = coef * X + intercept
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--- 模型训练结果 ---&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;模型截距 (Intercept): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept_&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;模型系数 (Coefficient/Slope): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251027135317069.png&quot; alt=&quot;image-20251027135317069&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;4.模型预测，计算MSE&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c1&quot;&gt;# 1. 对训练集进行预测
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 2. 对测试集进行预测
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 计算 MSE
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mse_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mean_squared_error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mse_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mean_squared_error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--- 模型评估 (MSE) ---&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;训练集 MSE: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mse_train&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;测试集 MSE: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mse_test&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251027135354439.png&quot; alt=&quot;image-20251027135354439&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;5.绘图&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c1&quot;&gt;# -----------------------------------------------------------
# 步骤 3: 绘图
# -----------------------------------------------------------
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Matplotlib 绘图设置
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;font.sans-serif&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;SimHei&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;axes.unicode_minus&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 解决负号显示的问题
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# **关键修正步骤：排序**
# 1. 对完整的 X 数组进行排序，以确保拟合线是一条平滑的直线
#    np.argsort 返回排序后的索引
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argsort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 注意：X是二维数组，需要先展平
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_sorted&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 2. 对模型在 X 上的预测值也使用相同的索引进行排序
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_full_pred_sorted&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# --- 绘图要求 1: 所有点和预测线一起展示 (修正) ---
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 绘制所有原始数据点 (训练集和测试集)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;blue&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;训练集数据点&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;green&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;测试集数据点&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 绘制预测线 (拟合线) - 使用排序后的预测数据
# 这将确保红色线是一条平滑的直线
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_full_pred_sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;red&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
         &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;线性回归拟合线 (y = {:.4f}*X + {:.4f})&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
         &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;所有数据点与线性回归拟合线 (总览)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;特征 X&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;目标 Y&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# --- 绘图要求 2 &amp;amp; 3: 训练集和测试集分开展示（无需排序，因为点本身就是散点图） ---
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sharey&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 2. 训练集 (Training Set) - 绘制训练集数据和预测线
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;blue&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;训练集数据点&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# **注意：** 这里的 X_train 依然可能未排序，因此也需要排序以防折叠
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_index_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argsort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_train_sorted&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_index_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_train_pred_sorted&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train_sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train_sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train_pred_sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;red&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;模型预测线&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;训练集数据与模型拟合&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;特征 X&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;目标 Y&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 3. 测试集 (Testing Set) - 绘制测试集数据和预测线
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;green&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;测试集数据点&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# **注意：** 这里的 X_test 也需要排序以防折叠
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_index_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argsort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_test_sorted&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_index_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_test_pred_sorted&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test_sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test_sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test_pred_sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;red&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;模型预测线&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;测试集数据与模型预测&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;特征 X&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tight_layout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027135426797.png&quot; alt=&quot;image-20251027135426797&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027135438038.png&quot; alt=&quot;image-20251027135438038&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2mse与wb&quot;&gt;2.MSE与w,b&lt;/h1&gt;

&lt;h2 id=&quot;画图理解&quot;&gt;画图理解&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c1&quot;&gt;# 使用 sklearn 找到最优 w* 和 b*
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimal_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LinearRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;w_star&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimal_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b_star&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimal_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept_&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;最优参数 w*: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_star&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, b*: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_star&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 定义 MSE 计算函数
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;calculate_mse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;计算给定 w 和 b 下的均方误差&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 预测值: y_pred = w * X + b
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# MSE: mean((y - y_pred)^2)
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# -----------------------------------------------------------
# 步骤 2: 绘制 MSE vs W (固定 b = b*)
# -----------------------------------------------------------
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 选择 w 的变化范围 (以最优 w* 为中心)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_star&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_star&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 固定 b 为最优值
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_fixed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_star&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 计算 MSE 数组
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mse_w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;calculate_mse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_fixed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mse_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;blue&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_star&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;calculate_mse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_star&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_star&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;red&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;最小MSE点 (w*=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_star&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zorder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;MSE 随 W (斜率) 的变化 (固定 b = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_fixed&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;权重 W (斜率)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;均方误差 MSE&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# -----------------------------------------------------------
# 步骤 3: 绘制 MSE vs B (固定 w = w*)
# -----------------------------------------------------------
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 选择 b 的变化范围 (以最优 b* 为中心)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_star&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_star&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 固定 w 为最优值
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_fixed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_star&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 计算 MSE 数组
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mse_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;calculate_mse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_fixed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mse_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;green&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_star&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;calculate_mse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_star&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_star&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;red&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;最小MSE点 (b*=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_star&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zorder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;MSE 随 B (截距) 的变化 (固定 w = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_fixed&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;偏置 B (截距)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;均方误差 MSE&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251027135548654.png&quot; alt=&quot;image-20251027135548654&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251027135628114.png&quot; alt=&quot;image-20251027135628114&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果以全量数据进行预测，可以从上图看到MSE与w,b的关系。要使得MSE最小，一定存在这样的w和b&lt;/p&gt;

&lt;p&gt;这两张图都展示了 MSE 与单个参数（w或 b）之间的关系是 &lt;strong&gt;凸的二次函数（抛物线）&lt;/strong&gt;。曲线只有一个最低点。这个最低点对应的w值（在第一张图上）或b值（在第二张图上）就是使 MSE 最小化的最优参数值。这是梯度下降等优化算法能够有效工作的基础，因为它们总是沿着曲线下降，最终能够收敛到全局最低点。&lt;/p&gt;

&lt;h2 id=&quot;数学分析梯度分析&quot;&gt;数学分析(梯度分析)&lt;/h2&gt;

&lt;p&gt;从数学分析的角度来看，&lt;strong&gt;线性回归的均方误差（MSE）损失函数&lt;/strong&gt;是一个完美的&lt;strong&gt;凸函数（Convex Function）&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;对于一元线性回归模型 \(y = wX + b\)，给定数据集 \(\{(X_i, y_i)\}_{i=1}^n\)，其均方误差（MSE）损失函数 \(J(w, b)\) 定义为：&lt;/p&gt;

\[J(w, b) = \frac{1}{n} \sum_{i=1}^{n} (y_i - (wX_i + b))^2\]

&lt;p&gt;为了证明 \(J(w, b)\) 是一个凸函数，我们可以使用&lt;strong&gt;二阶导数判别法&lt;/strong&gt;（即 Hessian 矩阵）。&lt;/p&gt;

&lt;p&gt;【A. 凸函数定义】&lt;/p&gt;

&lt;p&gt;如果一个函数 \(f(\mathbf{x})\) 的 &lt;strong&gt;Hessian 矩阵 \(\mathbf{H}\)&lt;/strong&gt; 在其定义域上是 &lt;strong&gt;半正定（Positive Semi-definite）&lt;/strong&gt; 的，那么\(f(\mathbf{x})\) 是一个凸函数。&lt;/p&gt;

&lt;p&gt;【B. 计算 Hessian 矩阵】&lt;/p&gt;

&lt;p&gt;\(J(w, b)\) 是关于参数向量 \(\mathbf{\theta} = \begin{pmatrix} w \\ b \end{pmatrix}\) 的函数。&lt;/p&gt;

&lt;p&gt;1.计算一阶偏导数（梯度 \(\nabla J\)）：&lt;/p&gt;

\[\frac{\partial J}{\partial w} = \frac{2}{n} \sum_{i=1}^{n} (wX_i + b - y_i) X_i\]

\[\frac{\partial J}{\partial b} = \frac{2}{n} \sum_{i=1}^{n} (wX_i + b - y_i)\]

&lt;p&gt;2.计算二阶偏导数：&lt;/p&gt;

\[\frac{\partial^2 J}{\partial w^2} = \frac{\partial}{\partial w} \left[ \frac{2}{n} \sum_{i=1}^{n} (wX_i + b - y_i) X_i \right] = \frac{2}{n} \sum_{i=1}^{n} X_i^2\]

\[\frac{\partial^2 J}{\partial b^2} = \frac{\partial}{\partial b} \left[ \frac{2}{n} \sum_{i=1}^{n} (wX_i + b - y_i) \right] = \frac{2}{n} \sum_{i=1}^{n} 1 = 2\]

\[\frac{\partial^2 J}{\partial w \partial b} = \frac{\partial}{\partial b} \left[ \frac{2}{n} \sum_{i=1}^{n} (wX_i + b - y_i) X_i \right] = \frac{2}{n} \sum_{i=1}^{n} X_i\]

&lt;p&gt;3.构建 Hessian 矩阵 \(\mathbf{H}\)：&lt;/p&gt;

\[\mathbf{H} = \begin{pmatrix} \frac{\partial^2 J}{\partial w^2} &amp;amp; \frac{\partial^2 J}{\partial w \partial b} \\ \frac{\partial^2 J}{\partial w \partial b} &amp;amp; \frac{\partial^2 J}{\partial b^2} \end{pmatrix} = \frac{2}{n} \begin{pmatrix} \sum_{i=1}^{n} X_i^2 &amp;amp; \sum_{i=1}^{n} X_i \\ \sum_{i=1}^{n} X_i &amp;amp; n \end{pmatrix}\]

&lt;p&gt;【C. 判别 Hessian 矩阵的半正定性】&lt;/p&gt;

&lt;p&gt;一个 \(2 \times 2\) 矩阵是半正定的，当且仅当它的&lt;strong&gt;主子式（Principal Minors）&lt;/strong&gt;是非负的：&lt;/p&gt;

&lt;p&gt;1.&lt;strong&gt;一阶主子式（对角线元素）：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$H_{11} = \frac{2}{n} \sum X_i^2$. 由于 $X_i^2 \ge 0$，因此 $H_{11} \ge 0$.&lt;/li&gt;
  &lt;li&gt;$H_{22} = 2 &amp;gt; 0$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2.二阶主子式（行列式 \(\det(\mathbf{H})\)）：&lt;/p&gt;

\[\det(\mathbf{H}) = \left(\frac{2}{n}\right)^2 \left[ n \sum_{i=1}^{n} X_i^2 - \left( \sum_{i=1}^{n} X_i \right)^2 \right]\]

&lt;p&gt;根据 柯西-施瓦茨不等式（Cauchy–Schwarz inequality） 的离散形式：&lt;/p&gt;

\[\left( \sum_{i=1}^{n} a_i^2 \right) \left( \sum_{i=1}^{n} b_i^2 \right) \ge \left( \sum_{i=1}^{n} a_i b_i \right)^2\]

&lt;p&gt;在我们的行列式表达式中，令 $a_i = X_i$ 且 $b_i = 1$：&lt;/p&gt;

\[\left( \sum_{i=1}^{n} X_i^2 \right) \left( \sum_{i=1}^{n} 1^2 \right) \ge \left( \sum_{i=1}^{n} X_i \cdot 1 \right)^2\]

\[n \sum_{i=1}^{n} X_i^2 \ge \left( \sum_{i=1}^{n} X_i \right)^2\]

&lt;p&gt;因此，行列式内部的项 \([ n \sum X_i^2 - (\sum X_i)^2 ] \ge 0\)。&lt;/p&gt;

&lt;p&gt;这意味着 \(\det(\mathbf{H}) \ge 0\)。&lt;/p&gt;

&lt;p&gt;由于所有主子式都非负，&lt;strong&gt;Hessian 矩阵 \(\mathbf{H}\) 是半正定的&lt;/strong&gt;，故 $J(w, b)$ 是一个&lt;strong&gt;凸函数&lt;/strong&gt;。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;为什么只有全局最小值，而不是局部最小值？&lt;/p&gt;

&lt;p&gt;任何凸函数 \(f(\mathbf{x})\) 的任何局部最小值同时也是&lt;strong&gt;全局最小值&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;如果一个凸函数是&lt;strong&gt;严格凸&lt;/strong&gt;的（即 \(\det(\mathbf{H}) &amp;gt; 0\)），那么它至多只有一个全局最小值。&lt;/p&gt;

&lt;p&gt;在大多数实际数据场景中（非病态数据）:只有当所有 \(X_i\) 都相同时（即特征没有变化），行列式 \(\det(\mathbf{H})\) 才会等于零。在这种情况下，MSE 损失函数会沿着某个方向形成一个“平底谷”（即多个参数组合都能达到最小 MSE），此时存在一个最小值的&lt;strong&gt;集合&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;只要数据集中的 \(X_i\) &lt;strong&gt;不全相同&lt;/strong&gt;（即 \(\sum X_i^2 \ne \frac{1}{n}(\sum X_i)^2\)），那么 \(\det(\mathbf{H}) &amp;gt; 0\)，函数就是&lt;strong&gt;严格凸&lt;/strong&gt;的。&lt;/p&gt;

&lt;p&gt;对于一个&lt;strong&gt;严格凸函数&lt;/strong&gt;，它只能有一个局部最小值，而这个局部最小值就是&lt;strong&gt;唯一的全局最小值&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;这意味着，无论从 \(w\) 和 \(b\) 的哪个初始值开始（比如使用梯度下降法），最终都将收敛到同一个使 MSE 最小化的参数组合。&lt;/p&gt;

&lt;p&gt;线性回归的 MSE 损失函数是一个凸函数，其碗状的损失曲面保证了它没有山峰或局部凹陷（局部最小值），因此任何优化算法找到的最低点都是&lt;strong&gt;全局最优解&lt;/strong&gt;。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;参数 \(w\) 和 \(b\) 如何更新以逼近这个最小值？&lt;/p&gt;

&lt;p&gt;梯度下降法的核心思想是：&lt;strong&gt;沿着损失函数曲面当前位置坡度最陡峭的下降方向（即负梯度方向）迈出一步&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;梯度 \(\nabla J(w, b)\) 是一个向量，包含了损失函数 \(J\) 对所有参数的&lt;strong&gt;一阶偏导数&lt;/strong&gt;：&lt;/p&gt;

\[\nabla J(w, b) = \begin{pmatrix} \frac{\partial J}{\partial w} \\ \frac{\partial J}{\partial b} \end{pmatrix}\]

&lt;p&gt;其中，偏导数（即梯度分量）上面计算过：&lt;/p&gt;

\[\frac{\partial J}{\partial w} = \frac{2}{n} \sum_{i=1}^{n} (wX_i + b - y_i) X_i\]

\[\frac{\partial J}{\partial b} = \frac{2}{n} \sum_{i=1}^{n} (wX_i + b - y_i)\]

&lt;p&gt;梯度下降法的参数更新迭代公式如下：&lt;/p&gt;

\[\begin{aligned} w_{\text{new}} &amp;amp;= w_{\text{old}} - \alpha \frac{\partial J}{\partial w} \\ b_{\text{new}} &amp;amp;= b_{\text{old}} - \alpha \frac{\partial J}{\partial b} \end{aligned}\]

&lt;p&gt;其中，\(\alpha &amp;gt; 0\) 是&lt;strong&gt;学习率（Learning Rate）&lt;/strong&gt;，它控制了每一步更新的幅度。&lt;/p&gt;

&lt;p&gt;我们以参数 \(w\) 的更新为例进行分析，参数 \(b\) 的分析同理。&lt;/p&gt;

&lt;p&gt;我们的目标是让 \(J(w, b)\) 减小，即找到曲线的最低点。&lt;/p&gt;

&lt;p&gt;情况一：\(\frac{\partial J}{\partial w} &amp;gt; 0\) （当前点在最低点右侧）&lt;/p&gt;

&lt;p&gt;损失函数曲线在当前点 \(w\) 处的斜率为正（向上倾斜）。这意味着当前 \(w\)的值&lt;strong&gt;大于&lt;/strong&gt;最优值 \(w^*\)。&lt;/p&gt;

\[\Delta w = - \alpha \underbrace{\frac{\partial J}{\partial w}}_{&amp;gt; 0}\]

&lt;p&gt;由于 \(\alpha &amp;gt; 0\)，所以 \(\Delta w\) 必须小于 0。参数 \(w\) 将减小 (\(w_{\text{new}} &amp;lt; w_{\text{old}}\))。\(w\) 向左（较小的值）移动，即向全局最小值 \(w^*\)靠近。&lt;/p&gt;

&lt;p&gt;情况二：\(\frac{\partial J}{\partial w} &amp;lt; 0\) （当前点在最低点左侧）&lt;/p&gt;

&lt;p&gt;损失函数曲线在当前点 \(w\) 处的斜率为负（向下倾斜）。这意味着当前 \(w\)的值&lt;strong&gt;小于&lt;/strong&gt;最优值 \(w^*\)。&lt;/p&gt;

\[\Delta w = - \alpha \underbrace{\frac{\partial J}{\partial w}}_{&amp;lt; 0}\]

&lt;p&gt;由于 \(\alpha &amp;gt; 0\)，所以 \(\Delta w\) 必须&lt;strong&gt;大于 0&lt;/strong&gt;。参数 \(w\) 将增大 (\(w_{\text{new}} &amp;gt; w_{\text{old}}\))。\(w\) 向右（较大的值）移动，即向全局最小值 \(w^*\) 靠近。&lt;/p&gt;

&lt;p&gt;所以，无论是梯度大于 0 还是小于 0，参数更新公式 \(w_{\text{new}} = w_{\text{old}} - \alpha \frac{\partial J}{\partial w}\) 都保证了参数&lt;strong&gt;总是在向坡度下降最快的方向移动&lt;/strong&gt;，从而不断减小损失 \(J(w, b)\)。&lt;/p&gt;

&lt;p&gt;由于 MSE 损失函数是一个&lt;strong&gt;凸函数&lt;/strong&gt;，这种持续下降的行为最终将不可避免地导向&lt;strong&gt;唯一的全局最小值&lt;/strong&gt;。梯度下降法之所以高效且强大，正是因为它能够利用损失函数的凸性，保证收敛到最优解。&lt;/p&gt;

&lt;h2 id=&quot;学习率的选择&quot;&gt;学习率的选择&lt;/h2&gt;

&lt;p&gt;在应用梯度下降法时&lt;strong&gt;至关重要&lt;/strong&gt;的超参数：&lt;strong&gt;学习率（Learning Rate），通常用 \(\alpha\) 表示&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;学习率 $\alpha$ 控制了参数在每次迭代中沿着梯度方向移动的步长。在更新公式中体现为：&lt;/p&gt;

\[\theta_{\text{new}} = \theta_{\text{old}} - \alpha \cdot \nabla J(\theta_{\text{old}})\]

&lt;p&gt;选择 \(\alpha\) 时，需要找到一个&lt;strong&gt;平衡点&lt;/strong&gt;：既要足够大以快速收敛，又要足够小以避免震荡和发散。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;情况&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;学习率 (α) 特征&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;训练效果&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;数学/几何分析&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;过大&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Large \(\alpha\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;发散 (Divergence) 或剧烈震荡&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;步长太大，每次更新都会跳过损失函数的最低点，甚至跳到更高、更陡峭的位置，导致损失函数 \(J(\theta)\) 不断增大。&lt;/td&gt;
      &lt;td&gt;❌ &lt;strong&gt;模型无法收敛&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;过小&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Small \(\alpha\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;收敛缓慢 (Slow Convergence)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;步长太小，需要极多的迭代次数才能到达最低点。模型训练时间过长，计算资源消耗大。&lt;/td&gt;
      &lt;td&gt;⚠️ &lt;strong&gt;训练效率低下&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;适中&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Optimal \(\alpha\)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;平稳且高效收敛&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;步长恰到好处，每次更新都能显著减小损失 \(J(\theta)\)，并平稳地向全局最小值收敛。&lt;/td&gt;
      &lt;td&gt;✅ &lt;strong&gt;最优选择&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;在实际应用中，没有一个“万能”的学习率，最佳的学习率取决于具体的数据集和损失函数曲面的形状。&lt;/p&gt;

&lt;p&gt;可以从一个合理范围的数值开始尝试：&lt;strong&gt;常用起始值：&lt;/strong&gt; \(0.1, 0.01, 0.001, 0.0001\)。&lt;/p&gt;

&lt;p&gt;学习率退火 (Learning Rate Scheduling / Decay)，在训练过程中动态调整学习率是一种高级策略：在训练初期，使用&lt;strong&gt;较大的学习率&lt;/strong&gt;快速接近最优区域；在训练后期，&lt;strong&gt;逐渐减小学习率&lt;/strong&gt;（“退火”）以实现更精细的搜索，避免在最低点附近来回震荡，确保稳定收敛。每隔一定数量的 Epoch（轮次）或迭代次数，将 $\alpha$ 乘以一个固定因子（如 0.5）。或者指数衰减。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;解析解的存在性与计算可行性&quot;&gt;解析解的存在性与计算可行性&lt;/h2&gt;

&lt;p&gt;在线性回归中，直接求解最优参数 \(w\) 和 \(b\) 的方法是利用&lt;strong&gt;正规方程（Normal Equation）&lt;/strong&gt;，这是一种&lt;strong&gt;解析解法&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;对于线性回归的 MSE 损失函数，最优参数 \(\mathbf{\theta}^*\) 的正规方程解为：&lt;/p&gt;

\[\mathbf{\theta}^* = (\mathbf{X}^{\text{T}}\mathbf{X})^{-1}\mathbf{X}^{\text{T}}\mathbf{y}\]

&lt;p&gt;我们之前已经证明，MSE 损失函数是一个凸函数，其全局最小值是唯一（或构成一个平面）。这个解析解正是这个全局最小值。&lt;strong&gt;所以，解是存在的。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;数学上不可能无解，但是指在&lt;strong&gt;计算上不可行或效率极低&lt;/strong&gt;（\(n\) 过大导致“解不出”的计算瓶颈）&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;矩阵求逆的计算量与特征维度的&lt;strong&gt;三次方&lt;/strong&gt;成正比。&lt;/p&gt;

  &lt;p&gt;对于数百万、数十亿样本（\(n\) 很大）或数万特征（\(d\) 很大）的现代大数据集，正规方程法因为 \(O(d^3)\) 的复杂度，几乎无法在合理时间内完成计算。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;度下降法（以及其变种 SGD/Mini-Batch GD）通过将复杂问题分解为&lt;strong&gt;多次高效的 \(O(nd)\) 或更低复杂度的迭代更新&lt;/strong&gt;，有效规避了求逆的瓶颈，成为大数据和高维场景下求解最优参数的首选方法。&lt;/p&gt;

&lt;h1 id=&quot;3梯度下降的分类&quot;&gt;3.梯度下降的分类&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;批量梯度下降 (Batch Gradient Descent, BGD)：在计算梯度 \(\nabla J(\mathbf{\theta})\) 时，使用&lt;strong&gt;全部&lt;/strong&gt;训练数据（即整个批次，或 Batch）。每次更新都需要遍历整个数据集。当数据集 \(n\) 非常大时，计算成本高，速度慢。此外，大批量计算可能占用大量内存。&lt;/li&gt;
&lt;/ul&gt;

\[\nabla J(\mathbf{\theta}) = \frac{1}{n} \sum_{i=1}^{n} \nabla J_i(\mathbf{\theta})\]

&lt;ul&gt;
  &lt;li&gt;随机梯度下降 (Stochastic Gradient Descent, SGD):在计算梯度 \(\nabla J(\mathbf{\theta})\) 时，每次迭代只随机抽取&lt;strong&gt;一个&lt;/strong&gt;样本来估计梯度。梯度估计具有较大的&lt;strong&gt;随机性/噪声&lt;/strong&gt;，导致收敛路径剧烈震荡。虽然最终会收敛到最小值附近，但通常不会精确停在最小值点，而是在附近&lt;strong&gt;徘徊&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

\[\nabla J(\mathbf{\theta}) \approx \nabla J_i(\mathbf{\theta})\]

&lt;ul&gt;
  &lt;li&gt;小批量梯度下降 (Mini-Batch Gradient Descent, MBGD):在计算梯度 \(\nabla J(\mathbf{\theta})\) 时，每次迭代使用一个&lt;strong&gt;小批量（Mini-Batch）&lt;/strong&gt;的样本子集（通常大小在 32 到 512 之间，一般为2的幂次）。需要调整超参数“批量大小”（Batch Size）。&lt;/li&gt;
&lt;/ul&gt;

\[\nabla J(\mathbf{\theta}) = \frac{1}{m} \sum_{i=1}^{m} \nabla J_i(\mathbf{\theta})\]

&lt;p&gt;其中 \(m\) 是小批次的大小，且 \(1 &amp;lt; m &amp;lt; n\)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;机器学习实践中做决策的核心——&lt;strong&gt;权衡（Trade-off）&lt;/strong&gt;。&lt;/p&gt;

  &lt;p&gt;如果&lt;strong&gt;数据量大且资源有限&lt;/strong&gt;，选择 &lt;strong&gt;MBGD&lt;/strong&gt; 或 &lt;strong&gt;SGD&lt;/strong&gt;，这意味着&lt;strong&gt;权衡了&lt;/strong&gt;收敛的微小不稳定性和噪声，来换取&lt;strong&gt;更高的训练速度和内存效率&lt;/strong&gt;。&lt;/p&gt;

  &lt;p&gt;如果&lt;strong&gt;数据量小且对最终参数精度要求极高&lt;/strong&gt;，可能会选择 &lt;strong&gt;BGD&lt;/strong&gt;，这意味着&lt;strong&gt;权衡了&lt;/strong&gt;训练速度较慢的劣势，来换取&lt;strong&gt;最高的稳定性&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;下面就是利用实际的例子说明不同的梯度下降策略，对于最优值w的影响：&lt;/p&gt;

&lt;p&gt;实现一个通用的梯度下降函数，并通过调整 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;batch_size&lt;/code&gt; 来模拟 BGD、SGD 和 MBGD&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LinearRegression&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 用于找到理论最优解
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Matplotlib 绘图设置 (用于显示中文)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;font.sans-serif&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;SimHei&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;axes.unicode_minus&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# -----------------------------------------------------------
# 步骤 1: 模拟数据和最优参数 (请用您的实际 X 和 y 替换)
# -----------------------------------------------------------
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 500 个样本
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 真实模型: y = 5 + 3*X + 噪声
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 使用 sklearn 找到理论最优解
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimal_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LinearRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;w_star&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimal_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b_star&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimal_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept_&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;理论最优参数 w*: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_star&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, b*: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_star&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# -----------------------------------------------------------
# 步骤 2: 通用梯度下降实现
# -----------------------------------------------------------
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;custom_gradient_descent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    运行梯度下降并记录参数 w 的变化路径。
    batch_size = n_samples -&amp;gt; BGD
    batch_size = 1        -&amp;gt; SGD
    batch_size = 32       -&amp;gt; MBGD
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 初始参数 w
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 初始参数 b
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;w_history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# 每次 Epoch 重新打乱数据，对 SGD/MBGD 尤其重要
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;X_shuffled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y_shuffled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;X_shuffled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y_shuffled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
            
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# 提取当前批次数据
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;X_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_shuffled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_shuffled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;m_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# 预测值
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# 计算梯度 (仅针对当前批次)
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_batch&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# 更新参数
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;w_history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_history&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# -----------------------------------------------------------
# 步骤 3: 运行三种策略
# -----------------------------------------------------------
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 统一参数设置 (不同的学习率和迭代次数可能需要调整以获得最佳展示效果)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_EPOCHS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;LEARNING_RATE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.005&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 适用于 BGD/MBGD
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LR_SGD&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0005&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# SGD 通常需要较小的学习率来减缓震荡
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 1. 批量梯度下降 (BGD)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_history_bgd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;custom_gradient_descent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LEARNING_RATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_EPOCHS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 2. 小批量梯度下降 (MBGD) - 常用 Batch Size = 32
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_history_mbgd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;custom_gradient_descent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LEARNING_RATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_EPOCHS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 3. 随机梯度下降 (SGD) - Batch Size = 1
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_history_sgd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;custom_gradient_descent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LR_SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_EPOCHS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# -----------------------------------------------------------
# 步骤 4: 画图展示 w 的收敛路径
# -----------------------------------------------------------
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 绘制三种策略的 w 历史路径
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_history_bgd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;BGD (Batch Gradient Descent)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;blue&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_history_mbgd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;MBGD (Mini-Batch Gradient Descent, Batch=32)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;orange&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_history_sgd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;SGD (Stochastic Gradient Descent)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;red&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 绘制理论最优值 w*
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;axhline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_star&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;green&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;理论最优解 $w^*$=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_star&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;不同梯度下降策略下参数 $w$ 的寻优路径 (迭代次数=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_EPOCHS&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; Epochs)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;参数更新次数 (Iterations)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;权重参数 $w$ 的值&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_star&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_star&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 聚焦于收敛区域
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027155327675.png&quot; alt=&quot;image-20251027155327675&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;牺牲梯度准确性（减小 Batch Size）可以显著增加参数更新次数&lt;/strong&gt;（SGD 的红线迭代次数远多于 BGD 的蓝线），从而加快训练速度，但代价是&lt;strong&gt;路径的剧烈震荡&lt;/strong&gt;。在实际工程中，&lt;strong&gt;MBGD&lt;/strong&gt; 提供了最佳的&lt;strong&gt;速度与稳定性的权衡&lt;/strong&gt;。&lt;/p&gt;

&lt;h1 id=&quot;4防止过拟合-有效集与提前停止&quot;&gt;4.防止过拟合-有效集与提前停止&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;数据集划分：&lt;/strong&gt; 训练数据（Train）通常被分成三部分。（一般是随机抽取分为3类）&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;训练集（Train）：&lt;/strong&gt; 用于模型参数的拟合。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;验证集（Valid）：&lt;/strong&gt; 用于模型调优和选择（有效率）。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;测试集（Test）：&lt;/strong&gt; 用于最终评估模型性能。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在训练过程中，如果&lt;strong&gt;验证集（Valid）的mse突然变大了&lt;/strong&gt;，而训练集mse仍在下降，这表明模型开始&lt;strong&gt;过拟合&lt;/strong&gt;训练集数据。此时应采用&lt;strong&gt;提前停止（Early Stopping）&lt;/strong&gt;策略，停止训练。&lt;/p&gt;

&lt;h1 id=&quot;面试题1小批量梯度下降m取值小性价比更高&quot;&gt;面试题1:小批量梯度下降m取值小，性价比更高？&lt;/h1&gt;

&lt;p&gt;小批量梯度下降（MBGD）中，&lt;strong&gt;批量m取值小（但大于 1），往往具有更高的“性价比”&lt;/strong&gt;。这里的性价比是指在&lt;strong&gt;单位计算资源消耗下，获得最高的参数优化效率&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;当计算梯度时，使用的样本 m越多，梯度估计的随机性就越小，越接近全部数据的真实梯度方向。&lt;/p&gt;

&lt;p&gt;梯度方差 \(\text{Var}(\nabla J_m)\) 的下降速度与 \(\frac{1}{\sqrt{m}}\) 相关。&lt;strong&gt;希望方差尽可能小，使参数w的寻优路径稳定。&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;批量 m 变化&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;迭代成本支出变化 (∝m)&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;标准误差 SE 收益变化 (∝1/m)&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;\(m=1 \to m=10\)&lt;/td&gt;
      &lt;td&gt;成本 \(\times 10\)&lt;/td&gt;
      &lt;td&gt;SE 降低 \(1/\sqrt{10} \approx 0.316\) 倍 (约 68.4%)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(m=100 \to m=200\)&lt;/td&gt;
      &lt;td&gt;成本 \(\times 2\)&lt;/td&gt;
      &lt;td&gt;SE 降低 \(1/\sqrt{2} \approx 0.707\) 倍 (约 29.3%)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(m=1000 \to m=2000\)&lt;/td&gt;
      &lt;td&gt;成本 \(\times 2\)&lt;/td&gt;
      &lt;td&gt;SE 降低 \(1/\sqrt{2} \approx 0.707\) 倍 (约 29.3%)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;当m从 1增加到10，需要付出 &lt;strong&gt;10 倍&lt;/strong&gt;的计算成本，换来 &lt;strong&gt;3.16 倍&lt;/strong&gt;的 SE 改善（即 $10 / 3.16 \approx 3.16$ 的效率比）。&lt;/p&gt;

&lt;p&gt;但是，当m从1000增加到2000时，你付出的计算成本&lt;strong&gt;增加了 2 倍&lt;/strong&gt;，而 SE 只改善了 &lt;strong&gt;$\approx 1.414$ 倍&lt;/strong&gt;（即 $2 / 0.707 \approx 1.414$ 的效率比）。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;边际收益递减：&lt;/strong&gt; 随着m的增加，虽然 SE 仍在下降，但 SE 的下降速度（收益）是 \(\mathbf{1/\sqrt{m}}\)，而计算成本（支出）是 \(\mathbf{m}\)，成本的增加速度远快于收益的增加速度。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在优化过程中，我们最关心的是&lt;strong&gt;单次迭代的计算时间&lt;/strong&gt;和&lt;strong&gt;最终收敛所需的迭代次数&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;小m例如32）的性价比高：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在较小的m范围内，&lt;strong&gt;SE 的改善是非常显著且高效的&lt;/strong&gt;。只需付出很小的计算代价，就能将梯度噪声降低到一个可接受的水平，避免 SGD 那样剧烈的震荡。在实际训练中，MBGD 的计算时间（\(\propto m\)）远小于 BGD，最终达到相同精度所需的总训练时间最短。&lt;/li&gt;
  &lt;li&gt;大m的性价比低,计算成本增大了，但总的收敛速度提升不明显。这是典型的&lt;strong&gt;低效率投入&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，根据 \(\mathbf{1/\sqrt{m}}\) 的关系，选择一个能最大化硬件利用率、且 SE 足够小的&lt;strong&gt;较小批量m&lt;/strong&gt;，是获得最高优化性价比的策略。&lt;/p&gt;

&lt;h1 id=&quot;5书籍推荐&quot;&gt;5.书籍推荐&lt;/h1&gt;

&lt;p&gt;1.统计学习方法 第二版 李航&lt;/p&gt;

&lt;p&gt;2.模式分类第2版&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251027212533939.png&quot; alt=&quot;image-20251027212533939&quot; style=&quot;zoom:25%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;3.深度学习  Ian Goodfellow等人&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251027212647529.png&quot; alt=&quot;image-20251027212647529&quot; style=&quot;zoom:25%;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 27 Oct 2025 00:00:00 +0000</pubDate>
        <link>https://kirsten-1.github.io/2025/10/27/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9903/</link>
        <guid isPermaLink="true">https://kirsten-1.github.io/2025/10/27/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9903/</guid>
        
        <category>AI思想启蒙</category>
        
        
      </item>
    
      <item>
        <title>【AI思想启蒙02】线性回归1第一个模型，用来进行数值预测 </title>
        <description>&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG&quot;&gt;
&lt;/script&gt;

&lt;p&gt;上一节：&lt;a href=&quot;https://kirsten-1.github.io/2025/10/26/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9901/&quot;&gt;人工智能概述和特征提取？做人工智能的第一步&lt;/a&gt;中提到：&lt;strong&gt;所有复杂的原始数据（图像、文本、用户）都必须通过&lt;/strong&gt;强业务绑定的&lt;strong&gt;特征工程（向量化）过程，转换为统一的数值向量，才能输入给机器学习模型进行学习和预测。&lt;/strong&gt;即数据 \(\rightarrow\) 向量化 \(\rightarrow\) 模型。&lt;/p&gt;

&lt;p&gt;而学习机器学习，就是学习各种模型，即学习各种传统AI算法。&lt;/p&gt;

&lt;p&gt;这节主要学习线性回归算法。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;首先需要明确线性回归算法的需求：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251026222508972.png&quot; alt=&quot;image-20251026222508972&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/Users/apple/Library/Application Support/typora-user-images/image-20251026222629683.png&quot; alt=&quot;image-20251026222629683&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如图，用于训练模型的数据集（&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;train_data&lt;/code&gt;）共有 &lt;strong&gt;499 个样本&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;线性回归模型的核心需求是利用所有 多个输入-输出数据对 \((x_i, y_i)\)，找到一个最优的线性函数来近似输入 \(x\) 和输出 \(y\) 之间的关系。&lt;/p&gt;

&lt;p&gt;模型表达式:&lt;/p&gt;

\[\hat{y} = w \cdot x + b\]

&lt;p&gt;其中，\(\hat{y}\) 是预测值，\(w\) 是权重，\(b\) 是偏置。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;学习目标:&lt;/strong&gt; 模型的首要需求是&lt;strong&gt;确定（估计）&lt;/strong&gt;最优的参数 \(w\) 和 \(b\)。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;如何找到最优？首先要量化。其次要定义误差。&lt;/p&gt;

&lt;p&gt;线性回归常见的就是用MSE进行误差的计算，公式是&lt;/p&gt;

\[\text{mse} = \frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)^2\]

&lt;p&gt;其中\(\hat{y}_i = w x_i + b\)&lt;/p&gt;

&lt;p&gt;MSE 的值&lt;strong&gt;越小&lt;/strong&gt;，说明模型的预测 \(\hat{y}_i\) 越接近真实值 \(y_i\)，模型的性能越好。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;测试集的误差（MSE）一定大于训练集的误差吗？不是。&lt;/p&gt;

&lt;p&gt;虽然测试集是随机抽样的，但它可能偶然性地包含了&lt;strong&gt;比训练集更接近拟合直线&lt;/strong&gt;的数据点。但是，在真实的环境中，测试集的mse一般大于训练集的mse&lt;/p&gt;

&lt;p&gt;\(\text{MSE}_{\text{Test}} &amp;lt; \text{MSE}_{\text{Train}}\) 是一种&lt;strong&gt;异常现象&lt;/strong&gt;，虽然可能发生，但它通常提示您：您的数据划分可能存在&lt;strong&gt;偶然性&lt;/strong&gt;，或者您的实验设计中可能存在&lt;strong&gt;数据泄露&lt;/strong&gt;问题。&lt;/p&gt;

&lt;p&gt;要使得测试集的MSE小，可以采用：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;训练集变大&lt;/li&gt;
  &lt;li&gt;训练集数据符合真实的环境&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;推广能力（泛化能力）：能在测试集上表现良好的能力&lt;/p&gt;

&lt;h1 id=&quot;面试题1测试集的mse和训练集的mse谁大谁小&quot;&gt;面试题1:&lt;strong&gt;测试集的mse和训练集的mse谁大谁小&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;首先，理论上，测试集的均方误差 (\(\text{MSE}_{\text{Test}}\)) 与训练集的均方误差 (\(\text{MSE}_{\text{Train}}\)) &lt;strong&gt;没有绝对的、统计学的必然大小关系&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;\(\text{MSE}_{\text{Test}} &amp;gt; \text{MSE}_{\text{Train}}\) (常见且合理):&lt;/strong&gt; 这是最常见的情况，表明模型在未见过的数据上性能略有下降，反映了模型的&lt;strong&gt;泛化能力&lt;/strong&gt;。如果差距过大，则表明模型&lt;strong&gt;过拟合&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(\text{MSE}_{\text{Test}} &amp;lt; \text{MSE}_{\text{Train}}\) (可能但罕见):&lt;/strong&gt; 这是可能的，通常是由于&lt;strong&gt;数据随机性&lt;/strong&gt;或&lt;strong&gt;统计巧合&lt;/strong&gt;。测试集可能恰好抽样到了比训练集更接近真实关系的数据点，使得模型在其上的表现更好。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其次，在实际的机器学习工程项目中，我们通常观察到的结果是：&lt;strong&gt;测试集的 MSE 大于训练集的 MSE&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;模型的训练过程（优化算法）被设计为&lt;strong&gt;最小化训练集上的误差&lt;/strong&gt;。模型所有参数的调整都以这个目标为依归。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;工程抽样:&lt;/strong&gt; 虽然理论上存在 \(\text{MSE}_{\text{Test}} &amp;lt; \text{MSE}_{\text{Train}}\) 的可能性，但在实际的、拥有大量数据和合理划分的工程实践中，很难稳定地采样到这种“测试集更容易”的情况(概率很低)。因此，&lt;strong&gt;经验上&lt;/strong&gt;，&lt;strong&gt;\(\text{MSE}_{\text{Test}} \ge \text{MSE}_{\text{Train}}\)&lt;/strong&gt; 是常态。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当观察到 \(\text{MSE}_{\text{Test}}\) &lt;strong&gt;显著大于&lt;/strong&gt; \(\text{MSE}_{\text{Train}}\)（即模型过拟合）时，主要的解决思路是提高模型的泛化能力。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;增大训练集，增加训练集的多样性:&lt;/strong&gt; 引入更多、更具有代表性的数据，让模型能够学习到更&lt;strong&gt;普遍&lt;/strong&gt;的规律，而不是只记住现有训练集的噪声和细节。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;其他常用方法（补充）:&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;正则化:&lt;/strong&gt; 在损失函数中加入惩罚项（如 L2正则化Ridge/L1正则化Lasso），限制模型参数的复杂性。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;特征选择/降维:&lt;/strong&gt; 减少输入特征的数量，降低模型复杂度。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;提前停止 (Early Stopping):&lt;/strong&gt; 在验证集误差开始上升时，就停止训练。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;面试题2感性分析为什么mse是平方项而不是绝对值&quot;&gt;面试题2:感性分析为什么MSE是平方项而不是绝对值&lt;/h1&gt;

&lt;h2 id=&quot;模型注意力转移&quot;&gt;模型“注意力”转移&lt;/h2&gt;

&lt;p&gt;下面详细解释为什么在回归问题中，均方误差（MSE，即误差的平方）比绝对值误差（MAE，即误差的绝对值）更常被使用，特别是从模型“注意力”转移的角度进行解释。&lt;/p&gt;

&lt;p&gt;一堆数据点，有些难预测，有些容易预测&lt;/p&gt;

\[(y - \hat{y})^2\]

&lt;p&gt;把容易预测的MSE降低到一定程度后，再在容易点上优化，收益就变小了。那注意力就会转移到难预测的焦点上&lt;/p&gt;

&lt;p&gt;如果用绝对值误差，收益永远不变，注意力就总在容易预测的焦点上了&lt;/p&gt;

&lt;p&gt;核心原因在于：&lt;strong&gt;平方惩罚（MSE）会随着误差的增大而加速增大，这使得模型“更关注”那些预测得很差的“难点”&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;比较误差的平方（MSE）和误差的绝对值（MAE）。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;真实误差&lt;/th&gt;
      &lt;th&gt;|y - ŷ|&lt;/th&gt;
      &lt;th&gt;平方误差 (MSE)&lt;/th&gt;
      &lt;th&gt;绝对值误差 (MAE)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;小误差 (例如 0.1)&lt;/td&gt;
      &lt;td&gt;0.1&lt;/td&gt;
      &lt;td&gt;0.1² = 0.01&lt;/td&gt;
      &lt;td&gt;|0.1| = 0.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;大误差 (例如 10)&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;10² = 100&lt;/td&gt;
      &lt;td&gt;|10| = 10&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;模型训练初期，模型的预测普遍较差，大误差很多。此时，模型计算出的总 \(\text{MSE}\) 会非常大，因为大误差被&lt;strong&gt;平方&lt;/strong&gt;放大了（ 10变成了100）。&lt;/p&gt;

&lt;p&gt;模型优化阶段，模型首先会快速修正那些大误差的点（&lt;strong&gt;“难预测的点”&lt;/strong&gt;），因为修正它们可以使MSE快速、大幅度地下降，&lt;strong&gt;收益最大&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;所以模型训练后期，难预测的点被修正得差不多了。&lt;/p&gt;

&lt;p&gt;如果使用绝对值误差（MAE），惩罚与误差是&lt;strong&gt;线性&lt;/strong&gt;关系。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;惩罚一致性：&lt;/strong&gt; 无论是将一个大误差10修正到9，还是将一个小误差0.1修正到0，对总MSE带来的&lt;strong&gt;下降值&lt;/strong&gt;是差不多的（都是 1或 0.1）。&lt;/li&gt;
  &lt;li&gt;模型会发现，优化那些&lt;strong&gt;容易预测&lt;/strong&gt;的点（通常意味着它们离拟合线已经很近，优化成本低）和优化那些&lt;strong&gt;难预测&lt;/strong&gt;的点（优化成本高）的&lt;strong&gt;收益是相对恒定且均衡的&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;模型的“注意力”可能总是在那些容易优化的点上打转，因为它可以在这些点上以较低的代价获得与修正难点一样的收益。这可能导致模型&lt;strong&gt;不愿冒险&lt;/strong&gt;去修正那些与现有拟合线偏差很大的&lt;strong&gt;难预测的点&lt;/strong&gt;，使它们长期保持较大的残差。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;平方误差（MSE）的关键作用在于其&lt;strong&gt;非线性惩罚机制&lt;/strong&gt;：它对大误差的惩罚不成比例地加大，强制模型优先关注并修正最严重的预测错误（难预测的点），从而确保模型的拟合结果能照顾到所有数据点，避免少数几个异常值被模型完全忽视。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;下面是代码，可以论证上面的结论：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_step_pow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.03&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_step_abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.03&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;if &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cal_data_error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# First parameter is w, second is the number of data points
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_step_pow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# MSE training
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_step_abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# MAE training
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;代码中，有2类点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;主体数据 (10 个样本)：&lt;/strong&gt; 由 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;get_data(10, 10)&lt;/code&gt; 生成，它们遵循模型 \(y = 10x\)。&lt;strong&gt;目标最优解 \(w^*\) 是 10。&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;异常值/离群点 (2 个样本)：&lt;/strong&gt; 由 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;get_data(6, 2)&lt;/code&gt; 生成，它们遵循模型 \(y = 6x\)。这些样本是相对于主体数据的&lt;strong&gt;强离群点&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;模型必须在主体数据 \(w=10\) 和异常值 \(w=6\) 之间做出权衡。由于主体数据占 \(10/12 \approx 83.3\%\)，最优的妥协解  \(w^*\)应该非常接近10，但会略微偏向6。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;train_step_pow&lt;/code&gt; (对应 MSE 损失,是平方项)&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;train_step_abs&lt;/code&gt; (对应 MAE 损失,是绝对值项)&lt;/p&gt;

&lt;p&gt;运行这段代码的结果如下：(每次运行会有区别，但是可以看到大体趋势)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027171951623.png&quot; alt=&quot;image-20251027171951623&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;发现，\(w1\)（MSE 训练结果）通常会收敛到9点多，明显小于10。&lt;/p&gt;

&lt;p&gt;\(w2\)（MAE 训练结果）通常会收敛到非常接近10的值，甚至可能在10附近震荡。&lt;/p&gt;

&lt;p&gt;这就是因为MSE 对异常值&lt;strong&gt;非常敏感&lt;/strong&gt;，它会&lt;strong&gt;过度惩罚&lt;/strong&gt;离群点。大误差会被平方放大，这意味着离群点的大误差会产生&lt;strong&gt;巨大的梯度&lt;/strong&gt;，将最优解 \(w\) &lt;strong&gt;强行拉向&lt;/strong&gt;离群点 \(w=6\) 的方向。为了平衡离群点的巨大损失，模型牺牲了主体数据的拟合精度，将最终的 \(w1\) &lt;strong&gt;从10拉低&lt;/strong&gt;到9左右。&lt;/p&gt;

&lt;p&gt;MAE 对异常值&lt;strong&gt;具有鲁棒性&lt;/strong&gt;，它更关注大多数样本。无论离群点的误差是 \(4x\) 还是 \(40x\)，它产生的梯度大小都是较为固定的。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;尽管在这个有离群值的案例中，MAE（绝对值项）得到了更接近&lt;strong&gt;真实主体数据&lt;/strong&gt;的最优解，但在更一般的机器学习应用中，&lt;strong&gt;MSE（平方项）仍然是默认的首选&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;MSE 的平方项使得损失函数是一个&lt;strong&gt;处处可导的凸函数&lt;/strong&gt;，为梯度下降等优化算法提供了&lt;strong&gt;最理想、最平滑的数学环境&lt;/strong&gt;，保证了收敛的稳定性和速度。只有当数据中存在大量已知的、需要忽略的异常值时，才会考虑使用 MAE。&lt;/p&gt;

&lt;h2 id=&quot;求导不可导&quot;&gt;求导不可导&lt;/h2&gt;

&lt;p&gt;平方项是一个&lt;strong&gt;处处可导（Differentiable Everywhere）&lt;/strong&gt;的平滑函数。它的导数在整个参数空间内都是连续的。&lt;/p&gt;

&lt;p&gt;当误差很大时，梯度也很大，参数更新的步长就大（移动快）。&lt;/p&gt;

&lt;p&gt;当误差很小时，梯度也趋于零，参数更新的步长就小（移动慢）。&lt;/p&gt;

&lt;p&gt;梯度下降法等基于梯度的优化算法依赖于损失函数在每一点上都能求出明确且唯一的梯度。MSE 完美地满足了这一点，保证了算法的稳定和高效收敛。&lt;/p&gt;

&lt;p&gt;当误差 \(y_i - \hat{y}_i\) 恰好等于0时（即模型预测完美），绝对值函数在该点是不可导的。在多维参数空间中，这会在损失曲面上形成一个尖锐的棱（而非平滑的底部）。&lt;/p&gt;

&lt;p&gt;因此，选择 MSE 作为线性回归的损失函数，主要是因为它是一个&lt;strong&gt;处处可导且平滑的凸函数&lt;/strong&gt;，这使得基于微积分的优化方法（如梯度下降法）能够高效、稳定、精确地找到全局最优解。&lt;/p&gt;

</description>
        <pubDate>Mon, 27 Oct 2025 00:00:00 +0000</pubDate>
        <link>https://kirsten-1.github.io/2025/10/27/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9902/</link>
        <guid isPermaLink="true">https://kirsten-1.github.io/2025/10/27/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9902/</guid>
        
        <category>AI思想启蒙</category>
        
        
      </item>
    
  </channel>
</rss>
