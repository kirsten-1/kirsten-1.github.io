<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
    <meta name="description" content="这里是 Hilda 的个人博客，与你一起发现更大的世界 | 要做一个有 swag 的程序员">
    <meta name="keywords" content="Hilda">
    <meta name="theme-color" content="#000000">

    <!-- Open Graph -->
    <meta property="og:title"
        content="【AI思想启蒙09】逻辑回归5让学习更高效，数值优化和一只看不见的手  - Hilda的博客 | Your genius girlfriend's blog">
    
    <meta property="og:type" content="article">
    <meta property="og:description" content="

">
    
    <meta property="article:published_time" content=" 2025-11-21T00:00:00Z">
    
    
    <meta property="article:author" content="Hilda">
    
    
    <meta property="article:tag" content="AI思想启蒙">
    
    
    <meta property="og:image" content="https://kirsten-1.github.io">
    <meta property="og:url" content="https://kirsten-1.github.io/2025/11/21/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9909/">
    <meta property="og:site_name" content="Hilda的博客 | Your genius girlfriend's blog">

    <title>【AI思想启蒙09】逻辑回归5让学习更高效，数值优化和一只看不见的手  - Hilda的博客 | Your genius girlfriend's blog</title>

    <!-- Web App Manifest -->
    <link rel="manifest" href="/pwa/manifest.json">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/favicon.ico">

    <!-- Canonical URL -->
    <link rel="canonical" href="https://kirsten-1.github.io/2025/11/21/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9909/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href=" /css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href=" /css/hux-blog.min.css">

    <!-- Custom Fonts -->
    <!-- <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet"
        type="text/css">


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>

    <!-- Google AdSense -->
    <script data-ad-client="ca-pub-6487568398225121" async
        src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Navigation -->

    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="/">Hilda</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div id="huxblog_navbar">
                <div class="navbar-collapse">
                    <ul class="nav navbar-nav navbar-right">
                        <li>
                            <a href="/">Home</a>
                        </li>
                        
                        
                        
                        
                        <li>
                            <a href="/about/">About</a>
                        </li>
                        
                        
                        
                        <li>
                            <a href="/archive/">Archive</a>
                        </li>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <li class="search-icon">
                            <a href="javascript:void(0)">
                                <i class="fa fa-search"></i>
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <script>
        // Drop Bootstarp low-performance Navbar
        // Use customize navbar with high-quality material design animation
        // in high-perf jank-free CSS3 implementation
        var $body = document.body;
        var $toggle = document.querySelector('.navbar-toggle');
        var $navbar = document.querySelector('#huxblog_navbar');
        var $collapse = document.querySelector('.navbar-collapse');

        var __HuxNav__ = {
            close: function () {
                $navbar.className = " ";
                // wait until animation end.
                setTimeout(function () {
                    // prevent frequently toggle
                    if ($navbar.className.indexOf('in') < 0) {
                        $collapse.style.height = "0px"
                    }
                }, 400)
            },
            open: function () {
                $collapse.style.height = "auto"
                $navbar.className += " in";
            }
        }

        // Bind Event
        $toggle.addEventListener('click', function (e) {
            if ($navbar.className.indexOf('in') > 0) {
                __HuxNav__.close()
            } else {
                __HuxNav__.open()
            }
        })

        /**
         * Since Fastclick is used to delegate 'touchstart' globally
         * to hack 300ms delay in iOS by performing a fake 'click',
         * Using 'e.stopPropagation' to stop 'touchstart' event from 
         * $toggle/$collapse will break global delegation.
         * 
         * Instead, we use a 'e.target' filter to prevent handler
         * added to document close HuxNav.  
         *
         * Also, we use 'click' instead of 'touchstart' as compromise
         */
        document.addEventListener('click', function (e) {
            if (e.target == $toggle) return;
            if (e.target.className == 'icon-bar') return;
            __HuxNav__.close();
        })
    </script>
    <!-- Search -->
<div class="search-page">
  <div class="search-icon-close-container">
    <span class="search-icon-close">
      <i class="fa fa-chevron-down"></i>
    </span>
  </div>
  <div class="search-main container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <form></form>
        <input type="text" id="search-input" placeholder="$ grep...">
        </form>
        <div id="search-results" class="mini-post-list"></div>
      </div>
    </div>
  </div>
</div>

    <!-- Image to hack wechat -->
<!-- <img src="/img/icon_wechat.png" width="0" height="0"> -->
<!-- <img src="/img/post-bg-2015.jpg" width="0" height="0"> -->

<!-- Post Header -->



<style type="text/css">
    header.intro-header{
        position: relative;
        background-image: url('/img/post-bg-2015.jpg');
        background: ;
    }

    
</style>




<header class="intro-header" >

    <div class="header-mask"></div>
    
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/archive/?tag=AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%99" title="AI思想启蒙">AI思想启蒙</a>
                        
                    </div>
                    <h1>【AI思想启蒙09】逻辑回归5让学习更高效，数值优化和一只看不见的手 </h1>
                    
                    <h2 class="subheading">Z-score标准化解决梯度尺度不一致、加速收敛；从同方差高斯+贝叶斯生成模型推导出逻辑回归与LDA等价；再由最大似然估计自然得到BCE损失本质为负对数似然</h2>
                    <span class="meta">Posted by Hilda on November 21, 2025</span>
                </div>
            </div>
        </div>
    </div>
</header>







<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <!-- Multi-Lingual -->
                

				<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG">
</script>

<h1 id="1特征缩放-z-score标准化归一化">1.特征缩放-Z-score标准化/归一化</h1>

<p>回顾逻辑回归的损失函数，及其导数：</p>

<table>
  <tbody>
    <tr>
      <td>损失函数是BCE：$$\mathcal{L}_{\text{BCE}}(P</td>
      <td> </td>
      <td>Q) = - \sum_{k \in {0, 1}} P(Y=k) \log Q(Y=k) = - [y \log \hat{y} + (1 - y) \log (1 - \hat{y})]=\ \sum_{i=1}^{n} \left[ y_i \log \frac{y_i}{f_i} + (1 - y_i) \log \frac{1 - y_i}{1 - f_i} \right]$$</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>导数：损失函数 $$\mathcal{L}_{\text{BCE}}(P</td>
      <td> </td>
      <td>Q)\(对权重向量\)\mathbf{w}\(中任一分量\)w_j\(的偏导数\)\frac{\partial L_i}{\partial w_j}$$：</td>
    </tr>
  </tbody>
</table>

\[\frac{\partial L_i}{\partial w_j} = - (y_i - \hat{y}_i) x_{i,j} = (\hat{y}_i - y_i) x_{i,j}\]

<p>总体损失梯度如下：</p>

<p>对于整个训练集（所有 \(N\) 个样本），总损失 \(L(\mathbf{w}) = \frac{1}{N} \sum_{i=1}^{N} L_i(\mathbf{w})\) 对 \(w_j\) 的梯度为：</p>

\[\frac{\partial L}{\partial w_j} = \frac{1}{N} \sum_{i=1}^{N} \frac{\partial L_i}{\partial w_j} = \frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i - y_i) x_{i,j}\]

<hr />

<p>梯度下降：对单个权重 \(w_j\) 的更新:</p>

\[w_{j, \text{new}} = w_{j, \text{old}} - \alpha \cdot \frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i - y_i) x_{i,j}\]

<p>如果特征都是大于0的取值，根据梯度下降的式子，参数\(w\)只会越来越小。反之如果特征都是小于0的数值，参数只会越来越大。如果用4个象限的等高线描述梯度下降的过程，那么梯度只会往第一象限/第三象限走。此时就会使得收敛过程发生巨大的震荡。</p>

<p>这些都属于<strong>未归一化/未标准化特征</strong>在梯度下降优化过程中的<strong>效率和稳定性</strong>问题。<strong>特征尺度的不一致或不平衡，会导致损失函数的等高线变得极度扁平狭长，使得梯度下降路径低效且震荡。</strong></p>

<p>解决这个问题的最优方案是使用 <strong>特征缩放（Feature Scaling）</strong>，特别是 <strong>Z-Score 归一化（标准化）</strong>。</p>

<p>每个特征 \(x_j\) 转换为标准正态分布，使其均值 \(\mu=0\)，标准差 \(\sigma=1\)。</p>

\[x_{\text{new}} = \frac{x - \mu}{\sigma}\]

<p>这是最推荐的解决方案，尤其适用于基于梯度下降的线性模型（如逻辑回归）和神经网络。</p>

<p>当然也可以用Min-Max 归一化 (Normalization)，但是Min-Max 归一化对异常值很敏感。</p>

<p><img src="https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251121003720143.png" alt="image-20251121003720143" /></p>

<h1 id="2逻辑回归的总结">2.逻辑回归的总结</h1>

<p>1.sigmoid伯努利分布   特殊的softmax（多项分布）</p>

<p>2.BCE  不用MSE</p>

<p>3.L1/L2正则</p>

<p>4.归一化</p>

<p>5.指标  ： 准确率/召回率/查准率/AUC-ROC</p>

<h1 id="3先验条件">3.先验条件</h1>

<p>一元高斯分布（Univariate Gaussian Distribution），也称为<strong>一维正态分布</strong>，其概率密度函数（Probability Density Function, PDF）为：</p>

<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20251121004636434.png" alt="image-20251121004636434" style="zoom: 33%;" /></p>

\[f(x | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x - \mu)^2}{2\sigma^2}}\]

<p>其中：</p>

<ul>
  <li>\(x\) 是随机变量的取值。</li>
  <li>\(\mu\) 是分布的<strong>均值</strong>（Mean），决定了分布的中心位置。</li>
  <li>\(\sigma^2\) 是分布的<strong>方差</strong>（Variance），决定了分布的形状，即数据的分散程度。\(\sigma\)越大，越分散。</li>
  <li>\(\sigma\) 是标准差（Standard Deviation）。</li>
  <li>\(\frac{1}{\sqrt{2\pi\sigma^2}}\) 是归一化常数，确保概率密度函数在整个实数域上的积分为 $1$。</li>
</ul>

<hr />

<p>相对论的成功在于它基于最少的公理，得到了最大的推论，构建了一个自洽的宇宙模型。</p>

<p>即：假设（公理）—-&gt;推论</p>

<p>机器学习中，这个假设（公理）就是：<strong>对于某一类来说，分布符合正态分布</strong></p>

<blockquote>
  <p>其实严格来说，判别模型（逻辑回归/softmax回归等）应该符合的是伯努利分布/多项分布（统称为指数族分布）。</p>
</blockquote>

<h1 id="4贝叶斯公式与高斯分布的结合">4.贝叶斯公式与高斯分布的结合</h1>

<p>贝叶斯公式是所有生成模型的理论基础。</p>

\[P(y|x) = \frac{P(x|y) \cdot P(y)}{P(x)} \quad \text{（后验概率）}\]

<p>例如身高判断 \(x=170\) 是男还是女</p>

<table>
  <tbody>
    <tr>
      <td>**$$P(y=1</td>
      <td>x)\(：** 在已知身高\)x$$ 的情况下，是<strong>男</strong>的概率。</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>**$$P(y=0</td>
      <td>x)\(：** 在已知身高\)x$$ 的情况下，是<strong>女</strong>的概率。</td>
    </tr>
  </tbody>
</table>

<p>由于 \(P(x)\) 对两个类别的比较是相同的，我们只需要比较<strong>分子</strong>：</p>

<table>
  <tbody>
    <tr>
      <td>选择$$\quad y = \arg\max_{y \in {\text{男}, \text{女}}} \left{ P(x=170</td>
      <td>y) \cdot P(y) \right}$$</td>
    </tr>
  </tbody>
</table>

<p>还有已知条件：</p>

<p>\(P(y=\text{男}) + P(y=\text{女}) = 1\)，这是先验概率 (Prior Probability)。</p>

<table>
  <tbody>
    <tr>
      <td>在观察到特定数据 \(x\)（例如，身高 \(x=170\)）之后，其对应的后验概率之和也必须为 1：$$P(y=\text{男}</td>
      <td>x=170) + P(y=\text{女}</td>
      <td>x=170) = 1$$</td>
    </tr>
  </tbody>
</table>

<hr />

<p>假设特征 \(x\) 在每个类别下服从<strong>正态分布</strong>（高斯分布），另外假设<strong>方差 \(\sigma^2\) 相等</strong>，即两个类别（\(y=1\) 和 \(y=0\)）的方差相等，即 \(\sigma_1^2 = \sigma_0^2 = \sigma^2\)。</p>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>类别 \(y=1\) 的分布：$$P(x</td>
          <td>y=1) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x - \mu_1)^2}{2\sigma^2}}$$</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>类别 \(y=0\) 的分布：$$P(x</td>
          <td>y=0) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x - \mu_0)^2}{2\sigma^2}}$$</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<table>
  <tbody>
    <tr>
      <td>计算两个类别似然项的比值 $$\frac{P(x</td>
      <td>y=1)}{P(x</td>
      <td>y=0)}$$：</td>
    </tr>
  </tbody>
</table>

\[\frac{P(x|y=1)}{P(x|y=0)} = \frac{\frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x - \mu_1)^2}{2\sigma^2}}}{\frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x - \mu_0)^2}{2\sigma^2}}}\]

<p>由于 \(\sigma^2\) 相等，系数 \(\frac{1}{\sqrt{2\pi\sigma^2}}\) 被抵消：</p>

\[\frac{P(x|y=1)}{P(x|y=0)} = e^{-\frac{1}{2\sigma^2} \left[ (x - \mu_1)^2 - (x - \mu_0)^2 \right]}\]

<p>化简指数上的项 \((x - \mu_1)^2 - (x - \mu_0)^2\) 的负值：</p>

\[\begin{aligned} \text{指数项} &amp;= -(x - \mu_1)^2 + (x - \mu_0)^2 \\ &amp;= - (x^2 - 2x\mu_1 + \mu_1^2) + (x^2 - 2x\mu_0 + \mu_0^2) \\ &amp;= -x^2 + 2x\mu_1 - \mu_1^2 + x^2 - 2x\mu_0 + \mu_0^2 \\ &amp;=  (2x\mu_1 - 2x\mu_0) + (\mu_0^2 - \mu_1^2) \\ &amp;= 2x(\mu_1 - \mu_0) + (\mu_0^2 - \mu_1^2) \end{aligned}\]

<p>将化简后的结果代回似然比的指数：</p>

\[\log \left( \frac{P(x|y=1)}{P(x|y=0)} \right) = \frac{1}{2\sigma^2} \left[ 2x(\mu_1 - \mu_0) + (\mu_0^2 - \mu_1^2) \right]\]

<table>
  <tbody>
    <tr>
      <td>最终目标是后验概率 $$P(y=1</td>
      <td>x)$$。在贝叶斯公式中：</td>
    </tr>
  </tbody>
</table>

\[\frac{P(y=1|x)}{P(y=0|x)} = \frac{P(x|y=1) P(y=1)}{P(x|y=0) P(y=0)} = \left( \frac{P(x|y=1)}{P(x|y=0)} \right) \cdot \left( \frac{P(y=1)}{P(y=0)} \right)\]

<p>取对数，得到<strong>对数几率 (Log-Odds)</strong>：</p>

\[\log \left( \frac{P(y=1|x)}{P(y=0|x)} \right) = \log \left( \frac{P(x|y=1)}{P(x|y=0)} \right) + \log \left( \frac{P(y=1)}{P(y=0)} \right)\]

<p>将结果代入：</p>

\[\log \left( \frac{P(y=1|x)}{P(y=0|x)} \right) = \underbrace{\left[ \frac{1}{\sigma^2} (\mu_1 - \mu_0) \right]}_{W} x + \underbrace{\left[ \frac{1}{2\sigma^2} (\mu_0^2 - \mu_1^2) + \log \left( \frac{P(y=1)}{P(y=0)} \right) \right]}_{W_0}\]

<p>模型的对数几率被表示成了特征 \(x\) 的<strong>线性函数</strong> \(W x + W_0\)。</p>

\[\log \left( \frac{P(y=1|x)}{P(y=0|x)} \right) = W x + W_0 = \mathbf{z}\]

<p>两边同时取 \(e\) 的指数：</p>

\[\frac{P(y=1|x)}{P(y=0|x)} = e^{\mathbf{z}}\]

<p>在二分类问题中，事件 \(y=1\) 和 \(y=0\) 是互斥且穷尽的，因此它们的概率之和必须为 1：</p>

\[P(y=1|x) + P(y=0|x) = 1\]

<p>从上式可得：</p>

\[P(y=0|x) = 1 - P(y=1|x)\]

<p>代入：</p>

\[\frac{P(y=1|x)}{1 - P(y=1|x)} = e^{\mathbf{z}}\]

<table>
  <tbody>
    <tr>
      <td>现在开始代数求解 $$P(y=1</td>
      <td>x)\(（设\)\hat{y} = P(y=1</td>
      <td>x)$$ 方便书写）：</td>
    </tr>
  </tbody>
</table>

\[\frac{\hat{y}}{1 - \hat{y}} = e^{\mathbf{z}}\]

\[\hat{y} = e^{\mathbf{z}} (1 - \hat{y})\]

\[\hat{y} = e^{\mathbf{z}} - \hat{y} e^{\mathbf{z}}\]

<p>将包含 \(\hat{y}\) 的项移到等式左侧：</p>

\[\hat{y} + \hat{y} e^{\mathbf{z}} = e^{\mathbf{z}}\]

<p>提取 \(\hat{y}\)：</p>

\[\hat{y} (1 + e^{\mathbf{z}}) = e^{\mathbf{z}}\]

<p>最终解出 \(\hat{y}\)：</p>

\[\hat{y} = \frac{e^{\mathbf{z}}}{1 + e^{\mathbf{z}}}\]

<p>为了得到更标准的 Sigmoid 形式，我们将分子和分母同时除以 \(e^{\mathbf{z}}\)：</p>

\[\hat{y} = \frac{e^{\mathbf{z}} / e^{\mathbf{z}}}{(1 + e^{\mathbf{z}}) / e^{\mathbf{z}}} = \frac{1}{1/e^{\mathbf{z}} + e^{\mathbf{z}}/e^{\mathbf{z}}} = \frac{1}{e^{-\mathbf{z}} + 1}\]

<p>最后，用 \(\mathbf{z} = W x + W_0\) 替换 \(\mathbf{z}\)：</p>

\[P(y=1|x) = \frac{1}{1 + e^{-(W x + W_0)}}\]

<p>这就是<strong>逻辑函数（Sigmoid 函数）</strong> 的形式。</p>

<p>这证明了在特征服从高斯分布且<strong>方差相等</strong>的假设下，<strong>线性判别分析 (LDA)</strong> 的结果在数学上与 <strong>逻辑回归</strong> 是等价的。</p>

<p>或者说上面的内容论证了<strong>生成模型</strong>（基于贝叶斯公式和高斯分布假设）如何<strong>推导出</strong>这个判别模型的形式。</p>

<p><strong>将生成模型（假设特征服从高斯分布的贝叶斯分类器）推导至逻辑回归形式</strong>所需的特定条件：</p>

<ul>
  <li>满足正态分布</li>
  <li>方差相等</li>
</ul>

<table>
  <tbody>
    <tr>
      <td><strong>当数据满足“高斯分布”和“同方差”这两个条件时，基于贝叶斯和高斯分布的生成模型（即LDA）的决策边界形式，会自然地推导出与判别模型“逻辑回归”完全一致的形式。</strong> 换句话说，在这些假设下，两个模型本质上是相同的线性分类器。如果<strong>类别条件概率</strong>服从<strong>同方差高斯分布</strong>，那么从贝叶斯公式推导出的<strong>后验概率</strong> $$P(y</td>
      <td>x)$$ 必然是<strong>逻辑回归</strong>的Sigmoid形式。</td>
    </tr>
  </tbody>
</table>

<h1 id="5最大似然估计到bcekl散度">5.最大似然估计到BCE/KL散度</h1>

<p>对于二分类问题，最大似然估计（Maximum Likelihood Estimation, MLE）的目标是找到一组参数 \(\mathbf{W}\) 和 \(b\) (或 \(\mathbf{W}\) 和 \(W_0\))，使得观测到的训练数据出现的<strong>总概率最大化</strong>。</p>

<p>对于逻辑回归（Logistic Regression）模型，最大化似然函数（Likelihood Function）的等价操作就是最小化<strong>二元交叉熵损失（Binary Cross-Entropy Loss, BCE）</strong>。</p>

<p>下面是详细的推导过程。</p>

<hr />

<p>【1】逻辑回归的二分类模型</p>

<table>
  <tbody>
    <tr>
      <td>在二分类问题中，我们通常使用逻辑回归（Sigmoid 函数）来建模<strong>后验概率</strong> $$P(y=1</td>
      <td>x)$$。</td>
    </tr>
  </tbody>
</table>

<p>设输入特征为 \(\mathbf{x}\)，模型参数为 \(\boldsymbol{\theta} = \{\mathbf{W}, b\}\)。</p>

<ol>
  <li>
    <p>线性组合 (Logit):</p>

\[z = \mathbf{W}^T \mathbf{x} + b\]
  </li>
  <li>
    <p>类别 1 的概率 (Sigmoid 函数):</p>

\[\hat{y} = P(y=1|\mathbf{x}; \boldsymbol{\theta}) = \frac{1}{1 + e^{-z}}\]
  </li>
  <li>
    <p>类别 0 的概率:</p>

\[P(y=0|\mathbf{x}; \boldsymbol{\theta}) = 1 - \hat{y} = 1 - \frac{1}{1 + e^{-z}} = \frac{e^{-z}}{1 + e^{-z}}\]
  </li>
</ol>

<p>【2】似然函数</p>

<table>
  <tbody>
    <tr>
      <td>对于单个训练样本 \((\mathbf{x}_i, y_i)\)，其中 \(y_i \in \{0, 1\}\)，我们可以将 $$P(y_i</td>
      <td>\mathbf{x}_i; \boldsymbol{\theta})$$ 写成一个紧凑的形式：</td>
    </tr>
  </tbody>
</table>

\[P(y_i|\mathbf{x}_i; \boldsymbol{\theta}) = (\hat{y}_i)^{y_i} \cdot (1 - \hat{y}_i)^{1 - y_i}\]

<ul>
  <li>如果 \(y_i = 1\)，则概率为 \(\hat{y}_i^1 (1 - \hat{y}_i)^0 = \hat{y}_i\)。</li>
  <li>如果 \(y_i = 0\)，则概率为 \(\hat{y}_i^0 (1 - \hat{y}_i)^1 = 1 - \hat{y}_i\)。</li>
</ul>

<p>假设我们有 \(N\) 个独立同分布的训练样本 \((\mathbf{x}_1, y_1), \dots, (\mathbf{x}_N, y_N)\)。<strong>似然函数 \(\mathcal{L}(\boldsymbol{\theta})\)</strong> 是所有样本概率的乘积：</p>

\[\mathcal{L}(\boldsymbol{\theta}) = P(Y|\mathbf{X}; \boldsymbol{\theta}) = \prod_{i=1}^{N} P(y_i|\mathbf{x}_i; \boldsymbol{\theta})\]

\[\mathcal{L}(\boldsymbol{\theta}) = \prod_{i=1}^{N} (\hat{y}_i)^{y_i} \cdot (1 - \hat{y}_i)^{1 - y_i}\]

<p>最大似然估计（MLE）的目标是找到 \(\boldsymbol{\theta}\) 使得 \(\mathcal{L}(\boldsymbol{\theta})\) 最大化：</p>

\[\boldsymbol{\theta}_{\text{MLE}} = \arg \max_{\boldsymbol{\theta}} \mathcal{L}(\boldsymbol{\theta})\]

<p>【3】对数似然函数（Log-Likelihood Function）</p>

<p>为了简化计算（将乘积转化为求和，且避免浮点数下溢），我们通常最大化<strong>对数似然函数 \(\ell(\boldsymbol{\theta})\)</strong>：</p>

\[\ell(\boldsymbol{\theta}) = \log \mathcal{L}(\boldsymbol{\theta}) = \log \left( \prod_{i=1}^{N} (\hat{y}_i)^{y_i} \cdot (1 - \hat{y}_i)^{1 - y_i} \right)\]

<p>根据对数运算的性质:</p>

\[\ell(\boldsymbol{\theta}) = \sum_{i=1}^{N} \left[ \log \left( (\hat{y}_i)^{y_i} \right) + \log \left( (1 - \hat{y}_i)^{1 - y_i} \right) \right]\]

\[\ell(\boldsymbol{\theta}) = \sum_{i=1}^{N} \left[ y_i \log (\hat{y}_i) + (1 - y_i) \log (1 - \hat{y}_i) \right]\]

<p>最大化对数似然函数的等价于最大化原始似然函数：</p>

\[\boldsymbol{\theta}_{\text{MLE}} = \arg \max_{\boldsymbol{\theta}} \ell(\boldsymbol{\theta})\]

<p>【4】损失函数：最小化负对数似然（Negative Log-Likelihood）</p>

<p>在优化领域，习惯于将优化问题转化为<strong>最小化损失函数</strong>的形式。因此，我们定义<strong>损失函数 \(J(\boldsymbol{\theta})\)</strong> 为负的对数似然函数（Negative Log-Likelihood, NLL）：</p>

\[J(\boldsymbol{\theta}) = - \ell(\boldsymbol{\theta})\]

\[\boldsymbol{\theta}_{\text{MLE}} = \arg \min_{\boldsymbol{\theta}} J(\boldsymbol{\theta})\]

<p>将 NLL 展开：</p>

\[J(\boldsymbol{\theta}) = - \sum_{i=1}^{N} \left[ y_i \log (\hat{y}_i) + (1 - y_i) \log (1 - \hat{y}_i) \right]\]

<p>【5】得到二元交叉熵损失 (BCE Loss)</p>

<p>最终得到的这个损失函数 \(J(\boldsymbol{\theta})\) <strong>正是二元交叉熵损失（Binary Cross-Entropy Loss, BCE）</strong>，通常也称为对数损失（Log Loss）。</p>

<p>通常，损失函数还会在前面加上 \(\frac{1}{N}\) 进行平均：</p>

\[L_{\text{BCE}}(\boldsymbol{\theta}) = - \frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log (\hat{y}_i) + (1 - y_i) \log (1 - \hat{y}_i) \right]\]

<hr />

<p>总结来说：对于逻辑回归模型，<strong>最大化似然函数</strong> \(\mathcal{L}(\boldsymbol{\theta})\) 在数学上等价于<strong>最小化二元交叉熵损失函数 \(L_{\text{BCE}}(\boldsymbol{\theta})\)</strong>。交叉熵损失来源于最大似然估计在伯努利分布假设下的自然推导。</p>


                <hr style="visibility: hidden;">
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2025/11/20/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9908/" data-toggle="tooltip" data-placement="top" title="【AI思想启蒙08】逻辑回归4让模型看的更准更稳，正则优化 ">
                        Previous<br>
                        <span>【AI思想启蒙08】逻辑回归4让模型看的更准更稳，正则优化 </span>
                        </a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2025/11/22/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9910/" data-toggle="tooltip" data-placement="top" title="【AI思想启蒙10】朴素贝叶斯模型：简单背后蕴含的有效 ">
                        Next<br>
                        <span>【AI思想启蒙10】朴素贝叶斯模型：简单背后蕴含的有效 </span>
                        </a>
                    </li>
                    
                </ul>
                <hr style="visibility: hidden;">

                

                
            </div>  

    <!-- Side Catalog Container -->
        
            <div class="
                col-lg-2 col-lg-offset-0
                visible-lg-block
                sidebar-container
                catalog-container">
                <div class="side-catalog">
                    <hr class="hidden-sm hidden-xs">
                    <h5>
                        <a class="catalog-toggle" href="#">CATALOG</a>
                    </h5>
                    <ul class="catalog-body"></ul>
                </div>
            </div>
        

    <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                


<section>
    
        <hr class="hidden-sm hidden-xs">
    
    <h5><a href="/archive/">FEATURED TAGS</a></h5>
    <div class="tags">
        
        
        
        
        
        
                <a data-sort="0185" 
                    href="/archive/?tag=%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB"
                    title="书籍阅读"
                    rel="3">书籍阅读</a>
        
                <a data-sort="0147" 
                    href="/archive/?tag=%E7%AE%97%E6%B3%95"
                    title="算法"
                    rel="41">算法</a>
        
                <a data-sort="0170" 
                    href="/archive/?tag=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI%E5%9F%BA%E7%A1%80"
                    title="人工智能AI基础"
                    rel="18">人工智能AI基础</a>
        
                <a data-sort="0171" 
                    href="/archive/?tag=python%E5%9F%BA%E7%A1%80"
                    title="python基础"
                    rel="17">python基础</a>
        
                <a data-sort="0173" 
                    href="/archive/?tag=%E5%8A%9B%E6%89%A3"
                    title="力扣"
                    rel="15">力扣</a>
        
                <a data-sort="0175" 
                    href="/archive/?tag=numpy"
                    title="numpy"
                    rel="13">numpy</a>
        
                <a data-sort="0175" 
                    href="/archive/?tag=pandas"
                    title="pandas"
                    rel="13">pandas</a>
        
                <a data-sort="0176" 
                    href="/archive/?tag=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE"
                    title="机器学习-吴恩达"
                    rel="12">机器学习-吴恩达</a>
        
                <a data-sort="0177" 
                    href="/archive/?tag=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95"
                    title="机器学习算法"
                    rel="11">机器学习算法</a>
        
                <a data-sort="0177" 
                    href="/archive/?tag=AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%99"
                    title="AI思想启蒙"
                    rel="11">AI思想启蒙</a>
        
                <a data-sort="0182" 
                    href="/archive/?tag=matplotlib"
                    title="matplotlib"
                    rel="6">matplotlib</a>
        
                <a data-sort="0185" 
                    href="/archive/?tag=spring6"
                    title="spring6"
                    rel="3">spring6</a>
        
                <a data-sort="0186" 
                    href="/archive/?tag=%E7%AE%97%E6%B3%95%E9%A2%98%E5%BA%93"
                    title="算法题库"
                    rel="2">算法题库</a>
        
                <a data-sort="0186" 
                    href="/archive/?tag=Java%E5%9F%BA%E7%A1%80"
                    title="Java基础"
                    rel="2">Java基础</a>
        
                <a data-sort="0186" 
                    href="/archive/?tag=java%E9%9B%86%E5%90%88"
                    title="java集合"
                    rel="2">java集合</a>
        
                <a data-sort="0186" 
                    href="/archive/?tag=ollama%E5%B7%A5%E5%85%B7"
                    title="ollama工具"
                    rel="2">ollama工具</a>
        
                <a data-sort="0186" 
                    href="/archive/?tag=python%E7%88%AC%E8%99%AB"
                    title="python爬虫"
                    rel="2">python爬虫</a>
    </div>
</section>


                <!-- Friends Blog -->
                
<hr>
<h5>FRIENDS</h5>
<ul class="list-inline">
  
  <li><a href="https://m.freebuf.com/">freebuf</a></li>
  
  <li><a href="https://xz.aliyun.com/">先知</a></li>
  
  <li><a href="https://www.sec-in.com/All">sec-in</a></li>
  
  <li><a href="https://paper.seebug.org/">see-bug</a></li>
  
  <li><a href="https://twitter.com/Concurr21486093">我的推特</a></li>
  
  <li><a href="https://pdai.tech/">pdai</a></li>
  
  <li><a href="https://nodejs.org/dist/">nodejs index of dist</a></li>
  
  <li><a href="#">公众号：小东方不败</a></li>
  
</ul>

            </div>
        </div>
    </div>
</article>

<!-- add support for mathjax by voleking-->









<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'hover',
          placement: 'right',
          // icon: '#'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <!-- SNS Link -->
                


<ul class="list-inline text-center">


  
  
  <li>
    <a href="https://twitter.com/Concurr21486093">
      <span class="fa-stack fa-lg">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
      </span>
    </a>
  </li>
  
  
  <li>
    <a target="_blank" href="https://www.zhihu.com/people/Hilda">
      <span class="fa-stack fa-lg">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa  fa-stack-1x fa-inverse">知</i>
      </span>
    </a>
  </li>
  
  
  
  
  <li>
    <a target="_blank" href="https://github.com/kirsten-1">
      <span class="fa-stack fa-lg">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa fa-github fa-stack-1x fa-inverse"></i>
      </span>
    </a>
  </li>
  
  
</ul>

                <p class="copyright text-muted">
                    Copyright &copy; Hilda 2025
                    <br>
                    Powered by <a href="https://kirsten-1.github.io/">hilda Blog</a>
<!--                    <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="100px"-->
<!--                        height="20px"-->
<!--                        src="https://ghbtns.com/github-btn.html?user=huxpro&repo=huxpro.github.io&type=star&count=true">-->
<!--                    </iframe>-->
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<!-- Currently, only navbar scroll-down effect at desktop still depends on this -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js "></script>

<!-- Simple Jekyll Search -->
<script src="/js/simple-jekyll-search.min.js"></script>

<!-- Service Worker -->

<script src="/js/snackbar.js "></script>
<script src="/js/sw-registration.js "></script>


<!-- async load function -->
<script>
    function async(u, c) {
        var d = document, t = 'script',
            o = d.createElement(t),
            s = d.getElementsByTagName(t)[0];
        o.src = u;
        if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
        s.parentNode.insertBefore(o, s);
    }
</script>

<!--
     Because of the native support for backtick-style fenced code blocks
     right within the Markdown is landed in Github Pages,
     From V1.6, There is no need for Highlight.js,
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/
     - https://github.com/jneen/rouge/wiki/list-of-supported-languages-and-lexers
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->







<!--fastClick.js -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function () {
        var $nav = document.querySelector("nav");
        if ($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->



<!-- Baidu Tongji -->



<!-- Side Catalog -->

<script type="text/javascript">
    function generateCatalog(selector) {

        // interop with multilangual 
        if ('' == 'true') {
            _containerSelector = 'div.post-container.active'
        } else {
            _containerSelector = 'div.post-container'
        }

        // init
        var P = $(_containerSelector), a, n, t, l, i, c;
        a = P.find('h1,h2,h3,h4,h5,h6');

        // clean
        $(selector).html('')

        // appending
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            i = "#" + $(this).prop('id');
            t = $(this).text();
            c = $('<a href="' + i + '" rel="nofollow">' + t + '</a>');
            l = $('<li class="' + n + '_nav"></li>').append(c);
            $(selector).append(l);
        });
        return true;
    }

    generateCatalog(".catalog-body");

    // toggle side catalog
    $(".catalog-toggle").click((function (e) {
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    /*
     * Doc: https://github.com/davist11/jQuery-One-Page-Nav
     * Fork by Hux to support padding
     */
    async("/js/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });
</script>



<!-- Multi-Lingual -->


<!-- Simple Jekyll Search -->
<script>
    // https://stackoverflow.com/questions/1912501/unescape-html-entities-in-javascript
    function htmlDecode(input) {
        var e = document.createElement('textarea');
        e.innerHTML = input;
        // handle case of empty input
        return e.childNodes.length === 0 ? "" : e.childNodes[0].nodeValue;
    }

    SimpleJekyllSearch({
        searchInput: document.getElementById('search-input'),
        resultsContainer: document.getElementById('search-results'),
        json: '/search.json',
        searchResultTemplate: '<div class="post-preview item"><a href="{url}"><h2 class="post-title">{title}</h2><h3 class="post-subtitle">{subtitle}</h3><hr></a></div>',
        noResultsText: 'No results',
        limit: 50,
        fuzzy: false,
        // a hack to get escaped subtitle unescaped. for some reason, 
        // post.subtitle w/o escape filter nuke entire search.
        templateMiddleware: function (prop, value, template) {
            if (prop === 'subtitle' || prop === 'title') {
                if (value.indexOf("code")) {
                    return htmlDecode(value);
                } else {
                    return value;
                }
            }
        }
    });

    $(document).ready(function () {
        var $searchPage = $('.search-page');
        var $searchOpen = $('.search-icon');
        var $searchClose = $('.search-icon-close');
        var $searchInput = $('#search-input');
        var $body = $('body');

        $searchOpen.on('click', function (e) {
            e.preventDefault();
            $searchPage.toggleClass('search-active');
            var prevClasses = $body.attr('class') || '';
            setTimeout(function () {
                $body.addClass('no-scroll');
            }, 400)

            if ($searchPage.hasClass('search-active')) {
                $searchClose.on('click', function (e) {
                    e.preventDefault();
                    $searchPage.removeClass('search-active');
                    $body.attr('class', prevClasses);  // from closure 
                });
                $searchInput.focus();
            }
        });
    });
</script>


<!-- Image to hack wechat -->
<img src="/img/icon_wechat.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
