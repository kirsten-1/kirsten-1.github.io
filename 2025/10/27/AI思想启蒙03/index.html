<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
    <meta name="description" content="这里是 Hilda 的个人博客，与你一起发现更大的世界 | 要做一个有 swag 的程序员">
    <meta name="keywords" content="Hilda">
    <meta name="theme-color" content="#000000">

    <!-- Open Graph -->
    <meta property="og:title"
        content="【AI思想启蒙03】线性回归2从傻瓜到智能，梯度下降法学习法 - Hilda的博客 | Your genius girlfriend's blog">
    
    <meta property="og:type" content="article">
    <meta property="og:description" content="

">
    
    <meta property="article:published_time" content=" 2025-10-27T00:00:00Z">
    
    
    <meta property="article:author" content="Hilda">
    
    
    <meta property="article:tag" content="AI思想启蒙">
    
    
    <meta property="og:image" content="https://kirsten-1.github.io">
    <meta property="og:url" content="https://kirsten-1.github.io/2025/10/27/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9903/">
    <meta property="og:site_name" content="Hilda的博客 | Your genius girlfriend's blog">

    <title>【AI思想启蒙03】线性回归2从傻瓜到智能，梯度下降法学习法 - Hilda的博客 | Your genius girlfriend's blog</title>

    <!-- Web App Manifest -->
    <link rel="manifest" href="/pwa/manifest.json">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/favicon.ico">

    <!-- Canonical URL -->
    <link rel="canonical" href="https://kirsten-1.github.io/2025/10/27/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9903/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href=" /css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href=" /css/hux-blog.min.css">

    <!-- Custom Fonts -->
    <!-- <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet"
        type="text/css">


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>

    <!-- Google AdSense -->
    <script data-ad-client="ca-pub-6487568398225121" async
        src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Navigation -->

    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="/">Hilda</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div id="huxblog_navbar">
                <div class="navbar-collapse">
                    <ul class="nav navbar-nav navbar-right">
                        <li>
                            <a href="/">Home</a>
                        </li>
                        
                        
                        
                        
                        <li>
                            <a href="/about/">About</a>
                        </li>
                        
                        
                        
                        <li>
                            <a href="/archive/">Archive</a>
                        </li>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <li class="search-icon">
                            <a href="javascript:void(0)">
                                <i class="fa fa-search"></i>
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <script>
        // Drop Bootstarp low-performance Navbar
        // Use customize navbar with high-quality material design animation
        // in high-perf jank-free CSS3 implementation
        var $body = document.body;
        var $toggle = document.querySelector('.navbar-toggle');
        var $navbar = document.querySelector('#huxblog_navbar');
        var $collapse = document.querySelector('.navbar-collapse');

        var __HuxNav__ = {
            close: function () {
                $navbar.className = " ";
                // wait until animation end.
                setTimeout(function () {
                    // prevent frequently toggle
                    if ($navbar.className.indexOf('in') < 0) {
                        $collapse.style.height = "0px"
                    }
                }, 400)
            },
            open: function () {
                $collapse.style.height = "auto"
                $navbar.className += " in";
            }
        }

        // Bind Event
        $toggle.addEventListener('click', function (e) {
            if ($navbar.className.indexOf('in') > 0) {
                __HuxNav__.close()
            } else {
                __HuxNav__.open()
            }
        })

        /**
         * Since Fastclick is used to delegate 'touchstart' globally
         * to hack 300ms delay in iOS by performing a fake 'click',
         * Using 'e.stopPropagation' to stop 'touchstart' event from 
         * $toggle/$collapse will break global delegation.
         * 
         * Instead, we use a 'e.target' filter to prevent handler
         * added to document close HuxNav.  
         *
         * Also, we use 'click' instead of 'touchstart' as compromise
         */
        document.addEventListener('click', function (e) {
            if (e.target == $toggle) return;
            if (e.target.className == 'icon-bar') return;
            __HuxNav__.close();
        })
    </script>
    <!-- Search -->
<div class="search-page">
  <div class="search-icon-close-container">
    <span class="search-icon-close">
      <i class="fa fa-chevron-down"></i>
    </span>
  </div>
  <div class="search-main container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <form></form>
        <input type="text" id="search-input" placeholder="$ grep...">
        </form>
        <div id="search-results" class="mini-post-list"></div>
      </div>
    </div>
  </div>
</div>

    <!-- Image to hack wechat -->
<!-- <img src="/img/icon_wechat.png" width="0" height="0"> -->
<!-- <img src="/img/post-bg-2015.jpg" width="0" height="0"> -->

<!-- Post Header -->



<style type="text/css">
    header.intro-header{
        position: relative;
        background-image: url('/img/post-bg-2015.jpg');
        background: ;
    }

    
</style>




<header class="intro-header" >

    <div class="header-mask"></div>
    
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/archive/?tag=AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%99" title="AI思想启蒙">AI思想启蒙</a>
                        
                    </div>
                    <h1>【AI思想启蒙03】线性回归2从傻瓜到智能，梯度下降法学习法</h1>
                    
                    <h2 class="subheading">线性回归代码实现数据读取、模型训练、MSE评估与可视化，分析MSE凸性与梯度下降策略，MBGD平衡速度与稳定性，提前停止防过拟合。</h2>
                    <span class="meta">Posted by Hilda on October 27, 2025</span>
                </div>
            </div>
        </div>
    </div>
</header>







<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <!-- Multi-Lingual -->
                

				<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG">
</script>

<h1 id="1代码实战线性回归">1.代码实战：线性回归</h1>

<p>1.导包与数据读取：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span> 
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span> <span class="c1"># 分割数据集，分成训练集和测试集
</span><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>   <span class="c1"># 计算MSE
</span></pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">load_and_clean_data</span><span class="p">(</span><span class="n">file_path</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    从指定文件中读取数据，清理字符串格式，并返回 NumPy 数组。
    数据格式预期为：[[x], [y]]
    </span><span class="sh">"""</span>
    <span class="n">cleaned_data_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">line_number</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># 用于跟踪行号
</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">line_number</span> <span class="o">+=</span> <span class="mi">1</span>
                
                <span class="c1"># 1. 清理行首和行尾的空白字符
</span>                <span class="n">line_stripped</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span>
                
                <span class="c1"># 严格跳过空行或仅包含空白字符的行
</span>                <span class="k">if</span> <span class="ow">not</span> <span class="n">line_stripped</span><span class="p">:</span>
                    <span class="c1"># 如果需要调试，可以取消注释下面这行
</span>                    <span class="c1"># print(f"跳过文件中的空行或空白行 (行号: {line_number})")
</span>                    <span class="k">continue</span>
                    
                <span class="c1"># 2. 移除所有方括号 '[]' 和空格，只留下数字和逗号
</span>                <span class="c1"># 示例: "[[5.34...], [30.91...]]" -&gt; "5.34...,30.91..."
</span>                <span class="n">clean_value_str</span> <span class="o">=</span> <span class="n">line_stripped</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">[</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">]</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s"> </span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">)</span>
                
                <span class="c1"># 3. 按逗号分隔，得到 X 和 y 的字符串
</span>                <span class="n">x_str</span><span class="p">,</span> <span class="n">y_str</span> <span class="o">=</span> <span class="n">clean_value_str</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="p">)</span>
                
                <span class="c1"># 4. 转换为浮点数并存储
</span>                <span class="n">x_val</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="n">x_str</span><span class="p">)</span>
                <span class="n">y_val</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="n">y_str</span><span class="p">)</span>
                <span class="n">cleaned_data_list</span><span class="p">.</span><span class="nf">append</span><span class="p">([</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">])</span>
                
    <span class="k">except</span> <span class="nb">FileNotFoundError</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">❌ 错误：未找到文件 </span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="s">。请检查文件路径。</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
    <span class="k">except</span> <span class="nb">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">❌ 错误：数据格式不正确，无法转换为浮点数。请检查数据行 (行号: </span><span class="si">{</span><span class="n">line_number</span><span class="si">}</span><span class="s">): </span><span class="si">{</span><span class="n">line_stripped</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">具体错误信息: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">❌ 发生未知错误: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>

    <span class="c1"># 5. 转换为最终的 NumPy 数组
</span>    <span class="n">cleaned_data_np</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">cleaned_data_list</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float64</span><span class="p">)</span>
    
    <span class="c1"># 6. 分离特征 (X) 和目标值 (y)
</span>    <span class="c1"># X 必须是二维数组 (n, 1)
</span>    <span class="n">X</span> <span class="o">=</span> <span class="n">cleaned_data_np</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">cleaned_data_np</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="c1"># y 是一维数组 (n,)
</span>    
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

<span class="c1"># ----------------- 修改后的使用示例 -----------------
</span><span class="n">file_name</span> <span class="o">=</span> <span class="sh">'</span><span class="s">train_data</span><span class="sh">'</span> <span class="c1"># 建议使用 .txt 扩展名，以明确文件类型
</span>
<span class="c1"># **注意:** 请确保您的数据已保存到指定的文件中
</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">load_and_clean_data</span><span class="p">(</span><span class="n">file_name</span><span class="p">)</span>

<span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">--- ✅ 数据读取成功 ---</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">特征 X 的形状: </span><span class="si">{</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">目标 y 的形状: </span><span class="si">{</span><span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">X 的前 5 个样本:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">y 的前 5 个样本:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">数据已清理并准备好进行模型训练（未分割数据集）。</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="c1"># **********************************************
</span>    <span class="c1"># 移除的分割代码原本在此处，现在直接对 X 和 y 进行操作
</span>    <span class="c1"># **********************************************
</span>    
    <span class="c1"># 现在您可以直接使用整个 X 和 y 进行模型训练（例如，训练集就是整个数据集）
</span>    <span class="c1"># from sklearn.linear_model import LinearRegression
</span>    <span class="c1"># model = LinearRegression()
</span>    <span class="c1"># model.fit(X, y) # 直接使用所有数据进行训练
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027135230250.png" alt="image-20251027135230250" style="zoom:50%;" /></p>

<p>2.分割数据集，分为测试集和训练集，比例2:8</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> 
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span> <span class="c1"># 设置随机种子以确保结果可重现
</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">训练集大小 (X_train): </span><span class="si">{</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">测试集大小 (X_test): </span><span class="si">{</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20251027135243118.png" alt="image-20251027135243118" style="zoom:50%;" /></p>

<p>3.模型训练：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="n">model</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># 打印模型参数 (截距和斜率)
# 对于一元线性回归： y = coef * X + intercept
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">--- 模型训练结果 ---</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">模型截距 (Intercept): </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">intercept_</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">模型系数 (Coefficient/Slope): </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20251027135317069.png" alt="image-20251027135317069" style="zoom:50%;" /></p>

<p>4.模型预测，计算MSE</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre><span class="c1"># 1. 对训练集进行预测
</span><span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="c1"># 2. 对测试集进行预测
</span><span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># 计算 MSE
</span><span class="n">mse_train</span> <span class="o">=</span> <span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>
<span class="n">mse_test</span> <span class="o">=</span> <span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">--- 模型评估 (MSE) ---</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">训练集 MSE: </span><span class="si">{</span><span class="n">mse_train</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">测试集 MSE: </span><span class="si">{</span><span class="n">mse_test</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20251027135354439.png" alt="image-20251027135354439" style="zoom:50%;" /></p>

<p>5.绘图</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
</pre></td><td class="rouge-code"><pre><span class="c1"># -----------------------------------------------------------
# 步骤 3: 绘图
# -----------------------------------------------------------
</span>
<span class="c1"># Matplotlib 绘图设置
</span><span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="sh">"</span><span class="s">font.sans-serif</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">SimHei</span><span class="sh">"</span><span class="p">]</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="sh">"</span><span class="s">axes.unicode_minus</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>  <span class="c1"># 解决负号显示的问题
</span>
<span class="c1"># **关键修正步骤：排序**
# 1. 对完整的 X 数组进行排序，以确保拟合线是一条平滑的直线
#    np.argsort 返回排序后的索引
</span><span class="n">sort_index</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="nf">flatten</span><span class="p">())</span> <span class="c1"># 注意：X是二维数组，需要先展平
</span><span class="n">X_sorted</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">sort_index</span><span class="p">]</span>
<span class="c1"># 2. 对模型在 X 上的预测值也使用相同的索引进行排序
</span><span class="n">y_full_pred_sorted</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_sorted</span><span class="p">)</span>


<span class="c1"># --- 绘图要求 1: 所有点和预测线一起展示 (修正) ---
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># 绘制所有原始数据点 (训练集和测试集)
</span><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">训练集数据点</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">测试集数据点</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>

<span class="c1"># 绘制预测线 (拟合线) - 使用排序后的预测数据
# 这将确保红色线是一条平滑的直线
</span><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X_sorted</span><span class="p">,</span> <span class="n">y_full_pred_sorted</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">-</span><span class="sh">'</span><span class="p">,</span> 
         <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">线性回归拟合线 (y = {:.4f}*X + {:.4f})</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">model</span><span class="p">.</span><span class="n">intercept_</span><span class="p">),</span> 
         <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">所有数据点与线性回归拟合线 (总览)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">特征 X</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">目标 Y</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># --- 绘图要求 2 &amp; 3: 训练集和测试集分开展示（无需排序，因为点本身就是散点图） ---
</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># 2. 训练集 (Training Set) - 绘制训练集数据和预测线
</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">训练集数据点</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>

<span class="c1"># **注意：** 这里的 X_train 依然可能未排序，因此也需要排序以防折叠
</span><span class="n">sort_index_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="nf">flatten</span><span class="p">())</span>
<span class="n">X_train_sorted</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">sort_index_train</span><span class="p">]</span>
<span class="n">y_train_pred_sorted</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_train_sorted</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">X_train_sorted</span><span class="p">,</span> <span class="n">y_train_pred_sorted</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">-</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">模型预测线</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">训练集数据与模型拟合</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">特征 X</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">目标 Y</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>

<span class="c1"># 3. 测试集 (Testing Set) - 绘制测试集数据和预测线
</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">测试集数据点</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>

<span class="c1"># **注意：** 这里的 X_test 也需要排序以防折叠
</span><span class="n">sort_index_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="nf">flatten</span><span class="p">())</span>
<span class="n">X_test_sorted</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="n">sort_index_test</span><span class="p">]</span>
<span class="n">y_test_pred_sorted</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test_sorted</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">X_test_sorted</span><span class="p">,</span> <span class="n">y_test_pred_sorted</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">-</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">模型预测线</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">测试集数据与模型预测</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">特征 X</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027135426797.png" alt="image-20251027135426797" /></p>

<p><img src="https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027135438038.png" alt="image-20251027135438038" /></p>

<h1 id="2mse与wb">2.MSE与w,b</h1>

<h2 id="画图理解">画图理解</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
</pre></td><td class="rouge-code"><pre><span class="c1"># 使用 sklearn 找到最优 w* 和 b*
</span><span class="n">optimal_model</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">().</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">w_star</span> <span class="o">=</span> <span class="n">optimal_model</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">b_star</span> <span class="o">=</span> <span class="n">optimal_model</span><span class="p">.</span><span class="n">intercept_</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">最优参数 w*: </span><span class="si">{</span><span class="n">w_star</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, b*: </span><span class="si">{</span><span class="n">b_star</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 定义 MSE 计算函数
</span><span class="k">def</span> <span class="nf">calculate_mse</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">计算给定 w 和 b 下的均方误差</span><span class="sh">"""</span>
    <span class="c1"># 预测值: y_pred = w * X + b
</span>    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">X_data</span> <span class="o">+</span> <span class="n">b</span>
    <span class="c1"># MSE: mean((y - y_pred)^2)
</span>    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">((</span><span class="n">y_data</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">.</span><span class="nf">flatten</span><span class="p">())</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># -----------------------------------------------------------
# 步骤 2: 绘制 MSE vs W (固定 b = b*)
# -----------------------------------------------------------
</span>
<span class="c1"># 选择 w 的变化范围 (以最优 w* 为中心)
</span><span class="n">w_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">w_star</span> <span class="o">-</span> <span class="mi">5</span><span class="p">,</span> <span class="n">w_star</span> <span class="o">+</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="c1"># 固定 b 为最优值
</span><span class="n">b_fixed</span> <span class="o">=</span> <span class="n">b_star</span>

<span class="c1"># 计算 MSE 数组
</span><span class="n">mse_w</span> <span class="o">=</span> <span class="p">[</span><span class="nf">calculate_mse</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b_fixed</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">w_values</span><span class="p">]</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">w_values</span><span class="p">,</span> <span class="n">mse_w</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">w_star</span><span class="p">,</span> <span class="nf">calculate_mse</span><span class="p">(</span><span class="n">w_star</span><span class="p">,</span> <span class="n">b_star</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="sh">'</span><span class="s">最小MSE点 (w*=</span><span class="si">{</span><span class="n">w_star</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">)</span><span class="sh">'</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">MSE 随 W (斜率) 的变化 (固定 b = </span><span class="si">{</span><span class="n">b_fixed</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">权重 W (斜率)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">均方误差 MSE</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># -----------------------------------------------------------
# 步骤 3: 绘制 MSE vs B (固定 w = w*)
# -----------------------------------------------------------
</span>
<span class="c1"># 选择 b 的变化范围 (以最优 b* 为中心)
</span><span class="n">b_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">b_star</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="n">b_star</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="c1"># 固定 w 为最优值
</span><span class="n">w_fixed</span> <span class="o">=</span> <span class="n">w_star</span>

<span class="c1"># 计算 MSE 数组
</span><span class="n">mse_b</span> <span class="o">=</span> <span class="p">[</span><span class="nf">calculate_mse</span><span class="p">(</span><span class="n">w_fixed</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">b_values</span><span class="p">]</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">b_values</span><span class="p">,</span> <span class="n">mse_b</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">b_star</span><span class="p">,</span> <span class="nf">calculate_mse</span><span class="p">(</span><span class="n">w_star</span><span class="p">,</span> <span class="n">b_star</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="sh">'</span><span class="s">最小MSE点 (b*=</span><span class="si">{</span><span class="n">b_star</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">)</span><span class="sh">'</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">MSE 随 B (截距) 的变化 (固定 w = </span><span class="si">{</span><span class="n">w_fixed</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">偏置 B (截距)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">均方误差 MSE</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20251027135548654.png" alt="image-20251027135548654" style="zoom:50%;" /></p>

<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20251027135628114.png" alt="image-20251027135628114" style="zoom:50%;" /></p>

<p>如果以全量数据进行预测，可以从上图看到MSE与w,b的关系。要使得MSE最小，一定存在这样的w和b</p>

<p>这两张图都展示了 MSE 与单个参数（w或 b）之间的关系是 <strong>凸的二次函数（抛物线）</strong>。曲线只有一个最低点。这个最低点对应的w值（在第一张图上）或b值（在第二张图上）就是使 MSE 最小化的最优参数值。这是梯度下降等优化算法能够有效工作的基础，因为它们总是沿着曲线下降，最终能够收敛到全局最低点。</p>

<h2 id="数学分析梯度分析">数学分析(梯度分析)</h2>

<p>从数学分析的角度来看，<strong>线性回归的均方误差（MSE）损失函数</strong>是一个完美的<strong>凸函数（Convex Function）</strong>。</p>

<p>对于一元线性回归模型 \(y = wX + b\)，给定数据集 \(\{(X_i, y_i)\}_{i=1}^n\)，其均方误差（MSE）损失函数 \(J(w, b)\) 定义为：</p>

\[J(w, b) = \frac{1}{n} \sum_{i=1}^{n} (y_i - (wX_i + b))^2\]

<p>为了证明 \(J(w, b)\) 是一个凸函数，我们可以使用<strong>二阶导数判别法</strong>（即 Hessian 矩阵）。</p>

<p>【A. 凸函数定义】</p>

<p>如果一个函数 \(f(\mathbf{x})\) 的 <strong>Hessian 矩阵 \(\mathbf{H}\)</strong> 在其定义域上是 <strong>半正定（Positive Semi-definite）</strong> 的，那么\(f(\mathbf{x})\) 是一个凸函数。</p>

<p>【B. 计算 Hessian 矩阵】</p>

<p>\(J(w, b)\) 是关于参数向量 \(\mathbf{\theta} = \begin{pmatrix} w \\ b \end{pmatrix}\) 的函数。</p>

<p>1.计算一阶偏导数（梯度 \(\nabla J\)）：</p>

\[\frac{\partial J}{\partial w} = \frac{2}{n} \sum_{i=1}^{n} (wX_i + b - y_i) X_i\]

\[\frac{\partial J}{\partial b} = \frac{2}{n} \sum_{i=1}^{n} (wX_i + b - y_i)\]

<p>2.计算二阶偏导数：</p>

\[\frac{\partial^2 J}{\partial w^2} = \frac{\partial}{\partial w} \left[ \frac{2}{n} \sum_{i=1}^{n} (wX_i + b - y_i) X_i \right] = \frac{2}{n} \sum_{i=1}^{n} X_i^2\]

\[\frac{\partial^2 J}{\partial b^2} = \frac{\partial}{\partial b} \left[ \frac{2}{n} \sum_{i=1}^{n} (wX_i + b - y_i) \right] = \frac{2}{n} \sum_{i=1}^{n} 1 = 2\]

\[\frac{\partial^2 J}{\partial w \partial b} = \frac{\partial}{\partial b} \left[ \frac{2}{n} \sum_{i=1}^{n} (wX_i + b - y_i) X_i \right] = \frac{2}{n} \sum_{i=1}^{n} X_i\]

<p>3.构建 Hessian 矩阵 \(\mathbf{H}\)：</p>

\[\mathbf{H} = \begin{pmatrix} \frac{\partial^2 J}{\partial w^2} &amp; \frac{\partial^2 J}{\partial w \partial b} \\ \frac{\partial^2 J}{\partial w \partial b} &amp; \frac{\partial^2 J}{\partial b^2} \end{pmatrix} = \frac{2}{n} \begin{pmatrix} \sum_{i=1}^{n} X_i^2 &amp; \sum_{i=1}^{n} X_i \\ \sum_{i=1}^{n} X_i &amp; n \end{pmatrix}\]

<p>【C. 判别 Hessian 矩阵的半正定性】</p>

<p>一个 \(2 \times 2\) 矩阵是半正定的，当且仅当它的<strong>主子式（Principal Minors）</strong>是非负的：</p>

<p>1.<strong>一阶主子式（对角线元素）：</strong></p>

<ul>
  <li>$H_{11} = \frac{2}{n} \sum X_i^2$. 由于 $X_i^2 \ge 0$，因此 $H_{11} \ge 0$.</li>
  <li>$H_{22} = 2 &gt; 0$.</li>
</ul>

<p>2.二阶主子式（行列式 \(\det(\mathbf{H})\)）：</p>

\[\det(\mathbf{H}) = \left(\frac{2}{n}\right)^2 \left[ n \sum_{i=1}^{n} X_i^2 - \left( \sum_{i=1}^{n} X_i \right)^2 \right]\]

<p>根据 柯西-施瓦茨不等式（Cauchy–Schwarz inequality） 的离散形式：</p>

\[\left( \sum_{i=1}^{n} a_i^2 \right) \left( \sum_{i=1}^{n} b_i^2 \right) \ge \left( \sum_{i=1}^{n} a_i b_i \right)^2\]

<p>在我们的行列式表达式中，令 $a_i = X_i$ 且 $b_i = 1$：</p>

\[\left( \sum_{i=1}^{n} X_i^2 \right) \left( \sum_{i=1}^{n} 1^2 \right) \ge \left( \sum_{i=1}^{n} X_i \cdot 1 \right)^2\]

\[n \sum_{i=1}^{n} X_i^2 \ge \left( \sum_{i=1}^{n} X_i \right)^2\]

<p>因此，行列式内部的项 \([ n \sum X_i^2 - (\sum X_i)^2 ] \ge 0\)。</p>

<p>这意味着 \(\det(\mathbf{H}) \ge 0\)。</p>

<p>由于所有主子式都非负，<strong>Hessian 矩阵 \(\mathbf{H}\) 是半正定的</strong>，故 $J(w, b)$ 是一个<strong>凸函数</strong>。</p>

<hr />

<p>为什么只有全局最小值，而不是局部最小值？</p>

<p>任何凸函数 \(f(\mathbf{x})\) 的任何局部最小值同时也是<strong>全局最小值</strong>。</p>

<p>如果一个凸函数是<strong>严格凸</strong>的（即 \(\det(\mathbf{H}) &gt; 0\)），那么它至多只有一个全局最小值。</p>

<p>在大多数实际数据场景中（非病态数据）:只有当所有 \(X_i\) 都相同时（即特征没有变化），行列式 \(\det(\mathbf{H})\) 才会等于零。在这种情况下，MSE 损失函数会沿着某个方向形成一个“平底谷”（即多个参数组合都能达到最小 MSE），此时存在一个最小值的<strong>集合</strong>。</p>

<p>只要数据集中的 \(X_i\) <strong>不全相同</strong>（即 \(\sum X_i^2 \ne \frac{1}{n}(\sum X_i)^2\)），那么 \(\det(\mathbf{H}) &gt; 0\)，函数就是<strong>严格凸</strong>的。</p>

<p>对于一个<strong>严格凸函数</strong>，它只能有一个局部最小值，而这个局部最小值就是<strong>唯一的全局最小值</strong>。</p>

<p>这意味着，无论从 \(w\) 和 \(b\) 的哪个初始值开始（比如使用梯度下降法），最终都将收敛到同一个使 MSE 最小化的参数组合。</p>

<p>线性回归的 MSE 损失函数是一个凸函数，其碗状的损失曲面保证了它没有山峰或局部凹陷（局部最小值），因此任何优化算法找到的最低点都是<strong>全局最优解</strong>。</p>

<hr />

<p>参数 \(w\) 和 \(b\) 如何更新以逼近这个最小值？</p>

<p>梯度下降法的核心思想是：<strong>沿着损失函数曲面当前位置坡度最陡峭的下降方向（即负梯度方向）迈出一步</strong>。</p>

<p>梯度 \(\nabla J(w, b)\) 是一个向量，包含了损失函数 \(J\) 对所有参数的<strong>一阶偏导数</strong>：</p>

\[\nabla J(w, b) = \begin{pmatrix} \frac{\partial J}{\partial w} \\ \frac{\partial J}{\partial b} \end{pmatrix}\]

<p>其中，偏导数（即梯度分量）上面计算过：</p>

\[\frac{\partial J}{\partial w} = \frac{2}{n} \sum_{i=1}^{n} (wX_i + b - y_i) X_i\]

\[\frac{\partial J}{\partial b} = \frac{2}{n} \sum_{i=1}^{n} (wX_i + b - y_i)\]

<p>梯度下降法的参数更新迭代公式如下：</p>

\[\begin{aligned} w_{\text{new}} &amp;= w_{\text{old}} - \alpha \frac{\partial J}{\partial w} \\ b_{\text{new}} &amp;= b_{\text{old}} - \alpha \frac{\partial J}{\partial b} \end{aligned}\]

<p>其中，\(\alpha &gt; 0\) 是<strong>学习率（Learning Rate）</strong>，它控制了每一步更新的幅度。</p>

<p>我们以参数 \(w\) 的更新为例进行分析，参数 \(b\) 的分析同理。</p>

<p>我们的目标是让 \(J(w, b)\) 减小，即找到曲线的最低点。</p>

<p>情况一：\(\frac{\partial J}{\partial w} &gt; 0\) （当前点在最低点右侧）</p>

<p>损失函数曲线在当前点 \(w\) 处的斜率为正（向上倾斜）。这意味着当前 \(w\)的值<strong>大于</strong>最优值 \(w^*\)。</p>

\[\Delta w = - \alpha \underbrace{\frac{\partial J}{\partial w}}_{&gt; 0}\]

<p>由于 \(\alpha &gt; 0\)，所以 \(\Delta w\) 必须小于 0。参数 \(w\) 将减小 (\(w_{\text{new}} &lt; w_{\text{old}}\))。\(w\) 向左（较小的值）移动，即向全局最小值 \(w^*\)靠近。</p>

<p>情况二：\(\frac{\partial J}{\partial w} &lt; 0\) （当前点在最低点左侧）</p>

<p>损失函数曲线在当前点 \(w\) 处的斜率为负（向下倾斜）。这意味着当前 \(w\)的值<strong>小于</strong>最优值 \(w^*\)。</p>

\[\Delta w = - \alpha \underbrace{\frac{\partial J}{\partial w}}_{&lt; 0}\]

<p>由于 \(\alpha &gt; 0\)，所以 \(\Delta w\) 必须<strong>大于 0</strong>。参数 \(w\) 将增大 (\(w_{\text{new}} &gt; w_{\text{old}}\))。\(w\) 向右（较大的值）移动，即向全局最小值 \(w^*\) 靠近。</p>

<p>所以，无论是梯度大于 0 还是小于 0，参数更新公式 \(w_{\text{new}} = w_{\text{old}} - \alpha \frac{\partial J}{\partial w}\) 都保证了参数<strong>总是在向坡度下降最快的方向移动</strong>，从而不断减小损失 \(J(w, b)\)。</p>

<p>由于 MSE 损失函数是一个<strong>凸函数</strong>，这种持续下降的行为最终将不可避免地导向<strong>唯一的全局最小值</strong>。梯度下降法之所以高效且强大，正是因为它能够利用损失函数的凸性，保证收敛到最优解。</p>

<h2 id="学习率的选择">学习率的选择</h2>

<p>在应用梯度下降法时<strong>至关重要</strong>的超参数：<strong>学习率（Learning Rate），通常用 \(\alpha\) 表示</strong>。</p>

<p>学习率 $\alpha$ 控制了参数在每次迭代中沿着梯度方向移动的步长。在更新公式中体现为：</p>

\[\theta_{\text{new}} = \theta_{\text{old}} - \alpha \cdot \nabla J(\theta_{\text{old}})\]

<p>选择 \(\alpha\) 时，需要找到一个<strong>平衡点</strong>：既要足够大以快速收敛，又要足够小以避免震荡和发散。</p>

<table>
  <thead>
    <tr>
      <th><strong>情况</strong></th>
      <th><strong>学习率 (α) 特征</strong></th>
      <th><strong>训练效果</strong></th>
      <th><strong>数学/几何分析</strong></th>
      <th><strong>结论</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>过大</strong></td>
      <td><strong>Large \(\alpha\)</strong></td>
      <td><strong>发散 (Divergence) 或剧烈震荡</strong></td>
      <td>步长太大，每次更新都会跳过损失函数的最低点，甚至跳到更高、更陡峭的位置，导致损失函数 \(J(\theta)\) 不断增大。</td>
      <td>❌ <strong>模型无法收敛</strong></td>
    </tr>
    <tr>
      <td><strong>过小</strong></td>
      <td><strong>Small \(\alpha\)</strong></td>
      <td><strong>收敛缓慢 (Slow Convergence)</strong></td>
      <td>步长太小，需要极多的迭代次数才能到达最低点。模型训练时间过长，计算资源消耗大。</td>
      <td>⚠️ <strong>训练效率低下</strong></td>
    </tr>
    <tr>
      <td><strong>适中</strong></td>
      <td><strong>Optimal \(\alpha\)</strong></td>
      <td><strong>平稳且高效收敛</strong></td>
      <td>步长恰到好处，每次更新都能显著减小损失 \(J(\theta)\)，并平稳地向全局最小值收敛。</td>
      <td>✅ <strong>最优选择</strong></td>
    </tr>
  </tbody>
</table>

<p>在实际应用中，没有一个“万能”的学习率，最佳的学习率取决于具体的数据集和损失函数曲面的形状。</p>

<p>可以从一个合理范围的数值开始尝试：<strong>常用起始值：</strong> \(0.1, 0.01, 0.001, 0.0001\)。</p>

<p>学习率退火 (Learning Rate Scheduling / Decay)，在训练过程中动态调整学习率是一种高级策略：在训练初期，使用<strong>较大的学习率</strong>快速接近最优区域；在训练后期，<strong>逐渐减小学习率</strong>（“退火”）以实现更精细的搜索，避免在最低点附近来回震荡，确保稳定收敛。每隔一定数量的 Epoch（轮次）或迭代次数，将 $\alpha$ 乘以一个固定因子（如 0.5）。或者指数衰减。</p>

<hr />

<h2 id="解析解的存在性与计算可行性">解析解的存在性与计算可行性</h2>

<p>在线性回归中，直接求解最优参数 \(w\) 和 \(b\) 的方法是利用<strong>正规方程（Normal Equation）</strong>，这是一种<strong>解析解法</strong>。</p>

<p>对于线性回归的 MSE 损失函数，最优参数 \(\mathbf{\theta}^*\) 的正规方程解为：</p>

\[\mathbf{\theta}^* = (\mathbf{X}^{\text{T}}\mathbf{X})^{-1}\mathbf{X}^{\text{T}}\mathbf{y}\]

<p>我们之前已经证明，MSE 损失函数是一个凸函数，其全局最小值是唯一（或构成一个平面）。这个解析解正是这个全局最小值。<strong>所以，解是存在的。</strong></p>

<p>数学上不可能无解，但是指在<strong>计算上不可行或效率极低</strong>（\(n\) 过大导致“解不出”的计算瓶颈）</p>

<blockquote>
  <p>矩阵求逆的计算量与特征维度的<strong>三次方</strong>成正比。</p>

  <p>对于数百万、数十亿样本（\(n\) 很大）或数万特征（\(d\) 很大）的现代大数据集，正规方程法因为 \(O(d^3)\) 的复杂度，几乎无法在合理时间内完成计算。</p>
</blockquote>

<p>度下降法（以及其变种 SGD/Mini-Batch GD）通过将复杂问题分解为<strong>多次高效的 \(O(nd)\) 或更低复杂度的迭代更新</strong>，有效规避了求逆的瓶颈，成为大数据和高维场景下求解最优参数的首选方法。</p>

<h1 id="3梯度下降的分类">3.梯度下降的分类</h1>

<ul>
  <li>批量梯度下降 (Batch Gradient Descent, BGD)：在计算梯度 \(\nabla J(\mathbf{\theta})\) 时，使用<strong>全部</strong>训练数据（即整个批次，或 Batch）。每次更新都需要遍历整个数据集。当数据集 \(n\) 非常大时，计算成本高，速度慢。此外，大批量计算可能占用大量内存。</li>
</ul>

\[\nabla J(\mathbf{\theta}) = \frac{1}{n} \sum_{i=1}^{n} \nabla J_i(\mathbf{\theta})\]

<ul>
  <li>随机梯度下降 (Stochastic Gradient Descent, SGD):在计算梯度 \(\nabla J(\mathbf{\theta})\) 时，每次迭代只随机抽取<strong>一个</strong>样本来估计梯度。梯度估计具有较大的<strong>随机性/噪声</strong>，导致收敛路径剧烈震荡。虽然最终会收敛到最小值附近，但通常不会精确停在最小值点，而是在附近<strong>徘徊</strong>。</li>
</ul>

\[\nabla J(\mathbf{\theta}) \approx \nabla J_i(\mathbf{\theta})\]

<ul>
  <li>小批量梯度下降 (Mini-Batch Gradient Descent, MBGD):在计算梯度 \(\nabla J(\mathbf{\theta})\) 时，每次迭代使用一个<strong>小批量（Mini-Batch）</strong>的样本子集（通常大小在 32 到 512 之间，一般为2的幂次）。需要调整超参数“批量大小”（Batch Size）。</li>
</ul>

\[\nabla J(\mathbf{\theta}) = \frac{1}{m} \sum_{i=1}^{m} \nabla J_i(\mathbf{\theta})\]

<p>其中 \(m\) 是小批次的大小，且 \(1 &lt; m &lt; n\)</p>

<blockquote>
  <p>机器学习实践中做决策的核心——<strong>权衡（Trade-off）</strong>。</p>

  <p>如果<strong>数据量大且资源有限</strong>，选择 <strong>MBGD</strong> 或 <strong>SGD</strong>，这意味着<strong>权衡了</strong>收敛的微小不稳定性和噪声，来换取<strong>更高的训练速度和内存效率</strong>。</p>

  <p>如果<strong>数据量小且对最终参数精度要求极高</strong>，可能会选择 <strong>BGD</strong>，这意味着<strong>权衡了</strong>训练速度较慢的劣势，来换取<strong>最高的稳定性</strong>。</p>
</blockquote>

<p>下面就是利用实际的例子说明不同的梯度下降策略，对于最优值w的影响：</p>

<p>实现一个通用的梯度下降函数，并通过调整 <code class="language-plaintext highlighter-rouge">batch_size</code> 来模拟 BGD、SGD 和 MBGD</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span> <span class="c1"># 用于找到理论最优解
</span>
<span class="c1"># Matplotlib 绘图设置 (用于显示中文)
</span><span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="sh">'</span><span class="s">font.sans-serif</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">SimHei</span><span class="sh">'</span><span class="p">]</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="sh">'</span><span class="s">axes.unicode_minus</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>

<span class="c1"># -----------------------------------------------------------
# 步骤 1: 模拟数据和最优参数 (请用您的实际 X 和 y 替换)
# -----------------------------------------------------------
</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># 500 个样本
</span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">500</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># 真实模型: y = 5 + 3*X + 噪声
</span><span class="n">y</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">X</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># 使用 sklearn 找到理论最优解
</span><span class="n">optimal_model</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">().</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">w_star</span> <span class="o">=</span> <span class="n">optimal_model</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">b_star</span> <span class="o">=</span> <span class="n">optimal_model</span><span class="p">.</span><span class="n">intercept_</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">理论最优参数 w*: </span><span class="si">{</span><span class="n">w_star</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, b*: </span><span class="si">{</span><span class="n">b_star</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># -----------------------------------------------------------
# 步骤 2: 通用梯度下降实现
# -----------------------------------------------------------
</span>
<span class="k">def</span> <span class="nf">custom_gradient_descent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    运行梯度下降并记录参数 w 的变化路径。
    batch_size = n_samples -&gt; BGD
    batch_size = 1        -&gt; SGD
    batch_size = 32       -&gt; MBGD
    </span><span class="sh">"""</span>
    <span class="n">w</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="c1"># 初始参数 w
</span>    <span class="n">b</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="c1"># 初始参数 b
</span>    <span class="n">w_history</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
        <span class="c1"># 每次 Epoch 重新打乱数据，对 SGD/MBGD 尤其重要
</span>        <span class="k">if</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="n">n_samples</span><span class="p">:</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">permutation</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
            <span class="n">X_shuffled</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
            <span class="n">y_shuffled</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_shuffled</span> <span class="o">=</span> <span class="n">X</span>
            <span class="n">y_shuffled</span> <span class="o">=</span> <span class="n">y</span>
            
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="c1"># 提取当前批次数据
</span>            <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X_shuffled</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
            <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_shuffled</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
            <span class="n">m_batch</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
            
            <span class="c1"># 预测值
</span>            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">X_batch</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()</span> <span class="o">+</span> <span class="n">b</span>
            
            <span class="c1"># 计算梯度 (仅针对当前批次)
</span>            <span class="n">error</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">-</span> <span class="n">y_batch</span>
            <span class="n">dw</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">m_batch</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">error</span> <span class="o">*</span> <span class="n">X_batch</span><span class="p">.</span><span class="nf">flatten</span><span class="p">())</span>
            <span class="n">db</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">m_batch</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
            
            <span class="c1"># 更新参数
</span>            <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dw</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db</span>
            
            <span class="n">w_history</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
            
    <span class="k">return</span> <span class="n">w_history</span>

<span class="c1"># -----------------------------------------------------------
# 步骤 3: 运行三种策略
# -----------------------------------------------------------
</span>
<span class="c1"># 统一参数设置 (不同的学习率和迭代次数可能需要调整以获得最佳展示效果)
</span><span class="n">N_EPOCHS</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">0.005</span> <span class="c1"># 适用于 BGD/MBGD
</span><span class="n">LR_SGD</span> <span class="o">=</span> <span class="mf">0.0005</span> <span class="c1"># SGD 通常需要较小的学习率来减缓震荡
</span>
<span class="c1"># 1. 批量梯度下降 (BGD)
</span><span class="n">w_history_bgd</span> <span class="o">=</span> <span class="nf">custom_gradient_descent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="n">N_EPOCHS</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">n_samples</span><span class="p">)</span>

<span class="c1"># 2. 小批量梯度下降 (MBGD) - 常用 Batch Size = 32
</span><span class="n">w_history_mbgd</span> <span class="o">=</span> <span class="nf">custom_gradient_descent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="n">N_EPOCHS</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

<span class="c1"># 3. 随机梯度下降 (SGD) - Batch Size = 1
</span><span class="n">w_history_sgd</span> <span class="o">=</span> <span class="nf">custom_gradient_descent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR_SGD</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="n">N_EPOCHS</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<span class="c1"># -----------------------------------------------------------
# 步骤 4: 画图展示 w 的收敛路径
# -----------------------------------------------------------
</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># 绘制三种策略的 w 历史路径
</span><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">w_history_bgd</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">BGD (Batch Gradient Descent)</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">w_history_mbgd</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">MBGD (Mini-Batch Gradient Descent, Batch=32)</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">orange</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">w_history_sgd</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">SGD (Stochastic Gradient Descent)</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="c1"># 绘制理论最优值 w*
</span><span class="n">plt</span><span class="p">.</span><span class="nf">axhline</span><span class="p">(</span><span class="n">w_star</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="sh">'</span><span class="s">理论最优解 $w^*$=</span><span class="si">{</span><span class="n">w_star</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">不同梯度下降策略下参数 $w$ 的寻优路径 (迭代次数=</span><span class="si">{</span><span class="n">N_EPOCHS</span><span class="si">}</span><span class="s"> Epochs)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">参数更新次数 (Iterations)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">权重参数 $w$ 的值</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="n">w_star</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">w_star</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># 聚焦于收敛区域
</span><span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="https://wechat01.oss-cn-hangzhou.aliyuncs.com/img/image-20251027155327675.png" alt="image-20251027155327675" /></p>

<p><strong>牺牲梯度准确性（减小 Batch Size）可以显著增加参数更新次数</strong>（SGD 的红线迭代次数远多于 BGD 的蓝线），从而加快训练速度，但代价是<strong>路径的剧烈震荡</strong>。在实际工程中，<strong>MBGD</strong> 提供了最佳的<strong>速度与稳定性的权衡</strong>。</p>

<h1 id="4防止过拟合-有效集与提前停止">4.防止过拟合-有效集与提前停止</h1>

<p><strong>数据集划分：</strong> 训练数据（Train）通常被分成三部分。（一般是随机抽取分为3类）</p>

<ul>
  <li><strong>训练集（Train）：</strong> 用于模型参数的拟合。</li>
  <li><strong>验证集（Valid）：</strong> 用于模型调优和选择（有效率）。</li>
  <li><strong>测试集（Test）：</strong> 用于最终评估模型性能。</li>
</ul>

<p>在训练过程中，如果<strong>验证集（Valid）的mse突然变大了</strong>，而训练集mse仍在下降，这表明模型开始<strong>过拟合</strong>训练集数据。此时应采用<strong>提前停止（Early Stopping）</strong>策略，停止训练。</p>

<h1 id="面试题1小批量梯度下降m取值小性价比更高">面试题1:小批量梯度下降m取值小，性价比更高？</h1>

<p>小批量梯度下降（MBGD）中，<strong>批量m取值小（但大于 1），往往具有更高的“性价比”</strong>。这里的性价比是指在<strong>单位计算资源消耗下，获得最高的参数优化效率</strong>。</p>

<p>当计算梯度时，使用的样本 m越多，梯度估计的随机性就越小，越接近全部数据的真实梯度方向。</p>

<p>梯度方差 \(\text{Var}(\nabla J_m)\) 的下降速度与 \(\frac{1}{\sqrt{m}}\) 相关。<strong>希望方差尽可能小，使参数w的寻优路径稳定。</strong></p>

<table>
  <thead>
    <tr>
      <th><strong>批量 m 变化</strong></th>
      <th><strong>迭代成本支出变化 (∝m)</strong></th>
      <th><strong>标准误差 SE 收益变化 (∝1/m)</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>\(m=1 \to m=10\)</td>
      <td>成本 \(\times 10\)</td>
      <td>SE 降低 \(1/\sqrt{10} \approx 0.316\) 倍 (约 68.4%)</td>
    </tr>
    <tr>
      <td>\(m=100 \to m=200\)</td>
      <td>成本 \(\times 2\)</td>
      <td>SE 降低 \(1/\sqrt{2} \approx 0.707\) 倍 (约 29.3%)</td>
    </tr>
    <tr>
      <td>\(m=1000 \to m=2000\)</td>
      <td>成本 \(\times 2\)</td>
      <td>SE 降低 \(1/\sqrt{2} \approx 0.707\) 倍 (约 29.3%)</td>
    </tr>
  </tbody>
</table>

<p>当m从 1增加到10，需要付出 <strong>10 倍</strong>的计算成本，换来 <strong>3.16 倍</strong>的 SE 改善（即 $10 / 3.16 \approx 3.16$ 的效率比）。</p>

<p>但是，当m从1000增加到2000时，你付出的计算成本<strong>增加了 2 倍</strong>，而 SE 只改善了 <strong>$\approx 1.414$ 倍</strong>（即 $2 / 0.707 \approx 1.414$ 的效率比）。</p>

<blockquote>
  <p><strong>边际收益递减：</strong> 随着m的增加，虽然 SE 仍在下降，但 SE 的下降速度（收益）是 \(\mathbf{1/\sqrt{m}}\)，而计算成本（支出）是 \(\mathbf{m}\)，成本的增加速度远快于收益的增加速度。</p>
</blockquote>

<p>在优化过程中，我们最关心的是<strong>单次迭代的计算时间</strong>和<strong>最终收敛所需的迭代次数</strong>。</p>

<p><strong>小m例如32）的性价比高：</strong></p>

<ul>
  <li>在较小的m范围内，<strong>SE 的改善是非常显著且高效的</strong>。只需付出很小的计算代价，就能将梯度噪声降低到一个可接受的水平，避免 SGD 那样剧烈的震荡。在实际训练中，MBGD 的计算时间（\(\propto m\)）远小于 BGD，最终达到相同精度所需的总训练时间最短。</li>
  <li>大m的性价比低,计算成本增大了，但总的收敛速度提升不明显。这是典型的<strong>低效率投入</strong>。</li>
</ul>

<p>因此，根据 \(\mathbf{1/\sqrt{m}}\) 的关系，选择一个能最大化硬件利用率、且 SE 足够小的<strong>较小批量m</strong>，是获得最高优化性价比的策略。</p>

<h1 id="5书籍推荐">5.书籍推荐</h1>

<p>1.统计学习方法 第二版 李航</p>

<p>2.模式分类第2版</p>

<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20251027212533939.png" alt="image-20251027212533939" style="zoom:25%;" /></p>

<p>3.深度学习  Ian Goodfellow等人</p>

<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20251027212647529.png" alt="image-20251027212647529" style="zoom:25%;" /></p>


                <hr style="visibility: hidden;">
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2025/10/27/AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%9902/" data-toggle="tooltip" data-placement="top" title="【AI思想启蒙02】线性回归1第一个模型，用来进行数值预测 ">
                        Previous<br>
                        <span>【AI思想启蒙02】线性回归1第一个模型，用来进行数值预测 </span>
                        </a>
                    </li>
                    
                    
                </ul>
                <hr style="visibility: hidden;">

                

                
            </div>  

    <!-- Side Catalog Container -->
        
            <div class="
                col-lg-2 col-lg-offset-0
                visible-lg-block
                sidebar-container
                catalog-container">
                <div class="side-catalog">
                    <hr class="hidden-sm hidden-xs">
                    <h5>
                        <a class="catalog-toggle" href="#">CATALOG</a>
                    </h5>
                    <ul class="catalog-body"></ul>
                </div>
            </div>
        

    <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                


<section>
    
        <hr class="hidden-sm hidden-xs">
    
    <h5><a href="/archive/">FEATURED TAGS</a></h5>
    <div class="tags">
        
        
        
        
        
        
                <a data-sort="0176" 
                    href="/archive/?tag=%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB"
                    title="书籍阅读"
                    rel="3">书籍阅读</a>
        
                <a data-sort="0138" 
                    href="/archive/?tag=%E7%AE%97%E6%B3%95"
                    title="算法"
                    rel="41">算法</a>
        
                <a data-sort="0161" 
                    href="/archive/?tag=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI%E5%9F%BA%E7%A1%80"
                    title="人工智能AI基础"
                    rel="18">人工智能AI基础</a>
        
                <a data-sort="0162" 
                    href="/archive/?tag=python%E5%9F%BA%E7%A1%80"
                    title="python基础"
                    rel="17">python基础</a>
        
                <a data-sort="0164" 
                    href="/archive/?tag=%E5%8A%9B%E6%89%A3"
                    title="力扣"
                    rel="15">力扣</a>
        
                <a data-sort="0166" 
                    href="/archive/?tag=numpy"
                    title="numpy"
                    rel="13">numpy</a>
        
                <a data-sort="0166" 
                    href="/archive/?tag=pandas"
                    title="pandas"
                    rel="13">pandas</a>
        
                <a data-sort="0167" 
                    href="/archive/?tag=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE"
                    title="机器学习-吴恩达"
                    rel="12">机器学习-吴恩达</a>
        
                <a data-sort="0168" 
                    href="/archive/?tag=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95"
                    title="机器学习算法"
                    rel="11">机器学习算法</a>
        
                <a data-sort="0173" 
                    href="/archive/?tag=matplotlib"
                    title="matplotlib"
                    rel="6">matplotlib</a>
        
                <a data-sort="0176" 
                    href="/archive/?tag=AI%E6%80%9D%E6%83%B3%E5%90%AF%E8%92%99"
                    title="AI思想启蒙"
                    rel="3">AI思想启蒙</a>
        
                <a data-sort="0176" 
                    href="/archive/?tag=spring6"
                    title="spring6"
                    rel="3">spring6</a>
        
                <a data-sort="0177" 
                    href="/archive/?tag=%E7%AE%97%E6%B3%95%E9%A2%98%E5%BA%93"
                    title="算法题库"
                    rel="2">算法题库</a>
        
                <a data-sort="0177" 
                    href="/archive/?tag=Java%E5%9F%BA%E7%A1%80"
                    title="Java基础"
                    rel="2">Java基础</a>
        
                <a data-sort="0177" 
                    href="/archive/?tag=java%E9%9B%86%E5%90%88"
                    title="java集合"
                    rel="2">java集合</a>
        
                <a data-sort="0177" 
                    href="/archive/?tag=ollama%E5%B7%A5%E5%85%B7"
                    title="ollama工具"
                    rel="2">ollama工具</a>
        
                <a data-sort="0177" 
                    href="/archive/?tag=python%E7%88%AC%E8%99%AB"
                    title="python爬虫"
                    rel="2">python爬虫</a>
    </div>
</section>


                <!-- Friends Blog -->
                
<hr>
<h5>FRIENDS</h5>
<ul class="list-inline">
  
  <li><a href="https://m.freebuf.com/">freebuf</a></li>
  
  <li><a href="https://xz.aliyun.com/">先知</a></li>
  
  <li><a href="https://www.sec-in.com/All">sec-in</a></li>
  
  <li><a href="https://paper.seebug.org/">see-bug</a></li>
  
  <li><a href="https://twitter.com/Concurr21486093">我的推特</a></li>
  
  <li><a href="https://pdai.tech/">pdai</a></li>
  
  <li><a href="https://nodejs.org/dist/">nodejs index of dist</a></li>
  
  <li><a href="#">公众号：小东方不败</a></li>
  
</ul>

            </div>
        </div>
    </div>
</article>

<!-- add support for mathjax by voleking-->









<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'hover',
          placement: 'right',
          // icon: '#'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <!-- SNS Link -->
                


<ul class="list-inline text-center">


  
  
  <li>
    <a href="https://twitter.com/Concurr21486093">
      <span class="fa-stack fa-lg">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
      </span>
    </a>
  </li>
  
  
  <li>
    <a target="_blank" href="https://www.zhihu.com/people/Hilda">
      <span class="fa-stack fa-lg">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa  fa-stack-1x fa-inverse">知</i>
      </span>
    </a>
  </li>
  
  
  
  
  <li>
    <a target="_blank" href="https://github.com/kirsten-1">
      <span class="fa-stack fa-lg">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa fa-github fa-stack-1x fa-inverse"></i>
      </span>
    </a>
  </li>
  
  
</ul>

                <p class="copyright text-muted">
                    Copyright &copy; Hilda 2025
                    <br>
                    Powered by <a href="https://kirsten-1.github.io/">hilda Blog</a>
<!--                    <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="100px"-->
<!--                        height="20px"-->
<!--                        src="https://ghbtns.com/github-btn.html?user=huxpro&repo=huxpro.github.io&type=star&count=true">-->
<!--                    </iframe>-->
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<!-- Currently, only navbar scroll-down effect at desktop still depends on this -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js "></script>

<!-- Simple Jekyll Search -->
<script src="/js/simple-jekyll-search.min.js"></script>

<!-- Service Worker -->

<script src="/js/snackbar.js "></script>
<script src="/js/sw-registration.js "></script>


<!-- async load function -->
<script>
    function async(u, c) {
        var d = document, t = 'script',
            o = d.createElement(t),
            s = d.getElementsByTagName(t)[0];
        o.src = u;
        if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
        s.parentNode.insertBefore(o, s);
    }
</script>

<!--
     Because of the native support for backtick-style fenced code blocks
     right within the Markdown is landed in Github Pages,
     From V1.6, There is no need for Highlight.js,
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/
     - https://github.com/jneen/rouge/wiki/list-of-supported-languages-and-lexers
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->







<!--fastClick.js -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function () {
        var $nav = document.querySelector("nav");
        if ($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->



<!-- Baidu Tongji -->



<!-- Side Catalog -->

<script type="text/javascript">
    function generateCatalog(selector) {

        // interop with multilangual 
        if ('' == 'true') {
            _containerSelector = 'div.post-container.active'
        } else {
            _containerSelector = 'div.post-container'
        }

        // init
        var P = $(_containerSelector), a, n, t, l, i, c;
        a = P.find('h1,h2,h3,h4,h5,h6');

        // clean
        $(selector).html('')

        // appending
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            i = "#" + $(this).prop('id');
            t = $(this).text();
            c = $('<a href="' + i + '" rel="nofollow">' + t + '</a>');
            l = $('<li class="' + n + '_nav"></li>').append(c);
            $(selector).append(l);
        });
        return true;
    }

    generateCatalog(".catalog-body");

    // toggle side catalog
    $(".catalog-toggle").click((function (e) {
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    /*
     * Doc: https://github.com/davist11/jQuery-One-Page-Nav
     * Fork by Hux to support padding
     */
    async("/js/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });
</script>



<!-- Multi-Lingual -->


<!-- Simple Jekyll Search -->
<script>
    // https://stackoverflow.com/questions/1912501/unescape-html-entities-in-javascript
    function htmlDecode(input) {
        var e = document.createElement('textarea');
        e.innerHTML = input;
        // handle case of empty input
        return e.childNodes.length === 0 ? "" : e.childNodes[0].nodeValue;
    }

    SimpleJekyllSearch({
        searchInput: document.getElementById('search-input'),
        resultsContainer: document.getElementById('search-results'),
        json: '/search.json',
        searchResultTemplate: '<div class="post-preview item"><a href="{url}"><h2 class="post-title">{title}</h2><h3 class="post-subtitle">{subtitle}</h3><hr></a></div>',
        noResultsText: 'No results',
        limit: 50,
        fuzzy: false,
        // a hack to get escaped subtitle unescaped. for some reason, 
        // post.subtitle w/o escape filter nuke entire search.
        templateMiddleware: function (prop, value, template) {
            if (prop === 'subtitle' || prop === 'title') {
                if (value.indexOf("code")) {
                    return htmlDecode(value);
                } else {
                    return value;
                }
            }
        }
    });

    $(document).ready(function () {
        var $searchPage = $('.search-page');
        var $searchOpen = $('.search-icon');
        var $searchClose = $('.search-icon-close');
        var $searchInput = $('#search-input');
        var $body = $('body');

        $searchOpen.on('click', function (e) {
            e.preventDefault();
            $searchPage.toggleClass('search-active');
            var prevClasses = $body.attr('class') || '';
            setTimeout(function () {
                $body.addClass('no-scroll');
            }, 400)

            if ($searchPage.hasClass('search-active')) {
                $searchClose.on('click', function (e) {
                    e.preventDefault();
                    $searchPage.removeClass('search-active');
                    $body.attr('class', prevClasses);  // from closure 
                });
                $searchInput.focus();
            }
        });
    });
</script>


<!-- Image to hack wechat -->
<img src="/img/icon_wechat.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
